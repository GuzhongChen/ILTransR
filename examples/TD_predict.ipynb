{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:06.758639Z",
     "start_time": "2021-09-24T08:53:04.238639Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon,nd,autograd,npx\n",
    "import gluonnlp as nlp\n",
    "import nmt\n",
    "from gluonnlp.model.transformer import ParallelTransformer, get_transformer_encoder_decoder\n",
    "import pandas as pd \n",
    "nlp.utils.check_version('0.7.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:06.774628Z",
     "start_time": "2021-09-24T08:53:06.759639Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "random.seed(101)\n",
    "mx.random.seed(10001)\n",
    "ctx = mx.gpu(0)\n",
    "\n",
    "# parameters for dataset\n",
    "dataset = 'pubchem'\n",
    "src_lang, tgt_lang = 'random_smiles', 'rdkit_canonical_smiles'\n",
    "src_max_len, tgt_max_len = 100, 100\n",
    "\n",
    "# parameters for model\n",
    "num_units=128\n",
    "hidden_size=1024\n",
    "tf_dropout=0\n",
    "epsilon=0.1\n",
    "num_layers=3\n",
    "num_heads=4\n",
    "scaled=True\n",
    "share_embed=True\n",
    "embed_size=128\n",
    "tie_weights=True\n",
    "embed_initializer=None\n",
    "magnitude = 3.0\n",
    "lr_update_factor = 0.5\n",
    "param_file = 'C:\\\\Users\\\\QI_LAB\\\\Desktop\\\\IL-PROPERTY-PREDICT-PUBCHEM\\\\TD\\\\textcnn\\\\TD_best.params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:06.790628Z",
     "start_time": "2021-09-24T08:53:06.775631Z"
    }
   },
   "outputs": [],
   "source": [
    "def _load_vocab(file_path, **kwargs):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return nlp.Vocab.from_json(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:06.806627Z",
     "start_time": "2021-09-24T08:53:06.791628Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\QI_LAB\\\\Desktop\\\\IL-PROPERTY-PREDICT-PUBCHEM\\\\datasets\\\\pubchem\\\\vocab.random_smiles.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m src_vocab \u001b[38;5;241m=\u001b[39m \u001b[43m_load_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mQI_LAB\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mIL-PROPERTY-PREDICT-PUBCHEM\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mpubchem\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mvocab.random_smiles.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tgt_vocab \u001b[38;5;241m=\u001b[39m _load_vocab(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mQI_LAB\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mIL-PROPERTY-PREDICT-PUBCHEM\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mpubchem\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mvocab.rdkit_canonical_smiles.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m_load_vocab\u001b[0;34m(file_path, **kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_vocab\u001b[39m(file_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mVocab\u001b[38;5;241m.\u001b[39mfrom_json(f\u001b[38;5;241m.\u001b[39mread())\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\QI_LAB\\\\Desktop\\\\IL-PROPERTY-PREDICT-PUBCHEM\\\\datasets\\\\pubchem\\\\vocab.random_smiles.json'"
     ]
    }
   ],
   "source": [
    "src_vocab = _load_vocab('C:\\\\Users\\\\QI_LAB\\\\Desktop\\\\IL-PROPERTY-PREDICT-PUBCHEM\\\\datasets\\\\pubchem\\\\vocab.random_smiles.json')\n",
    "tgt_vocab = _load_vocab('C:\\\\Users\\\\QI_LAB\\\\Desktop\\\\IL-PROPERTY-PREDICT-PUBCHEM\\\\datasets\\\\pubchem\\\\vocab.rdkit_canonical_smiles.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:06.822628Z",
     "start_time": "2021-09-24T08:53:06.807628Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder, decoder, one_step_ahead_decoder = get_transformer_encoder_decoder(\n",
    "    units=num_units,\n",
    "    hidden_size=hidden_size,\n",
    "    dropout=tf_dropout,\n",
    "    num_layers=num_layers,\n",
    "    num_heads=num_heads,\n",
    "    max_src_length=src_max_len,\n",
    "    max_tgt_length=tgt_max_len,\n",
    "    scaled=scaled)\n",
    "model = nlp.model.translation.NMTModel(src_vocab=src_vocab,\n",
    "                 tgt_vocab=tgt_vocab,\n",
    "                 encoder=encoder,\n",
    "                 decoder=decoder,\n",
    "                 one_step_ahead_decoder=one_step_ahead_decoder,\n",
    "                 embed_size=num_units,\n",
    "                 embed_initializer=None,\n",
    "                 prefix='transformer_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:06.854627Z",
     "start_time": "2021-09-24T08:53:06.823628Z"
    }
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "def canonical_smile(sml):\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(sml)\n",
    "        return Chem.MolToSmiles(m, canonical=True,isomericSmiles=False)\n",
    "    except:\n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:06.870627Z",
     "start_time": "2021-09-24T08:53:06.856627Z"
    }
   },
   "outputs": [],
   "source": [
    "def no_split(sm):\n",
    "    arr = []\n",
    "    i = 0\n",
    "    try:\n",
    "        len(sm)\n",
    "    except:\n",
    "        print(sm)\n",
    "    while i < len(sm)-1:\n",
    "        arr.append(sm[i])\n",
    "        i += 1\n",
    "    if i == len(sm)-1:\n",
    "        arr.append(sm[i])\n",
    "    return ' '.join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:06.886627Z",
     "start_time": "2021-09-24T08:53:06.871628Z"
    }
   },
   "outputs": [],
   "source": [
    "length_clip = nlp.data.ClipSequence(100)\n",
    "# Helper function to preprocess a single data point\n",
    "def preprocess(data):\n",
    "    # A token index or a list of token indices is\n",
    "    # returned according to the vocabulary.\n",
    "    src_sentence = src_vocab[data.split()]\n",
    "    src_sentence.append(src_vocab[src_vocab.eos_token])\n",
    "    src_npy = np.array(src_sentence, dtype=np.int32)\n",
    "    src_nd = mx.nd.array(src_npy)\n",
    "    return src_nd\n",
    "\n",
    "# Helper function for getting the length\n",
    "def get_length(x):\n",
    "    return float(len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:06.902627Z",
     "start_time": "2021-09-24T08:53:06.887628Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_dropout = 0.1\n",
    "batch_size = 64\n",
    "bucket_num, bucket_ratio = 2, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:06.918627Z",
     "start_time": "2021-09-24T08:53:06.903628Z"
    }
   },
   "outputs": [],
   "source": [
    "class SigmaNet(gluon.HybridBlock):\n",
    "    \"\"\"Network for sentiment analysis.\"\"\"\n",
    "    def __init__(self, dropout, src_vocab=src_vocab,embed_size=embed_size,output_size=1,\n",
    "                 num_filters=(100, 200, 200, 200, 200, 100, 100, 100, 100,100), ngram_filter_sizes=(1, 2, 3,4, 5, 6, 7, 8, 9, 10),prefix=None, params=None):\n",
    "        super(SigmaNet, self).__init__(prefix=prefix, params=params)\n",
    "        with self.name_scope():\n",
    "            self.src_embed = None\n",
    "            self.encoder = None # will set with lm encoder later\n",
    "            self.textcnn = nlp.model.ConvolutionalEncoder(embed_size=embed_size,\n",
    "                                                          num_filters=num_filters,\n",
    "                                                          ngram_filter_sizes=ngram_filter_sizes,\n",
    "                                                          conv_layer_activation='relu',\n",
    "                                                          num_highway=1)\n",
    "            '''\n",
    "            self.conv = gluon.nn.HybridSequential()\n",
    "            with self.conv.name_scope():\n",
    "                self.conv.add(gluon.nn.BatchNorm())\n",
    "                self.conv.add(gluon.nn.Conv1D(256,kernel_size=3, padding=1,activation= 'relu'))\n",
    "                self.conv.add(gluon.nn.BatchNorm())\n",
    "                self.conv.add(gluon.nn.Conv1D(256,kernel_size=3, padding=1,activation= 'relu'))\n",
    "            self.resnet = gluon.nn.HybridSequential()\n",
    "            with self.resnet.name_scope():\n",
    "                self.resnet.add(resnet_block(256, 2, first_block=True),\n",
    "                resnet_block(256, 2),\n",
    "                resnet_block(256, 2),\n",
    "                resnet_block(256, 2),gluon.nn.GlobalAvgPool1D())\n",
    "            '''\n",
    "            self.output = gluon.nn.HybridSequential()\n",
    "            with self.output.name_scope():\n",
    "                self.output.add(gluon.nn.Dense(1024))\n",
    "                self.output.add(gluon.nn.Dropout(dropout))\n",
    "                self.output.add(gluon.nn.Dense(512))\n",
    "                #self.output.add(gluon.nn.Dropout(dropout))\n",
    "                self.output.add(gluon.nn.Dense(output_size, flatten= False))\n",
    "\n",
    "    def hybrid_forward(self, F, src_nd, valid_length):# pylint: disable=arguments-differ\n",
    "        #src_nd = F.reshape(src_nd, (F.shape_array(src_nd), -1))\n",
    "        src_embed_ = self.src_embed(src_nd)\n",
    "        encoded,_ = self.encoder(src_embed_,valid_length=valid_length)  # Shape(T, N, C)\n",
    "        #encoded = F.reshape(encoded,shape= (F.shape_array(encoded)[1],batch_size,-1))\n",
    "        textcnn = self.textcnn(F.transpose(encoded,axes = (1,0,2)))\n",
    "        #transformed = self.resnet(mx.symbol.expand_dims(textcnn,axis=1))\n",
    "        #conv = self.conv(F.transpose(mx.symbol.expand_dims(textcnn,axis=1),axes = (0,2,1)))\n",
    "        #conv = self.conv(mx.symbol.expand_dims(textcnn,axis=1))\n",
    "        #transformed = self.resnet(conv)\n",
    "        out = self.output(textcnn)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:06.934626Z",
     "start_time": "2021-09-24T08:53:06.919627Z"
    }
   },
   "outputs": [],
   "source": [
    "net = SigmaNet(dropout=cnn_dropout)\n",
    "net.encoder = model.encoder\n",
    "net.src_embed =  model.src_embed\n",
    "net.hybridize()\n",
    "print(net)\n",
    "#net.textcnn.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "#net.output.initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:08.959627Z",
     "start_time": "2021-09-24T08:53:06.935628Z"
    }
   },
   "outputs": [],
   "source": [
    "net.load_parameters(param_file,ctx=ctx)\n",
    "net.initialize(init=mx.init.Xavier(magnitude=magnitude), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:09.135627Z",
     "start_time": "2021-09-24T08:53:08.960629Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mx.viz.plot_network(net(mx.sym.var('smiles'),mx.sym.var('valid_length')),\n",
    "                    node_attrs={\n",
    "                        \"shape\": \"oval\",\n",
    "                        \"fixedsize\": \"false\"\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:09.151627Z",
     "start_time": "2021-09-24T08:53:09.136628Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(net, dataloader,context):\n",
    "    out = []\n",
    "    for i, ((data, length), label) in enumerate(dataloader):\n",
    "        data = data.as_in_context(context)\n",
    "        length = length.as_in_context(context).astype(np.float32)\n",
    "        label = label.as_in_context(context)\n",
    "        output = net(data,length)\n",
    "        out= out+[f for f in output.asnumpy()]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:09.167627Z",
     "start_time": "2021-09-24T08:53:09.152628Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloader(predict_dataset,predict_smiles_lengths):\n",
    "\n",
    "    # Pad data, stack label and lengths\n",
    "    batchify_fn = nlp.data.batchify.Tuple(\n",
    "        nlp.data.batchify.Pad(axis=0, pad_val=0, ret_length=True),\n",
    "        nlp.data.batchify.Stack(dtype='float32'))\n",
    "    predict_batch_sampler = nlp.data.sampler.FixedBucketSampler(\n",
    "        predict_smiles_lengths,\n",
    "        batch_size=batch_size,\n",
    "        num_buckets=bucket_num,\n",
    "        ratio=bucket_ratio,\n",
    "        shuffle=False)\n",
    "\n",
    "    predict_dataloader = gluon.data.DataLoader(dataset=predict_dataset,\n",
    "                                             batch_sampler=predict_batch_sampler,\n",
    "                                             batchify_fn=batchify_fn)\n",
    "    return predict_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:09.566639Z",
     "start_time": "2021-09-24T08:53:09.168628Z"
    }
   },
   "outputs": [],
   "source": [
    "to_predict_data = pd.read_excel('decom_test_set.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:11.689639Z",
     "start_time": "2021-09-24T08:53:09.567639Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_smiles = to_predict_data['SMILES'].map(canonical_smile).map(no_split).map(preprocess)\n",
    "predict_smiles_lengths = to_predict_data['SMILES'].map(canonical_smile).map(no_split).map(get_length)\n",
    "predict_sigma =mx.nd.ones((len(predict_smiles),1))\n",
    "predict_dataset = gluon.data.SimpleDataset(gluon.data.ArrayDataset(predict_smiles,predict_sigma))\n",
    "predict_dataloader = get_dataloader(predict_dataset,predict_smiles_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:48.589964Z",
     "start_time": "2021-09-24T08:53:11.690639Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted = predict(net, predict_dataloader,ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:53:48.621964Z",
     "start_time": "2021-09-24T08:53:48.590966Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predicted)\n",
    "df.to_csv('predicted_decom_test_set.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross valid avg train loss 1.3489668809973936\n",
    "K-fold cross valid avg train r2 0.9973347734852677\n",
    "K-fold cross valid avg test loss 13.18546958523049\n",
    "K-fold cross valid avg test r2 0.8633920641584876\n",
    "\n",
    "Total time cost 226.34s\n",
    "K-fold cross valid avg train loss 1.0208112936765557\n",
    "K-fold cross valid avg train r2 0.9973985693900078\n",
    "K-fold cross valid avg test loss 11.410513927679215\n",
    "K-fold cross valid avg test r2 0.9079264533881546"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
