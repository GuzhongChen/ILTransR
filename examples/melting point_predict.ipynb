{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:33.885684Z",
     "start_time": "2021-05-10T13:22:30.901685Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon,nd,autograd,npx\n",
    "import gluonnlp as nlp\n",
    "import nmt\n",
    "from gluonnlp.model.transformer import ParallelTransformer, get_transformer_encoder_decoder\n",
    "import pandas as pd \n",
    "nlp.utils.check_version('0.7.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:33.901684Z",
     "start_time": "2021-05-10T13:22:33.886685Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "random.seed(101)\n",
    "mx.random.seed(10001)\n",
    "ctx = mx.gpu(0)\n",
    "\n",
    "# parameters for dataset\n",
    "dataset = 'pubchem'\n",
    "src_lang, tgt_lang = 'random_smiles', 'rdkit_canonical_smiles'\n",
    "src_max_len, tgt_max_len = 100, 100\n",
    "\n",
    "# parameters for model\n",
    "num_units=128\n",
    "hidden_size=1024\n",
    "tf_dropout=0\n",
    "epsilon=0.1\n",
    "num_layers=3\n",
    "num_heads=4\n",
    "scaled=True\n",
    "share_embed=True\n",
    "embed_size=128\n",
    "tie_weights=True\n",
    "embed_initializer=None\n",
    "magnitude = 3.0\n",
    "lr_update_factor = 0.5\n",
    "param_file = 'MP/MP_best.params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:33.917684Z",
     "start_time": "2021-05-10T13:22:33.902686Z"
    }
   },
   "outputs": [],
   "source": [
    "def _load_vocab(file_path, **kwargs):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return nlp.Vocab.from_json(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:33.933684Z",
     "start_time": "2021-05-10T13:22:33.918685Z"
    }
   },
   "outputs": [],
   "source": [
    "src_vocab = _load_vocab('pubchem/vocab.random_smiles.json')\n",
    "tgt_vocab = _load_vocab('pubchem/vocab.rdkit_canonical_smiles.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:33.949686Z",
     "start_time": "2021-05-10T13:22:33.934685Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:40:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder, one_step_ahead_decoder = get_transformer_encoder_decoder(\n",
    "    units=num_units,\n",
    "    hidden_size=hidden_size,\n",
    "    dropout=tf_dropout,\n",
    "    num_layers=num_layers,\n",
    "    num_heads=num_heads,\n",
    "    max_src_length=src_max_len,\n",
    "    max_tgt_length=tgt_max_len,\n",
    "    scaled=scaled)\n",
    "model = nlp.model.translation.NMTModel(src_vocab=src_vocab,\n",
    "                 tgt_vocab=tgt_vocab,\n",
    "                 encoder=encoder,\n",
    "                 decoder=decoder,\n",
    "                 one_step_ahead_decoder=one_step_ahead_decoder,\n",
    "                 embed_size=num_units,\n",
    "                 embed_initializer=None,\n",
    "                 prefix='transformer_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:33.997685Z",
     "start_time": "2021-05-10T13:22:33.950686Z"
    }
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "def canonical_smile(sml):\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(sml)\n",
    "        return Chem.MolToSmiles(m, canonical=True,isomericSmiles=False)\n",
    "    except:\n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:34.013684Z",
     "start_time": "2021-05-10T13:22:33.999684Z"
    }
   },
   "outputs": [],
   "source": [
    "def no_split(sm):\n",
    "    arr = []\n",
    "    i = 0\n",
    "    try:\n",
    "        len(sm)\n",
    "    except:\n",
    "        print(sm)\n",
    "    while i < len(sm)-1:\n",
    "        arr.append(sm[i])\n",
    "        i += 1\n",
    "    if i == len(sm)-1:\n",
    "        arr.append(sm[i])\n",
    "    return ' '.join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:34.029684Z",
     "start_time": "2021-05-10T13:22:34.014686Z"
    }
   },
   "outputs": [],
   "source": [
    "length_clip = nlp.data.ClipSequence(100)\n",
    "# Helper function to preprocess a single data point\n",
    "def preprocess(data):\n",
    "    # A token index or a list of token indices is\n",
    "    # returned according to the vocabulary.\n",
    "    src_sentence = src_vocab[data.split()]\n",
    "    src_sentence.append(src_vocab[src_vocab.eos_token])\n",
    "    src_npy = np.array(src_sentence, dtype=np.int32)\n",
    "    src_nd = mx.nd.array(src_npy)\n",
    "    return src_nd\n",
    "\n",
    "# Helper function for getting the length\n",
    "def get_length(x):\n",
    "    return float(len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:34.045685Z",
     "start_time": "2021-05-10T13:22:34.030684Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_dropout = 0.1\n",
    "batch_size = 64\n",
    "bucket_num, bucket_ratio = 2, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:34.061685Z",
     "start_time": "2021-05-10T13:22:34.046686Z"
    }
   },
   "outputs": [],
   "source": [
    "class SigmaNet(gluon.HybridBlock):\n",
    "    \"\"\"Network for sentiment analysis.\"\"\"\n",
    "    def __init__(self, dropout, src_vocab=src_vocab,embed_size=embed_size,output_size=1,\n",
    "                 num_filters=(100, 200, 200, 200, 200, 100, 100, 100, 100,100), ngram_filter_sizes=(1, 2, 3,4, 5, 6, 7, 8, 9, 10),prefix=None, params=None):\n",
    "        super(SigmaNet, self).__init__(prefix=prefix, params=params)\n",
    "        with self.name_scope():\n",
    "            self.src_embed = None\n",
    "            self.encoder = None # will set with lm encoder later\n",
    "            self.textcnn = nlp.model.ConvolutionalEncoder(embed_size=embed_size,\n",
    "                                                          num_filters=num_filters,\n",
    "                                                          ngram_filter_sizes=ngram_filter_sizes,\n",
    "                                                          conv_layer_activation='relu',\n",
    "                                                          num_highway=1)\n",
    "            '''\n",
    "            self.conv = gluon.nn.HybridSequential()\n",
    "            with self.conv.name_scope():\n",
    "                self.conv.add(gluon.nn.BatchNorm())\n",
    "                self.conv.add(gluon.nn.Conv1D(256,kernel_size=3, padding=1,activation= 'relu'))\n",
    "                self.conv.add(gluon.nn.BatchNorm())\n",
    "                self.conv.add(gluon.nn.Conv1D(256,kernel_size=3, padding=1,activation= 'relu'))\n",
    "            self.resnet = gluon.nn.HybridSequential()\n",
    "            with self.resnet.name_scope():\n",
    "                self.resnet.add(resnet_block(256, 2, first_block=True),\n",
    "                resnet_block(256, 2),\n",
    "                resnet_block(256, 2),\n",
    "                resnet_block(256, 2),gluon.nn.GlobalAvgPool1D())\n",
    "            '''\n",
    "            self.output = gluon.nn.HybridSequential()\n",
    "            with self.output.name_scope():\n",
    "                #self.output.add(gluon.nn.Dense(1024))\n",
    "                #self.output.add(gluon.nn.Dropout(dropout))\n",
    "                self.output.add(gluon.nn.Dense(512))\n",
    "                #self.output.add(gluon.nn.Dropout(dropout))\n",
    "                self.output.add(gluon.nn.Dense(output_size, flatten= False))\n",
    "\n",
    "    def hybrid_forward(self, F, src_nd, valid_length):# pylint: disable=arguments-differ\n",
    "        #src_nd = F.reshape(src_nd, (F.shape_array(src_nd), -1))\n",
    "        src_embed_ = self.src_embed(src_nd)\n",
    "        encoded,_ = self.encoder(src_embed_,valid_length=valid_length)  # Shape(T, N, C)\n",
    "        #encoded = F.reshape(encoded,shape= (F.shape_array(encoded)[1],batch_size,-1))\n",
    "        textcnn = self.textcnn(F.transpose(encoded,axes = (1,0,2)))\n",
    "        #transformed = self.resnet(mx.symbol.expand_dims(textcnn,axis=1))\n",
    "        #conv = self.conv(F.transpose(mx.symbol.expand_dims(textcnn,axis=1),axes = (0,2,1)))\n",
    "        #conv = self.conv(mx.symbol.expand_dims(textcnn,axis=1))\n",
    "        #transformed = self.resnet(conv)\n",
    "        out = self.output(textcnn)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:34.077684Z",
     "start_time": "2021-05-10T13:22:34.062685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SigmaNet(\n",
      "  (src_embed): HybridSequential(\n",
      "    (0): Embedding(72 -> 128, float32)\n",
      "    (1): Dropout(p = 0.0, axes=())\n",
      "  )\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): TransformerEncoderCell(\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(None -> 128, linear)\n",
      "          (proj_key): Dense(None -> 128, linear)\n",
      "          (proj_value): Dense(None -> 128, linear)\n",
      "        )\n",
      "        (proj): Dense(None -> 128, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(None -> 1024, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(None -> 128, linear)\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "      )\n",
      "      (1): TransformerEncoderCell(\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(None -> 128, linear)\n",
      "          (proj_key): Dense(None -> 128, linear)\n",
      "          (proj_value): Dense(None -> 128, linear)\n",
      "        )\n",
      "        (proj): Dense(None -> 128, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(None -> 1024, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(None -> 128, linear)\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "      )\n",
      "      (2): TransformerEncoderCell(\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(None -> 128, linear)\n",
      "          (proj_key): Dense(None -> 128, linear)\n",
      "          (proj_value): Dense(None -> 128, linear)\n",
      "        )\n",
      "        (proj): Dense(None -> 128, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(None -> 1024, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(None -> 128, linear)\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (textcnn): ConvolutionalEncoder(\n",
      "    (_convs): HybridConcurrent(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(1,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv1D(128 -> 200, kernel_size=(2,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv1D(128 -> 200, kernel_size=(3,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv1D(128 -> 200, kernel_size=(4,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (4): HybridSequential(\n",
      "        (0): Conv1D(128 -> 200, kernel_size=(5,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (5): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(6,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (6): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(7,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (7): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(8,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (8): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(9,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (9): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(10,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (_highways): Highway(\n",
      "      (hnet): HybridSequential(\n",
      "        (0): Dense(1400 -> 2800, linear)\n",
      "      )\n",
      "      (_activation): Activation(relu)\n",
      "    )\n",
      "  )\n",
      "  (output): HybridSequential(\n",
      "    (0): Dense(None -> 512, linear)\n",
      "    (1): Dense(None -> 1, linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = SigmaNet(dropout=cnn_dropout)\n",
    "net.encoder = model.encoder\n",
    "net.src_embed =  model.src_embed\n",
    "net.hybridize()\n",
    "print(net)\n",
    "#net.textcnn.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "#net.output.initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:36.423684Z",
     "start_time": "2021-05-10T13:22:34.078685Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:40:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU\n"
     ]
    }
   ],
   "source": [
    "net.load_parameters(param_file,ctx=ctx)\n",
    "net.initialize(init=mx.init.Xavier(magnitude=magnitude), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:36.742684Z",
     "start_time": "2021-05-10T13:22:36.728685Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(net, dataloader,context):\n",
    "    out = []\n",
    "    for i, ((data, length), label) in enumerate(dataloader):\n",
    "        data = data.as_in_context(context)\n",
    "        length = length.as_in_context(context).astype(np.float32)\n",
    "        label = label.as_in_context(context)\n",
    "        output = net(data,length)\n",
    "        out= out+[f for f in output.asnumpy()]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:36.758685Z",
     "start_time": "2021-05-10T13:22:36.743685Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloader(predict_dataset,predict_smiles_lengths):\n",
    "\n",
    "    # Pad data, stack label and lengths\n",
    "    batchify_fn = nlp.data.batchify.Tuple(\n",
    "        nlp.data.batchify.Pad(axis=0, pad_val=0, ret_length=True),\n",
    "        nlp.data.batchify.Stack(dtype='float32'))\n",
    "    predict_batch_sampler = nlp.data.sampler.FixedBucketSampler(\n",
    "        predict_smiles_lengths,\n",
    "        batch_size=batch_size,\n",
    "        num_buckets=bucket_num,\n",
    "        ratio=bucket_ratio,\n",
    "        shuffle=False)\n",
    "\n",
    "    predict_dataloader = gluon.data.DataLoader(dataset=predict_dataset,\n",
    "                                             batch_sampler=predict_batch_sampler,\n",
    "                                             batchify_fn=batchify_fn)\n",
    "    return predict_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:37.108684Z",
     "start_time": "2021-05-10T13:22:36.759685Z"
    }
   },
   "outputs": [],
   "source": [
    "to_predict_data = pd.read_excel('mp_test_set.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:22:39.402696Z",
     "start_time": "2021-05-10T13:22:37.109685Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_smiles = to_predict_data['SMILES'].map(canonical_smile).map(no_split).map(preprocess)\n",
    "predict_smiles_lengths = to_predict_data['SMILES'].map(canonical_smile).map(no_split).map(get_length)\n",
    "predict_sigma =mx.nd.ones((len(predict_smiles),1))\n",
    "predict_dataset = gluon.data.SimpleDataset(gluon.data.ArrayDataset(predict_smiles,predict_sigma))\n",
    "predict_dataloader = get_dataloader(predict_dataset,predict_smiles_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:23:24.242684Z",
     "start_time": "2021-05-10T13:22:39.403685Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:40:17] ../src/operator/cudnn_ops.cc:292: Auto-tuning cuDNN op, set MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable\n",
      "[11:40:18] ../src/operator/cudnn_ops.cc:292: Auto-tuning cuDNN op, set MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable\n"
     ]
    }
   ],
   "source": [
    "predicted = predict(net, predict_dataloader,ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T13:23:24.273684Z",
     "start_time": "2021-05-10T13:23:24.243685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "0    315.489105\n",
      "1    346.444946\n",
      "2    312.293915\n",
      "3    311.751678\n",
      "4    315.064545\n",
      "..          ...\n",
      "406  275.522919\n",
      "407  336.472931\n",
      "408  294.943115\n",
      "409  334.717194\n",
      "410  294.337708\n",
      "\n",
      "[411 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(predicted)\n",
    "df.to_csv('predicted_mp_test_set.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross valid avg train loss 1.3489668809973936\n",
    "K-fold cross valid avg train r2 0.9973347734852677\n",
    "K-fold cross valid avg test loss 13.18546958523049\n",
    "K-fold cross valid avg test r2 0.8633920641584876\n",
    "\n",
    "Total time cost 226.34s\n",
    "K-fold cross valid avg train loss 1.0208112936765557\n",
    "K-fold cross valid avg train r2 0.9973985693900078\n",
    "K-fold cross valid avg test loss 11.410513927679215\n",
    "K-fold cross valid avg test r2 0.9079264533881546"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
