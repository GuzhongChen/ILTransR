{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:54.691605Z",
     "start_time": "2021-05-08T08:17:52.250605Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon,nd,autograd,npx\n",
    "import gluonnlp as nlp\n",
    "import nmt\n",
    "from gluonnlp.model.transformer import ParallelTransformer, get_transformer_encoder_decoder\n",
    "import pandas as pd \n",
    "nlp.utils.check_version('0.7.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:54.706604Z",
     "start_time": "2021-05-08T08:17:54.692604Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "ctx = mx.gpu(0)\n",
    "\n",
    "# parameters for dataset\n",
    "dataset = 'pubchem'\n",
    "src_lang, tgt_lang = 'random_smiles', 'rdkit_canonical_smiles'\n",
    "src_max_len, tgt_max_len = 100, 100\n",
    "\n",
    "# parameters for model\n",
    "num_units=128\n",
    "hidden_size=1024\n",
    "dropout=0.05\n",
    "epsilon=0.1\n",
    "num_layers=3\n",
    "num_heads=4\n",
    "scaled=True\n",
    "share_embed=True\n",
    "embed_size=128\n",
    "tie_weights=True\n",
    "embed_initializer=None\n",
    "magnitude = 3.0\n",
    "lr_update_factor = 0.5\n",
    "param_file = 'C:\\\\Users\\\\QI_LAB\\\\Desktop\\\\IL-PROPERTY-PREDICT-PUBCHEM\\\\smiles_transformer_128_1024\\\\valid_best.params'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:54.722604Z",
     "start_time": "2021-05-08T08:17:54.707605Z"
    }
   },
   "outputs": [],
   "source": [
    "def _load_vocab(file_path, **kwargs):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return nlp.Vocab.from_json(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:54.738605Z",
     "start_time": "2021-05-08T08:17:54.723605Z"
    }
   },
   "outputs": [],
   "source": [
    "src_vocab = _load_vocab('C:\\\\Users\\\\QI_LAB\\\\Desktop\\\\IL-PROPERTY-PREDICT-PUBCHEM\\\\datasets\\\\pubchem\\\\vocab.random_smiles.json')\n",
    "tgt_vocab = _load_vocab('C:\\\\Users\\\\QI_LAB\\\\Desktop\\\\IL-PROPERTY-PREDICT-PUBCHEM\\\\datasets\\\\pubchem\\\\vocab.rdkit_canonical_smiles.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:54.770605Z",
     "start_time": "2021-05-08T08:17:54.739605Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "encoder1, decoder1, one_step_ahead_decoder1 = get_transformer_encoder_decoder(\n",
    "    units=num_units,\n",
    "    hidden_size=hidden_size,\n",
    "    dropout=dropout,\n",
    "    num_layers=num_layers,\n",
    "    num_heads=num_heads,\n",
    "    max_src_length=src_max_len,\n",
    "    max_tgt_length=tgt_max_len,\n",
    "    scaled=scaled, prefix='transformer_1')\n",
    "\n",
    "encoder2, decoder2, one_step_ahead_decoder2 = get_transformer_encoder_decoder(\n",
    "    units=num_units,\n",
    "    hidden_size=hidden_size,\n",
    "    dropout=dropout,\n",
    "    num_layers=num_layers,\n",
    "    num_heads=num_heads,\n",
    "    max_src_length=src_max_len,\n",
    "    max_tgt_length=tgt_max_len,\n",
    "    scaled=scaled,prefix='transformer_2')\n",
    "'''\n",
    "encoder3, decoder3, one_step_ahead_decoder3 = get_transformer_encoder_decoder(\n",
    "    units=num_units,\n",
    "    hidden_size=hidden_size,\n",
    "    dropout=dropout,\n",
    "    num_layers=num_layers,\n",
    "    num_heads=num_heads,\n",
    "    max_src_length=src_max_len,\n",
    "    max_tgt_length=tgt_max_len,\n",
    "    scaled=scaled,prefix='transformer_3')\n",
    "'''\n",
    "model1 = nlp.model.translation.NMTModel(src_vocab=src_vocab,\n",
    "                 tgt_vocab=tgt_vocab,\n",
    "                 encoder=encoder1,\n",
    "                 decoder=decoder1,\n",
    "                 one_step_ahead_decoder=one_step_ahead_decoder1,\n",
    "                 embed_size=num_units,\n",
    "                 embed_initializer=None,\n",
    "                 prefix='transformer_1')\n",
    "model2 = nlp.model.translation.NMTModel(src_vocab=src_vocab,\n",
    "                 tgt_vocab=tgt_vocab,\n",
    "                 encoder=encoder2,\n",
    "                 decoder=decoder2,\n",
    "                 one_step_ahead_decoder=one_step_ahead_decoder2,\n",
    "                 embed_size=num_units,\n",
    "                 embed_initializer=None,\n",
    "                 prefix='transformer_2')\n",
    "'''\n",
    "model3 = nlp.model.translation.NMTModel(src_vocab=src_vocab,\n",
    "                 tgt_vocab=tgt_vocab,\n",
    "                 encoder=encoder3,\n",
    "                 decoder=decoder3,\n",
    "                 one_step_ahead_decoder=one_step_ahead_decoder3,\n",
    "                 embed_size=num_units,\n",
    "                 embed_initializer=None,\n",
    "                 prefix='transformer_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:54.786604Z",
     "start_time": "2021-05-08T08:17:54.771605Z"
    }
   },
   "outputs": [],
   "source": [
    "#model.initialize(init=mx.init.Xavier(magnitude=magnitude), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:57.115604Z",
     "start_time": "2021-05-08T08:17:54.788606Z"
    }
   },
   "outputs": [],
   "source": [
    "#model1.load_parameters(param_file,ctx=ctx)\n",
    "#model2.load_parameters(param_file,ctx=ctx)\n",
    "model3.load_parameters(param_file,ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T08:49:19.490024Z",
     "start_time": "2020-09-02T08:49:19.487020Z"
    }
   },
   "source": [
    "model.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T08:49:19.498031Z",
     "start_time": "2020-09-02T08:49:19.491025Z"
    }
   },
   "source": [
    "def encode(model, src_seq, src_vocab,ctx):\n",
    "    src_sentence = src_vocab[src_seq.split()]\n",
    "    src_sentence.append(src_vocab[src_vocab.eos_token])\n",
    "    src_npy = np.array(src_sentence, dtype=np.int32)\n",
    "    src_nd = mx.nd.array(src_npy)\n",
    "    src_nd = src_nd.reshape((1, -1)).as_in_context(ctx)\n",
    "    src_valid_length = mx.nd.array([src_nd.shape[1]]).as_in_context(ctx)\n",
    "    enc_outputs = model.encode(src_nd,valid_length=src_valid_length)\n",
    "    return enc_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T08:49:19.523053Z",
     "start_time": "2020-09-02T08:49:19.499032Z"
    }
   },
   "source": [
    "for sentence in ['c 1 ( N = C ( N ) N ) s c c ( - c 2 c c ( C ) n ( C ) c 2 ) n 1', 'C ( C ( c 1 c c c ( C ( N O ) = O ) c c 1 ) C C ) C']:\n",
    "    e = encode(model, sentence,src_vocab,ctx)\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:57.146604Z",
     "start_time": "2021-05-08T08:17:57.116604Z"
    }
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "def canonical_smile(sml):\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(sml)\n",
    "        #return Chem.MolToSmiles(m, canonical=True,isomericSmiles=False)\n",
    "        return Chem.MolToSmiles(m, canonical=True,isomericSmiles=True)\n",
    "    except:\n",
    "        print(sml)\n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:57.162604Z",
     "start_time": "2021-05-08T08:17:57.147605Z"
    }
   },
   "outputs": [],
   "source": [
    "def no_split(sm):\n",
    "    arr = []\n",
    "    i = 0\n",
    "    try:\n",
    "        len(sm)\n",
    "    except:\n",
    "        print(sm)\n",
    "    while i < len(sm)-1:\n",
    "        arr.append(sm[i])\n",
    "        i += 1\n",
    "    if i == len(sm)-1:\n",
    "        arr.append(sm[i])\n",
    "    return ' '.join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:57.177606Z",
     "start_time": "2021-05-08T08:17:57.163605Z"
    }
   },
   "outputs": [],
   "source": [
    "length_clip = nlp.data.ClipSequence(100)\n",
    "# Helper function to preprocess a single data point\n",
    "def preprocess(data):\n",
    "    # A token index or a list of token indices is\n",
    "    # returned according to the vocabulary.\n",
    "    src_sentence = src_vocab[length_clip(data.split())]\n",
    "    src_sentence.append(src_vocab[src_vocab.eos_token])\n",
    "    src_npy = np.array(src_sentence, dtype=np.int32)\n",
    "    src_nd = mx.nd.array(src_npy)\n",
    "    return src_nd\n",
    "\n",
    "# Helper function for getting the length\n",
    "def get_length(x):\n",
    "    return float(len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:57.208604Z",
     "start_time": "2021-05-08T08:17:57.178605Z"
    }
   },
   "outputs": [],
   "source": [
    "dropout = 0.05\n",
    "train_batch_size = 128\n",
    "test_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:57.239604Z",
     "start_time": "2021-05-08T08:17:57.209605Z"
    }
   },
   "outputs": [],
   "source": [
    "class ILNet(gluon.HybridBlock):\n",
    "    \"\"\"Network for sentiment analysis.\"\"\"\n",
    "    def __init__(self,\n",
    "                 dropout,\n",
    "                 src_vocab=src_vocab,\n",
    "                 embed_size=embed_size,\n",
    "                 output_size=1,\n",
    "                 num_filters=(100, 200, 200, 200, 200, 100,100),\n",
    "                 ngram_filter_sizes=(1, 2, 3, 4, 5, 6,7),\n",
    "                 IL_num_filters=(100, 200, 200, 200, 200, 100, 100, 100, 100,100, 160, 160),\n",
    "                 IL_ngram_filter_sizes=(1, 2, 3,4, 5, 6, 7, 8, 9, 10, 15, 20),\n",
    "                 prefix=None,\n",
    "                 params=None):\n",
    "        super(ILNet, self).__init__(prefix=prefix, params=params)\n",
    "        with self.name_scope():\n",
    "            \n",
    "            self.num_filters = num_filters\n",
    "            self.IL_num_filters = IL_num_filters\n",
    "            '''\n",
    "            self.cation_src_embed = None\n",
    "            self.cation_encoder = None\n",
    "            self.cation_textcnn = nlp.model.ConvolutionalEncoder(\n",
    "                embed_size=embed_size,\n",
    "                num_filters=num_filters,\n",
    "                ngram_filter_sizes=ngram_filter_sizes,\n",
    "                conv_layer_activation='relu',\n",
    "                num_highway=1)\n",
    "            self.cation_dropout = gluon.nn.Dropout(dropout)\n",
    "\n",
    "            self.anion_src_embed = None\n",
    "            self.anion_encoder = None\n",
    "            self.anion_textcnn = nlp.model.ConvolutionalEncoder(\n",
    "                embed_size=embed_size,\n",
    "                num_filters=num_filters,\n",
    "                ngram_filter_sizes=ngram_filter_sizes,\n",
    "                conv_layer_activation='relu',\n",
    "                num_highway=1)\n",
    "            self.anion_dropuot = gluon.nn.Dropout(dropout)\n",
    "            '''\n",
    "            self.IL_src_embed = None\n",
    "            self.IL_encoder = None\n",
    "            self.IL_textcnn = nlp.model.ConvolutionalEncoder(\n",
    "                embed_size=embed_size,\n",
    "                num_filters=IL_num_filters,\n",
    "                ngram_filter_sizes=IL_ngram_filter_sizes,\n",
    "                conv_layer_activation='relu',\n",
    "                num_highway=1)\n",
    "            #self.IL_dropout = gluon.nn.Dropout(dropout)\n",
    "            '''\n",
    "            self.mlp = gluon.nn.HybridSequential()\n",
    "            with self.mlp.name_scope():\n",
    "                #self.mlp.add(gluon.nn.Dropout(dropout))\n",
    "                self.mlp.add(gluon.nn.Dense(1024))\n",
    "                #self.mlp.add(gluon.nn.BatchNorm())\n",
    "                self.mlp.add(gluon.nn.Activation('relu'))\n",
    "                #self.mlp.add(gluon.nn.Dropout(dropout))\n",
    "                \n",
    "                self.mlp.add(gluon.nn.Dense(2048))\n",
    "                self.mlp.add(gluon.nn.BatchNorm())\n",
    "                self.mlp.add(gluon.nn.Activation('relu'))\n",
    "                \n",
    "                self.mlp.add(gluon.nn.Dense(1024))\n",
    "                self.mlp.add(gluon.nn.BatchNorm())\n",
    "                self.mlp.add(gluon.nn.Activation('relu'))\n",
    "                \n",
    "                self.mlp.add(gluon.nn.Dense(512))\n",
    "                self.mlp.add(gluon.nn.BatchNorm())\n",
    "                self.mlp.add(gluon.nn.Activation('relu'))\n",
    "                self.mlp.add(gluon.nn.Dense(256))\n",
    "                self.mlp.add(gluon.nn.BatchNorm())\n",
    "                self.mlp.add(gluon.nn.Activation('relu'))\n",
    "                '''\n",
    "            self.output = gluon.nn.HybridSequential()\n",
    "            with self.output.name_scope():\n",
    "                #self.output.add(gluon.nn.Dropout(dropout))\n",
    "                self.output.add(gluon.nn.Dense(1024))\n",
    "                self.output.add(gluon.nn.Activation('relu'))\n",
    "                self.output.add(gluon.nn.Dropout(dropout))\n",
    "                self.output.add(gluon.nn.Dense(512))\n",
    "                self.output.add(gluon.nn.Activation('relu'))\n",
    "                '''\n",
    "                #self.output.add(gluon.nn.Dropout(dropout))\n",
    "                self.output.add(gluon.nn.Dense(512))\n",
    "                self.output.add(gluon.nn.Activation('relu'))\n",
    "                #self.output.add(gluon.nn.Dropout(dropout))\n",
    "                self.output.add(gluon.nn.Dense(256))\n",
    "                self.output.add(gluon.nn.Activation('relu'))\n",
    "                #self.output.add(gluon.nn.Dropout(dropout))\n",
    "                '''\n",
    "                self.output.add(gluon.nn.Dense(output_size, flatten=False))\n",
    "\n",
    "    def hybrid_forward(self, F, IL_src_nd, IL_valid_length, T, P):  # pylint: disable=arguments-differ\n",
    "        '''\n",
    "        cation_src_embed_ = self.cation_src_embed(cation_src_nd)\n",
    "        cation_encoded, _ = self.cation_encoder(\n",
    "            cation_src_embed_,\n",
    "            valid_length=cation_valid_length)  # Shape(T, N, C)\n",
    "        cation_textcnn = self.cation_textcnn(\n",
    "            F.transpose(cation_encoded, axes=(1, 0, 2)))\n",
    "        cation_textcnn = self.cation_dropout(cation_textcnn)\n",
    "\n",
    "        anion_src_embed_ = self.anion_src_embed(anion_src_nd)\n",
    "        anion_encoded, _ = self.anion_encoder(\n",
    "            anion_src_embed_,\n",
    "            valid_length=anion_valid_length)  # Shape(T, N, C)\n",
    "        anion_textcnn = self.anion_textcnn(\n",
    "            F.transpose(anion_encoded, axes=(1, 0, 2)))\n",
    "        anion_textcnn = self.anion_dropuot(anion_textcnn)\n",
    "        '''\n",
    "        IL_src_embed_ = self.IL_src_embed(IL_src_nd)\n",
    "        IL_encoded, _ = self.IL_encoder(\n",
    "            IL_src_embed_,\n",
    "            valid_length=IL_valid_length)  # Shape(T, N, C)\n",
    "        IL_textcnn = self.IL_textcnn(\n",
    "            F.transpose(IL_encoded, axes=(1, 0, 2)))\n",
    "        #IL_textcnn = self.IL_dropout(IL_textcnn)\n",
    "        \n",
    "        T_ = F.reshape(T, shape=(-1, 1))\n",
    "        P_ = F.reshape(P, shape=(-1, 1))\n",
    "        \n",
    "        input_vecs = mx.symbol.concat(\n",
    "            F.reshape(IL_textcnn,\n",
    "                      shape=(-1, sum(self.IL_num_filters))),T_, P_)\n",
    "        \n",
    "        #mlp_out = self.mlp(IL_textcnn)\n",
    "\n",
    "        \n",
    "\n",
    "        #add_temp_press = mx.symbol.concat(IL_textcnn, T_, P_)\n",
    "        out = self.output(input_vecs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:57.271604Z",
     "start_time": "2021-05-08T08:17:57.240605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILNet(\n",
      "  (IL_src_embed): HybridSequential(\n",
      "    (0): Embedding(72 -> 128, float32)\n",
      "    (1): Dropout(p = 0.0, axes=())\n",
      "  )\n",
      "  (IL_encoder): TransformerEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.05, axes=())\n",
      "    (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.05, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.05, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(128 -> 128, linear)\n",
      "          (proj_key): Dense(128 -> 128, linear)\n",
      "          (proj_value): Dense(128 -> 128, linear)\n",
      "        )\n",
      "        (proj): Dense(128 -> 128, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(128 -> 1024, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(1024 -> 128, linear)\n",
      "          (dropout_layer): Dropout(p = 0.05, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "      )\n",
      "      (1): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.05, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.05, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(128 -> 128, linear)\n",
      "          (proj_key): Dense(128 -> 128, linear)\n",
      "          (proj_value): Dense(128 -> 128, linear)\n",
      "        )\n",
      "        (proj): Dense(128 -> 128, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(128 -> 1024, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(1024 -> 128, linear)\n",
      "          (dropout_layer): Dropout(p = 0.05, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "      )\n",
      "      (2): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.05, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.05, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(128 -> 128, linear)\n",
      "          (proj_key): Dense(128 -> 128, linear)\n",
      "          (proj_value): Dense(128 -> 128, linear)\n",
      "        )\n",
      "        (proj): Dense(128 -> 128, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(128 -> 1024, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(1024 -> 128, linear)\n",
      "          (dropout_layer): Dropout(p = 0.05, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=128)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (IL_textcnn): ConvolutionalEncoder(\n",
      "    (_convs): HybridConcurrent(\n",
      "      (0): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(1,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (1): HybridSequential(\n",
      "        (0): Conv1D(128 -> 200, kernel_size=(2,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (2): HybridSequential(\n",
      "        (0): Conv1D(128 -> 200, kernel_size=(3,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (3): HybridSequential(\n",
      "        (0): Conv1D(128 -> 200, kernel_size=(4,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (4): HybridSequential(\n",
      "        (0): Conv1D(128 -> 200, kernel_size=(5,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (5): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(6,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (6): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(7,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (7): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(8,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (8): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(9,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (9): HybridSequential(\n",
      "        (0): Conv1D(128 -> 100, kernel_size=(10,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (10): HybridSequential(\n",
      "        (0): Conv1D(128 -> 160, kernel_size=(15,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "      (11): HybridSequential(\n",
      "        (0): Conv1D(128 -> 160, kernel_size=(20,), stride=(1,))\n",
      "        (1): HybridLambda(<lambda>)\n",
      "        (2): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (_highways): Highway(\n",
      "      (hnet): HybridSequential(\n",
      "        (0): Dense(1720 -> 3440, linear)\n",
      "      )\n",
      "      (_activation): Activation(relu)\n",
      "    )\n",
      "  )\n",
      "  (output): HybridSequential(\n",
      "    (0): Dense(None -> 1024, linear)\n",
      "    (1): Activation(relu)\n",
      "    (2): Dropout(p = 0.05, axes=())\n",
      "    (3): Dense(None -> 512, linear)\n",
      "    (4): Activation(relu)\n",
      "    (5): Dense(None -> 1, linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ILNet(dropout=dropout)\n",
    "#net.cation_encoder = model1.encoder\n",
    "#net.cation_src_embed =  model1.src_embed\n",
    "\n",
    "#net.anion_encoder = model2.encoder\n",
    "#net.anion_src_embed =  model2.src_embed\n",
    "\n",
    "net.IL_encoder = model3.encoder\n",
    "net.IL_src_embed =  model3.src_embed\n",
    "net.hybridize()\n",
    "print(net)\n",
    "#net.textcnn.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "#net.output.initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:57.446605Z",
     "start_time": "2021-05-08T08:17:57.272605Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: plot Pages: 1 -->\r\n",
       "<svg width=\"5693pt\" height=\"10688pt\"\r\n",
       " viewBox=\"0.00 0.00 5692.69 10688.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 10684)\">\r\n",
       "<title>plot</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-10684 5688.69,-10684 5688.69,4 -4,4\"/>\r\n",
       "<!-- IL_smiles -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>IL_smiles</title>\r\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"3117.21\" cy=\"-29\" rx=\"47\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3117.21\" y=\"-25.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">IL_smiles</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3src_embed_embedding0_fwd -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>transformer_3src_embed_embedding0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3117.21\" cy=\"-123\" rx=\"143.489\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3117.21\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3src_embed_embedding0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3src_embed_embedding0_fwd&#45;&gt;IL_smiles -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>transformer_3src_embed_embedding0_fwd&#45;&gt;IL_smiles</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3117.21,-83.7443C3117.21,-75.2043 3117.21,-66.2977 3117.21,-58.2479\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3117.21,-93.8971 3112.71,-83.897 3117.21,-88.8971 3117.21,-83.8971 3117.21,-83.8971 3117.21,-83.8971 3117.21,-88.8971 3121.71,-83.8971 3117.21,-93.8971 3117.21,-93.8971\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3src_embed_dropout0_identity0 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>transformer_3src_embed_dropout0_identity0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3117.21\" cy=\"-217\" rx=\"148.292\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3117.21\" y=\"-213.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3src_embed_dropout0_identity0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3src_embed_dropout0_identity0&#45;&gt;transformer_3src_embed_embedding0_fwd -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>transformer_3src_embed_dropout0_identity0&#45;&gt;transformer_3src_embed_embedding0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3117.21,-177.744C3117.21,-169.204 3117.21,-160.298 3117.21,-152.248\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3117.21,-187.897 3112.71,-177.897 3117.21,-182.897 3117.21,-177.897 3117.21,-177.897 3117.21,-177.897 3117.21,-182.897 3121.71,-177.897 3117.21,-187.897 3117.21,-187.897\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_arange_like0 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>transformer_3enc_arange_like0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2941.21\" cy=\"-311\" rx=\"104.058\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2941.21\" y=\"-307.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_arange_like0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_arange_like0&#45;&gt;transformer_3src_embed_dropout0_identity0 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>transformer_3enc_arange_like0&#45;&gt;transformer_3src_embed_dropout0_identity0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2997.81,-280.412C3019.99,-268.819 3045.23,-255.626 3066.77,-244.365\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2988.84,-285.103 2995.62,-276.483 2993.27,-282.787 2997.7,-280.471 2997.7,-280.471 2997.7,-280.471 2993.27,-282.787 2999.79,-284.459 2988.84,-285.103 2988.84,-285.103\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_reshape0 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>transformer_3enc_reshape0</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2941.21\" cy=\"-781\" rx=\"93.8617\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2941.21\" y=\"-777.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_reshape0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_reshape0&#45;&gt;transformer_3enc_arange_like0 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>transformer_3enc_reshape0&#45;&gt;transformer_3enc_arange_like0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2941.21,-741.948C2941.21,-704.354 2941.21,-645.211 2941.21,-594 2941.21,-594 2941.21,-594 2941.21,-498 2941.21,-441.974 2941.21,-376.455 2941.21,-340.045\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2941.21,-751.955 2936.71,-741.955 2941.21,-746.955 2941.21,-741.955 2941.21,-741.955 2941.21,-741.955 2941.21,-746.955 2945.71,-741.955 2941.21,-751.955 2941.21,-751.955\"/>\r\n",
       "</g>\r\n",
       "<!-- IL_valid_length -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>IL_valid_length</title>\r\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"2756.21\" cy=\"-875\" rx=\"56.7886\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2756.21\" y=\"-871.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">IL_valid_length</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_reshape1 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>transformer_3enc_reshape1</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2819.21\" cy=\"-969\" rx=\"93.8617\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2819.21\" y=\"-965.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_reshape1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_reshape1&#45;&gt;IL_valid_length -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>transformer_3enc_reshape1&#45;&gt;IL_valid_length</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2794.56,-932.008C2787.86,-922.222 2780.73,-911.801 2774.45,-902.635\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2800.31,-940.397 2790.95,-934.689 2797.48,-936.272 2794.66,-932.146 2794.66,-932.146 2794.66,-932.146 2797.48,-936.272 2798.37,-929.604 2800.31,-940.397 2800.31,-940.397\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_lesser0 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>transformer_3enc_broadcast_lesser0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2872.21\" cy=\"-1063\" rx=\"122.005\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2872.21\" y=\"-1059.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_broadcast_lesser0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_lesser0&#45;&gt;transformer_3enc_reshape0 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>transformer_3enc_broadcast_lesser0&#45;&gt;transformer_3enc_reshape0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2905.64,-1026.54C2912.19,-1017.8 2918.25,-1008.04 2922.21,-998 2947.27,-934.435 2946.34,-852.429 2943.69,-810.082\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2899.26,-1034.6 2901.94,-1023.96 2902.37,-1030.68 2905.47,-1026.76 2905.47,-1026.76 2905.47,-1026.76 2902.37,-1030.68 2909,-1029.55 2899.26,-1034.6 2899.26,-1034.6\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_lesser0&#45;&gt;transformer_3enc_reshape1 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>transformer_3enc_broadcast_lesser0&#45;&gt;transformer_3enc_reshape1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2850.88,-1024.98C2845.62,-1015.84 2840.07,-1006.22 2835.12,-997.615\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2856.02,-1033.9 2847.13,-1027.48 2853.52,-1029.56 2851.03,-1025.23 2851.03,-1025.23 2851.03,-1025.23 2853.52,-1029.56 2854.93,-1022.99 2856.02,-1033.9 2856.02,-1033.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_expand_dims0 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>transformer_3enc_expand_dims0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2872.21\" cy=\"-1157\" rx=\"111.219\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2872.21\" y=\"-1153.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_expand_dims0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_expand_dims0&#45;&gt;transformer_3enc_broadcast_lesser0 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>transformer_3enc_expand_dims0&#45;&gt;transformer_3enc_broadcast_lesser0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2872.21,-1117.74C2872.21,-1109.2 2872.21,-1100.3 2872.21,-1092.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2872.21,-1127.9 2867.71,-1117.9 2872.21,-1122.9 2872.21,-1117.9 2872.21,-1117.9 2872.21,-1117.9 2872.21,-1122.9 2876.71,-1117.9 2872.21,-1127.9 2872.21,-1127.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_ones_like0 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>transformer_3enc_ones_like0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2608.21\" cy=\"-969\" rx=\"99.2546\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2608.21\" y=\"-965.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_ones_like0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_ones_like0&#45;&gt;transformer_3enc_arange_like0 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>transformer_3enc_ones_like0&#45;&gt;transformer_3enc_arange_like0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2618.66,-929.951C2628,-892.587 2640.21,-833.814 2640.21,-782 2640.21,-782 2640.21,-782 2640.21,-498 2640.21,-396.488 2765.63,-348.527 2854.55,-327.28\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2616.12,-939.898 2614.24,-929.095 2617.36,-935.054 2618.6,-930.21 2618.6,-930.21 2618.6,-930.21 2617.36,-935.054 2622.96,-931.325 2616.12,-939.898 2616.12,-939.898\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_reshape2 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>transformer_3enc_reshape2</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2633.21\" cy=\"-1063\" rx=\"93.8617\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2633.21\" y=\"-1059.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_reshape2</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_reshape2&#45;&gt;transformer_3enc_ones_like0 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>transformer_3enc_reshape2&#45;&gt;transformer_3enc_ones_like0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2622.94,-1024.21C2620.55,-1015.42 2618.05,-1006.21 2615.8,-997.931\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2625.57,-1033.9 2618.61,-1025.43 2624.26,-1029.07 2622.95,-1024.25 2622.95,-1024.25 2622.95,-1024.25 2624.26,-1029.07 2627.29,-1023.07 2625.57,-1033.9 2625.57,-1033.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_mul0 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>transformer_3enc_broadcast_mul0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2627.21\" cy=\"-1157\" rx=\"115.434\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2627.21\" y=\"-1153.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_broadcast_mul0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_mul0&#45;&gt;transformer_3enc_ones_like0 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>transformer_3enc_broadcast_mul0&#45;&gt;transformer_3enc_ones_like0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2562.11,-1125.99C2549.32,-1116.95 2537.58,-1105.7 2530.21,-1092 2517.99,-1069.3 2519.19,-1057.3 2530.21,-1034 2537.55,-1018.48 2550.7,-1005.47 2564.14,-995.311\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2570.64,-1131.61 2559.81,-1129.86 2566.46,-1128.86 2562.29,-1126.11 2562.29,-1126.11 2562.29,-1126.11 2566.46,-1128.86 2564.77,-1122.35 2570.64,-1131.61 2570.64,-1131.61\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_mul0&#45;&gt;transformer_3enc_reshape2 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>transformer_3enc_broadcast_mul0&#45;&gt;transformer_3enc_reshape2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2629.71,-1117.74C2630.26,-1109.2 2630.84,-1100.3 2631.37,-1092.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2629.04,-1127.9 2625.2,-1117.63 2629.37,-1122.91 2629.69,-1117.92 2629.69,-1117.92 2629.69,-1117.92 2629.37,-1122.91 2634.18,-1118.21 2629.04,-1127.9 2629.04,-1127.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_mul1 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>transformer_3enc_broadcast_mul1</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2662.21\" cy=\"-1251\" rx=\"115.434\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2662.21\" y=\"-1247.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_broadcast_mul1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_mul1&#45;&gt;transformer_3enc_expand_dims0 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>transformer_3enc_broadcast_mul1&#45;&gt;transformer_3enc_expand_dims0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2727.1,-1221.57C2755.88,-1208.96 2789.39,-1194.28 2816.95,-1182.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2717.94,-1225.59 2725.29,-1217.45 2722.52,-1223.58 2727.09,-1221.57 2727.09,-1221.57 2727.09,-1221.57 2722.52,-1223.58 2728.9,-1225.7 2717.94,-1225.59 2717.94,-1225.59\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_mul1&#45;&gt;transformer_3enc_broadcast_mul0 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>transformer_3enc_broadcast_mul1&#45;&gt;transformer_3enc_broadcast_mul0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2647.94,-1212.5C2644.57,-1203.62 2641.02,-1194.3 2637.84,-1185.93\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2651.52,-1221.9 2643.76,-1214.15 2649.74,-1217.22 2647.96,-1212.55 2647.96,-1212.55 2647.96,-1212.55 2649.74,-1217.22 2652.17,-1210.95 2651.52,-1221.9 2651.52,-1221.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_expand_dims0 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_expand_dims0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2710.21\" cy=\"-6139\" rx=\"226.653\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2710.21\" y=\"-6135.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_expand_dims0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_expand_dims0&#45;&gt;transformer_3enc_broadcast_mul1 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_expand_dims0&#45;&gt;transformer_3enc_broadcast_mul1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2681.98,-6101.7C2656.91,-6065.77 2624.21,-6008.16 2624.21,-5952 2624.21,-5952 2624.21,-5952 2624.21,-1438 2624.21,-1380.98 2641.56,-1316.08 2652.82,-1280\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2687.84,-6109.91 2678.37,-6104.39 2684.93,-6105.85 2682.03,-6101.78 2682.03,-6101.78 2682.03,-6101.78 2684.93,-6105.85 2685.69,-6099.16 2687.84,-6109.91 2687.84,-6109.91\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_broadcast_axis0 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_broadcast_axis0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2716.21\" cy=\"-6609\" rx=\"232.046\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2716.21\" y=\"-6605.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_broadcast_axis0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_broadcast_axis0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_expand_dims0 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_broadcast_axis0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_expand_dims0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2714.27,-6569.96C2712.51,-6532.37 2710.21,-6473.24 2710.21,-6422 2710.21,-6422 2710.21,-6422 2710.21,-6326 2710.21,-6269.97 2710.21,-6204.46 2710.21,-6168.04\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2714.74,-6579.96 2709.77,-6570.19 2714.5,-6574.97 2714.27,-6569.98 2714.27,-6569.98 2714.27,-6569.98 2714.5,-6574.97 2718.76,-6569.76 2714.74,-6579.96 2714.74,-6579.96\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape4 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape4</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2721.21\" cy=\"-6797\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2721.21\" y=\"-6793.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_reshape4</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape4&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_broadcast_axis0 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape4&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_broadcast_axis0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2720.18,-6757.75C2719.23,-6722.21 2717.83,-6670.1 2716.97,-6638.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2720.45,-6767.75 2715.68,-6757.88 2720.32,-6762.75 2720.18,-6757.75 2720.18,-6757.75 2720.18,-6757.75 2720.32,-6762.75 2724.68,-6757.63 2720.45,-6767.75 2720.45,-6767.75\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_expand_dims0 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_expand_dims0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2879.21\" cy=\"-3507\" rx=\"226.653\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2879.21\" y=\"-3503.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_expand_dims0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_expand_dims0&#45;&gt;transformer_3enc_broadcast_mul1 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_expand_dims0&#45;&gt;transformer_3enc_broadcast_mul1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2798.47,-3475.05C2736.76,-3445.53 2662.21,-3394.45 2662.21,-3320 2662.21,-3320 2662.21,-3320 2662.21,-1438 2662.21,-1381.97 2662.21,-1316.46 2662.21,-1280.04\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2807.86,-3479.43 2796.89,-3479.28 2803.32,-3477.31 2798.79,-3475.2 2798.79,-3475.2 2798.79,-3475.2 2803.32,-3477.31 2800.69,-3471.12 2807.86,-3479.43 2807.86,-3479.43\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_broadcast_axis0 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_broadcast_axis0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2887.21\" cy=\"-3977\" rx=\"232.046\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2887.21\" y=\"-3973.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_broadcast_axis0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_broadcast_axis0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_expand_dims0 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_broadcast_axis0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_expand_dims0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2884.62,-3937.97C2882.28,-3900.39 2879.21,-3841.26 2879.21,-3790 2879.21,-3790 2879.21,-3790 2879.21,-3694 2879.21,-3637.97 2879.21,-3572.46 2879.21,-3536.04\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2885.25,-3947.97 2880.13,-3938.28 2884.94,-3942.98 2884.62,-3937.99 2884.62,-3937.99 2884.62,-3937.99 2884.94,-3942.98 2889.11,-3937.71 2885.25,-3947.97 2885.25,-3947.97\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape4 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape4</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2902.21\" cy=\"-4165\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2902.21\" y=\"-4161.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_reshape4</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape4&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_broadcast_axis0 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape4&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_broadcast_axis0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2899.13,-4125.75C2896.26,-4090.21 2892.06,-4038.1 2889.49,-4006.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2899.93,-4135.75 2894.64,-4126.14 2899.53,-4130.77 2899.13,-4125.78 2899.13,-4125.78 2899.13,-4125.78 2899.53,-4130.77 2903.61,-4125.42 2899.93,-4135.75 2899.93,-4135.75\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_expand_dims0 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_expand_dims0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2920.21\" cy=\"-1345\" rx=\"226.653\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2920.21\" y=\"-1341.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_expand_dims0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_expand_dims0&#45;&gt;transformer_3enc_broadcast_mul1 -->\r\n",
       "<g id=\"edge21\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_expand_dims0&#45;&gt;transformer_3enc_broadcast_mul1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2836.1,-1314.01C2800.73,-1301.4 2760.22,-1286.95 2727.2,-1275.18\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2845.93,-1317.51 2835,-1318.39 2841.22,-1315.83 2836.51,-1314.15 2836.51,-1314.15 2836.51,-1314.15 2841.22,-1315.83 2838.02,-1309.92 2845.93,-1317.51 2845.93,-1317.51\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_broadcast_axis0 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_broadcast_axis0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2922.21\" cy=\"-1439\" rx=\"232.046\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2922.21\" y=\"-1435.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_broadcast_axis0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_broadcast_axis0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_expand_dims0 -->\r\n",
       "<g id=\"edge22\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_broadcast_axis0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_expand_dims0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2921.38,-1399.74C2921.19,-1391.2 2921,-1382.3 2920.82,-1374.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2921.6,-1409.9 2916.88,-1400 2921.49,-1404.9 2921.38,-1399.9 2921.38,-1399.9 2921.38,-1399.9 2921.49,-1404.9 2925.88,-1399.8 2921.6,-1409.9 2921.6,-1409.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape4 -->\r\n",
       "<g id=\"node22\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape4</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3419.21\" cy=\"-1533\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3419.21\" y=\"-1529.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_reshape4</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape4&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_broadcast_axis0 -->\r\n",
       "<g id=\"edge23\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape4&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_broadcast_axis0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3287.15,-1507.56C3213.28,-1493.88 3121.67,-1476.92 3048.72,-1463.42\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3296.99,-1509.38 3286.34,-1511.98 3292.08,-1508.47 3287.16,-1507.56 3287.16,-1507.56 3287.16,-1507.56 3292.08,-1508.47 3287.98,-1503.13 3296.99,-1509.38 3296.99,-1509.38\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc__mulscalar0 -->\r\n",
       "<g id=\"node23\" class=\"node\"><title>transformer_3enc__mulscalar0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3330.21\" cy=\"-405\" rx=\"102.88\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3330.21\" y=\"-401.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc__mulscalar0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc__mulscalar0&#45;&gt;transformer_3src_embed_dropout0_identity0 -->\r\n",
       "<g id=\"edge24\" class=\"edge\"><title>transformer_3enc__mulscalar0&#45;&gt;transformer_3src_embed_dropout0_identity0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3308.93,-367.723C3292.2,-341.491 3266.97,-306.498 3238.21,-282 3220.3,-266.743 3198.15,-253.715 3177.71,-243.474\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3314.27,-376.256 3305.15,-370.167 3311.62,-372.017 3308.96,-367.779 3308.96,-367.779 3308.96,-367.779 3311.62,-372.017 3312.78,-365.392 3314.27,-376.256 3314.27,-376.256\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_const -->\r\n",
       "<g id=\"node24\" class=\"node\"><title>transformer_3enc_const</title>\r\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"3146.21\" cy=\"-311\" rx=\"83.1648\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3146.21\" y=\"-307.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_const</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_embedding0 -->\r\n",
       "<g id=\"node25\" class=\"node\"><title>transformer_3enc_embedding0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3105.21\" cy=\"-405\" rx=\"104.058\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3105.21\" y=\"-401.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_embedding0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_embedding0&#45;&gt;transformer_3enc_arange_like0 -->\r\n",
       "<g id=\"edge25\" class=\"edge\"><title>transformer_3enc_embedding0&#45;&gt;transformer_3enc_arange_like0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3051.15,-373.674C3030.15,-361.892 3006.37,-348.552 2986.31,-337.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3059.96,-378.617 3049.04,-377.649 3055.6,-376.171 3051.24,-373.724 3051.24,-373.724 3051.24,-373.724 3055.6,-376.171 3053.44,-369.8 3059.96,-378.617 3059.96,-378.617\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_embedding0&#45;&gt;transformer_3enc_const -->\r\n",
       "<g id=\"edge26\" class=\"edge\"><title>transformer_3enc_embedding0&#45;&gt;transformer_3enc_const</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3121.92,-366.498C3125.88,-357.618 3130.03,-348.3 3133.76,-339.931\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3117.73,-375.897 3117.69,-364.931 3119.77,-371.33 3121.81,-366.763 3121.81,-366.763 3121.81,-366.763 3119.77,-371.33 3125.92,-368.595 3117.73,-375.897 3117.73,-375.897\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_expand_dims1 -->\r\n",
       "<g id=\"node26\" class=\"node\"><title>transformer_3enc_expand_dims1</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3152.21\" cy=\"-499\" rx=\"111.219\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3152.21\" y=\"-495.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_expand_dims1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_expand_dims1&#45;&gt;transformer_3enc_embedding0 -->\r\n",
       "<g id=\"edge27\" class=\"edge\"><title>transformer_3enc_expand_dims1&#45;&gt;transformer_3enc_embedding0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3133.2,-460.782C3128.62,-451.817 3123.8,-442.389 3119.48,-433.931\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3137.85,-469.897 3129.3,-463.039 3135.58,-465.444 3133.3,-460.992 3133.3,-460.992 3133.3,-460.992 3135.58,-465.444 3137.31,-458.945 3137.85,-469.897 3137.85,-469.897\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_add0 -->\r\n",
       "<g id=\"node27\" class=\"node\"><title>transformer_3enc_broadcast_add0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3330.21\" cy=\"-593\" rx=\"116.023\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3330.21\" y=\"-589.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_broadcast_add0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_add0&#45;&gt;transformer_3enc__mulscalar0 -->\r\n",
       "<g id=\"edge28\" class=\"edge\"><title>transformer_3enc_broadcast_add0&#45;&gt;transformer_3enc__mulscalar0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3330.21,-553.746C3330.21,-518.206 3330.21,-466.104 3330.21,-434.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3330.21,-563.751 3325.71,-553.751 3330.21,-558.751 3330.21,-553.751 3330.21,-553.751 3330.21,-553.751 3330.21,-558.751 3334.71,-553.751 3330.21,-563.751 3330.21,-563.751\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_broadcast_add0&#45;&gt;transformer_3enc_expand_dims1 -->\r\n",
       "<g id=\"edge29\" class=\"edge\"><title>transformer_3enc_broadcast_add0&#45;&gt;transformer_3enc_expand_dims1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3272.11,-561.969C3249.07,-550.06 3222.87,-536.52 3200.85,-525.141\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3281.1,-566.617 3270.15,-566.023 3276.66,-564.321 3272.22,-562.025 3272.22,-562.025 3272.22,-562.025 3276.66,-564.321 3274.28,-558.028 3281.1,-566.617 3281.1,-566.617\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_dropout0_fwd -->\r\n",
       "<g id=\"node28\" class=\"node\"><title>transformer_3enc_dropout0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3393.21\" cy=\"-687\" rx=\"110.63\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3393.21\" y=\"-683.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_dropout0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_dropout0_fwd&#45;&gt;transformer_3enc_broadcast_add0 -->\r\n",
       "<g id=\"edge30\" class=\"edge\"><title>transformer_3enc_dropout0_fwd&#45;&gt;transformer_3enc_broadcast_add0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3368.58,-650.027C3362.18,-640.683 3355.38,-630.76 3349.32,-621.902\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3374.31,-658.397 3364.95,-652.689 3371.48,-654.272 3368.66,-650.146 3368.66,-650.146 3368.66,-650.146 3371.48,-654.272 3372.37,-647.604 3374.31,-658.397 3374.31,-658.397\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_layernorm0_layernorm0 -->\r\n",
       "<g id=\"node29\" class=\"node\"><title>transformer_3enc_layernorm0_layernorm0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3425.21\" cy=\"-781\" rx=\"138.185\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3425.21\" y=\"-777.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_layernorm0_layernorm0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_layernorm0_layernorm0&#45;&gt;transformer_3enc_dropout0_fwd -->\r\n",
       "<g id=\"edge31\" class=\"edge\"><title>transformer_3enc_layernorm0_layernorm0&#45;&gt;transformer_3enc_dropout0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3412.07,-742.215C3409.01,-733.42 3405.81,-724.211 3402.93,-715.931\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3415.44,-751.897 3407.9,-743.93 3413.79,-747.175 3412.15,-742.452 3412.15,-742.452 3412.15,-742.452 3413.79,-747.175 3416.4,-740.974 3415.44,-751.897 3415.44,-751.897\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_query_fwd -->\r\n",
       "<g id=\"node30\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_query_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3674.21\" cy=\"-875\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3674.21\" y=\"-878.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3674.21\" y=\"-863.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_query_fwd&#45;&gt;transformer_3enc_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge32\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_query_fwd&#45;&gt;transformer_3enc_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3613.6,-851.605C3576.74,-837.986 3529.63,-820.581 3491.74,-806.582\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3623.22,-855.16 3612.28,-855.916 3618.53,-853.428 3613.84,-851.695 3613.84,-851.695 3613.84,-851.695 3618.53,-853.428 3615.4,-847.473 3623.22,-855.16 3623.22,-855.16\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape0 -->\r\n",
       "<g id=\"node31\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape0</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3766.21\" cy=\"-969\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3766.21\" y=\"-965.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_reshape0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_query_fwd -->\r\n",
       "<g id=\"edge33\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_query_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3730.86,-932.646C3720.68,-922.468 3709.76,-911.553 3700.26,-902.048\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3738.11,-939.897 3727.85,-936.008 3734.57,-936.362 3731.04,-932.826 3731.04,-932.826 3731.04,-932.826 3734.57,-936.362 3734.22,-929.644 3738.11,-939.897 3738.11,-939.897\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_transpose0 -->\r\n",
       "<g id=\"node32\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_transpose0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3869.21\" cy=\"-1063\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3869.21\" y=\"-1059.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_transpose0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_transpose0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape0 -->\r\n",
       "<g id=\"edge34\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_transpose0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3830.26,-1027.21C3819.36,-1017.48 3807.67,-1007.03 3797.29,-997.758\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3838.03,-1034.15 3827.57,-1030.84 3834.3,-1030.82 3830.57,-1027.49 3830.57,-1027.49 3830.57,-1027.49 3834.3,-1030.82 3833.57,-1024.13 3838.03,-1034.15 3838.03,-1034.15\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape1 -->\r\n",
       "<g id=\"node33\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape1</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3871.21\" cy=\"-1157\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3871.21\" y=\"-1153.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_reshape1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape1&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_transpose0 -->\r\n",
       "<g id=\"edge35\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape1&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3870.38,-1117.74C3870.19,-1109.2 3870,-1100.3 3869.82,-1092.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3870.6,-1127.9 3865.88,-1118 3870.49,-1122.9 3870.38,-1117.9 3870.38,-1117.9 3870.38,-1117.9 3870.49,-1122.9 3874.88,-1117.8 3870.6,-1127.9 3870.6,-1127.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_div_sqrt_dim0 -->\r\n",
       "<g id=\"node34\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_div_sqrt_dim0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3876.21\" cy=\"-1251\" rx=\"226.653\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3876.21\" y=\"-1247.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_div_sqrt_dim0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_div_sqrt_dim0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape1 -->\r\n",
       "<g id=\"edge36\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_div_sqrt_dim0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3874.13,-1211.74C3873.67,-1203.2 3873.18,-1194.3 3872.75,-1186.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3874.68,-1221.9 3869.65,-1212.16 3874.41,-1216.9 3874.14,-1211.91 3874.14,-1211.91 3874.14,-1211.91 3874.41,-1216.9 3878.63,-1211.67 3874.68,-1221.9 3874.68,-1221.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_key_fwd -->\r\n",
       "<g id=\"node35\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_key_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3425.21\" cy=\"-875\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3425.21\" y=\"-878.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3425.21\" y=\"-863.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_key_fwd&#45;&gt;transformer_3enc_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge37\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_key_fwd&#45;&gt;transformer_3enc_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3425.21,-835.744C3425.21,-827.204 3425.21,-818.298 3425.21,-810.248\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3425.21,-845.897 3420.71,-835.897 3425.21,-840.897 3425.21,-835.897 3425.21,-835.897 3425.21,-835.897 3425.21,-840.897 3429.71,-835.897 3425.21,-845.897 3425.21,-845.897\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape2 -->\r\n",
       "<g id=\"node36\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape2</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3425.21\" cy=\"-1063\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3425.21\" y=\"-1059.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_reshape2</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape2&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_key_fwd -->\r\n",
       "<g id=\"edge38\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape2&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_key_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3425.21,-1023.75C3425.21,-988.206 3425.21,-936.104 3425.21,-904.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3425.21,-1033.75 3420.71,-1023.75 3425.21,-1028.75 3425.21,-1023.75 3425.21,-1023.75 3425.21,-1023.75 3425.21,-1028.75 3429.71,-1023.75 3425.21,-1033.75 3425.21,-1033.75\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_transpose1 -->\r\n",
       "<g id=\"node37\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_transpose1</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3425.21\" cy=\"-1157\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3425.21\" y=\"-1153.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_transpose1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_transpose1&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape2 -->\r\n",
       "<g id=\"edge39\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_transpose1&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3425.21,-1117.74C3425.21,-1109.2 3425.21,-1100.3 3425.21,-1092.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3425.21,-1127.9 3420.71,-1117.9 3425.21,-1122.9 3425.21,-1117.9 3425.21,-1117.9 3425.21,-1117.9 3425.21,-1122.9 3429.71,-1117.9 3425.21,-1127.9 3425.21,-1127.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape3 -->\r\n",
       "<g id=\"node38\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape3</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3422.21\" cy=\"-1251\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3422.21\" y=\"-1247.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_reshape3</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape3&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_transpose1 -->\r\n",
       "<g id=\"edge40\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape3&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_transpose1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3423.46,-1211.74C3423.74,-1203.2 3424.03,-1194.3 3424.29,-1186.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3423.13,-1221.9 3418.96,-1211.76 3423.29,-1216.9 3423.45,-1211.9 3423.45,-1211.9 3423.45,-1211.9 3423.29,-1216.9 3427.95,-1212.05 3423.13,-1221.9 3423.13,-1221.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_batch_dot0 -->\r\n",
       "<g id=\"node39\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_batch_dot0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3768.21\" cy=\"-1345\" rx=\"216.546\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3768.21\" y=\"-1341.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_batch_dot0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_div_sqrt_dim0 -->\r\n",
       "<g id=\"edge41\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_div_sqrt_dim0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3808.72,-1309.49C3820.24,-1299.68 3832.64,-1289.12 3843.62,-1279.76\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3800.91,-1316.15 3805.6,-1306.24 3804.71,-1312.9 3808.52,-1309.66 3808.52,-1309.66 3808.52,-1309.66 3804.71,-1312.9 3811.44,-1313.09 3800.91,-1316.15 3800.91,-1316.15\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape3 -->\r\n",
       "<g id=\"edge42\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3663.76,-1316.23C3616.76,-1303.73 3561.71,-1289.09 3516.04,-1276.95\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3673.66,-1318.86 3662.84,-1320.64 3668.83,-1317.58 3664,-1316.29 3664,-1316.29 3664,-1316.29 3668.83,-1317.58 3665.16,-1311.94 3673.66,-1318.86 3673.66,-1318.86\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_ones_like0 -->\r\n",
       "<g id=\"node40\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_ones_like0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3900.21\" cy=\"-1439\" rx=\"214.688\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3900.21\" y=\"-1435.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_ones_like0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_ones_like0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_batch_dot0 -->\r\n",
       "<g id=\"edge43\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_ones_like0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_batch_dot0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3852.19,-1404.53C3837.6,-1394.36 3821.75,-1383.32 3807.79,-1373.58\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3860.61,-1410.4 3849.83,-1408.37 3856.5,-1407.54 3852.4,-1404.68 3852.4,-1404.68 3852.4,-1404.68 3856.5,-1407.54 3854.98,-1400.99 3860.61,-1410.4 3860.61,-1410.4\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0__mulscalar0 -->\r\n",
       "<g id=\"node41\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0__mulscalar0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3902.21\" cy=\"-1533\" rx=\"218.313\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3902.21\" y=\"-1529.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0__mulscalar0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0__mulscalar0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_ones_like0 -->\r\n",
       "<g id=\"edge44\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0__mulscalar0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_ones_like0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3901.38,-1493.74C3901.19,-1485.2 3901,-1476.3 3900.82,-1468.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3901.6,-1503.9 3896.88,-1494 3901.49,-1498.9 3901.38,-1493.9 3901.38,-1493.9 3901.38,-1493.9 3901.49,-1498.9 3905.88,-1493.8 3901.6,-1503.9 3901.6,-1503.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_where0 -->\r\n",
       "<g id=\"node42\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_where0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3656.21\" cy=\"-1627\" rx=\"203.902\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3656.21\" y=\"-1623.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_where0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape4 -->\r\n",
       "<g id=\"edge45\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3578.88,-1595.98C3549.43,-1584.55 3516.1,-1571.61 3487.55,-1560.53\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3588.3,-1599.64 3577.35,-1600.21 3583.63,-1597.83 3578.97,-1596.02 3578.97,-1596.02 3578.97,-1596.02 3583.63,-1597.83 3580.6,-1591.82 3588.3,-1599.64 3588.3,-1599.64\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_batch_dot0 -->\r\n",
       "<g id=\"edge46\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_batch_dot0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3650.53,-1587.8C3645.73,-1542.21 3644.02,-1465.24 3676.21,-1410 3684.93,-1395.04 3698.71,-1382.74 3712.97,-1373.07\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3651.7,-1597.85 3646.08,-1588.43 3651.12,-1592.88 3650.55,-1587.92 3650.55,-1587.92 3650.55,-1587.92 3651.12,-1592.88 3655.02,-1587.4 3651.7,-1597.85 3651.7,-1597.85\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0__mulscalar0 -->\r\n",
       "<g id=\"edge47\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0__mulscalar0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3735.75,-1596.25C3766.44,-1584.78 3801.26,-1571.75 3831.1,-1560.59\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3726.37,-1599.76 3734.17,-1592.04 3731.06,-1598.01 3735.74,-1596.26 3735.74,-1596.26 3735.74,-1596.26 3731.06,-1598.01 3737.32,-1600.47 3726.37,-1599.76 3726.37,-1599.76\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_softmax0 -->\r\n",
       "<g id=\"node43\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_softmax0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3657.21\" cy=\"-1721\" rx=\"210.474\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3657.21\" y=\"-1717.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_softmax0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_softmax0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_where0 -->\r\n",
       "<g id=\"edge48\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_softmax0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_where0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3656.79,-1681.74C3656.7,-1673.2 3656.6,-1664.3 3656.52,-1656.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3656.9,-1691.9 3652.3,-1681.95 3656.85,-1686.9 3656.8,-1681.9 3656.8,-1681.9 3656.8,-1681.9 3656.85,-1686.9 3661.3,-1681.85 3656.9,-1691.9 3656.9,-1691.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0__mul0 -->\r\n",
       "<g id=\"node44\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0__mul0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3649.21\" cy=\"-1815\" rx=\"200.955\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3649.21\" y=\"-1811.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0__mul0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape4 -->\r\n",
       "<g id=\"edge50\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3494.79,-1791.04C3473.06,-1781.54 3453.1,-1768.33 3438.21,-1750 3394.31,-1695.94 3403.94,-1607.21 3412.65,-1562.15\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3504.2,-1794.89 3493.24,-1795.27 3499.57,-1793 3494.94,-1791.1 3494.94,-1791.1 3494.94,-1791.1 3499.57,-1793 3496.65,-1786.94 3504.2,-1794.89 3504.2,-1794.89\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_softmax0 -->\r\n",
       "<g id=\"edge49\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_softmax0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3652.54,-1775.74C3653.28,-1767.2 3654.05,-1758.3 3654.75,-1750.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3651.65,-1785.9 3648.04,-1775.54 3652.09,-1780.92 3652.52,-1775.93 3652.52,-1775.93 3652.52,-1775.93 3652.09,-1780.92 3657,-1776.32 3651.65,-1785.9 3651.65,-1785.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_dotproductattentioncell0_dropout0_fwd -->\r\n",
       "<g id=\"node45\" class=\"node\"><title>transformer_3enc_transformer0_dotproductattentioncell0_dropout0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3649.21\" cy=\"-1909\" rx=\"231.457\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3649.21\" y=\"-1905.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_dotproductattentioncell0_dropout0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_dotproductattentioncell0_dropout0_fwd&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0__mul0 -->\r\n",
       "<g id=\"edge51\" class=\"edge\"><title>transformer_3enc_transformer0_dotproductattentioncell0_dropout0_fwd&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0__mul0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3649.21,-1869.74C3649.21,-1861.2 3649.21,-1852.3 3649.21,-1844.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3649.21,-1879.9 3644.71,-1869.9 3649.21,-1874.9 3649.21,-1869.9 3649.21,-1869.9 3649.21,-1869.9 3649.21,-1874.9 3653.71,-1869.9 3649.21,-1879.9 3649.21,-1879.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape5 -->\r\n",
       "<g id=\"node46\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape5</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3649.21\" cy=\"-2003\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3649.21\" y=\"-1999.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_reshape5</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape5&#45;&gt;transformer_3enc_transformer0_dotproductattentioncell0_dropout0_fwd -->\r\n",
       "<g id=\"edge52\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape5&#45;&gt;transformer_3enc_transformer0_dotproductattentioncell0_dropout0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3649.21,-1963.74C3649.21,-1955.2 3649.21,-1946.3 3649.21,-1938.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3649.21,-1973.9 3644.71,-1963.9 3649.21,-1968.9 3649.21,-1963.9 3649.21,-1963.9 3649.21,-1963.9 3649.21,-1968.9 3653.71,-1963.9 3649.21,-1973.9 3649.21,-1973.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape6 -->\r\n",
       "<g id=\"node47\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape6</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3649.21\" cy=\"-2097\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3649.21\" y=\"-2093.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_reshape6</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape6&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape5 -->\r\n",
       "<g id=\"edge53\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape6&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3649.21,-2057.74C3649.21,-2049.2 3649.21,-2040.3 3649.21,-2032.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3649.21,-2067.9 3644.71,-2057.9 3649.21,-2062.9 3649.21,-2057.9 3649.21,-2057.9 3649.21,-2057.9 3649.21,-2062.9 3653.71,-2057.9 3649.21,-2067.9 3649.21,-2067.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_value_fwd -->\r\n",
       "<g id=\"node48\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_value_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3186.21\" cy=\"-1721\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3186.21\" y=\"-1724.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3186.21\" y=\"-1709.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_value_fwd&#45;&gt;transformer_3enc_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge54\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_value_fwd&#45;&gt;transformer_3enc_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3184.91,-1681.95C3183.75,-1644.36 3182.21,-1585.22 3182.21,-1534 3182.21,-1534 3182.21,-1534 3182.21,-968 3182.21,-883.129 3276.84,-831.751 3347.99,-805.115\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3185.23,-1691.96 3180.42,-1682.11 3185.07,-1686.96 3184.91,-1681.96 3184.91,-1681.96 3184.91,-1681.96 3185.07,-1686.96 3189.41,-1681.82 3185.23,-1691.96 3185.23,-1691.96\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape7 -->\r\n",
       "<g id=\"node49\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape7</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3189.21\" cy=\"-1909\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3189.21\" y=\"-1905.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_reshape7</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape7&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_value_fwd -->\r\n",
       "<g id=\"edge55\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape7&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_value_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3188.59,-1869.75C3188.02,-1834.21 3187.18,-1782.1 3186.67,-1750.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3188.75,-1879.75 3184.09,-1869.82 3188.67,-1874.75 3188.59,-1869.75 3188.59,-1869.75 3188.59,-1869.75 3188.67,-1874.75 3193.09,-1869.68 3188.75,-1879.75 3188.75,-1879.75\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_transpose2 -->\r\n",
       "<g id=\"node50\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_transpose2</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3197.21\" cy=\"-2003\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3197.21\" y=\"-1999.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_transpose2</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_transpose2&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape7 -->\r\n",
       "<g id=\"edge56\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_transpose2&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3193.88,-1963.74C3193.14,-1955.2 3192.37,-1946.3 3191.67,-1938.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3194.77,-1973.9 3189.42,-1964.32 3194.33,-1968.92 3193.9,-1963.93 3193.9,-1963.93 3193.9,-1963.93 3194.33,-1968.92 3198.38,-1963.54 3194.77,-1973.9 3194.77,-1973.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape8 -->\r\n",
       "<g id=\"node51\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape8</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3212.21\" cy=\"-2097\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3212.21\" y=\"-2093.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_reshape8</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape8&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_transpose2 -->\r\n",
       "<g id=\"edge57\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape8&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_transpose2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3206.02,-2058.03C3204.61,-2049.4 3203.14,-2040.39 3201.82,-2032.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3207.63,-2067.9 3201.58,-2058.75 3206.82,-2062.96 3206.02,-2058.03 3206.02,-2058.03 3206.02,-2058.03 3206.82,-2062.96 3210.46,-2057.3 3207.63,-2067.9 3207.63,-2067.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_batch_dot1 -->\r\n",
       "<g id=\"node52\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_batch_dot1</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3649.21\" cy=\"-2191\" rx=\"216.546\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3649.21\" y=\"-2187.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_batch_dot1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape6 -->\r\n",
       "<g id=\"edge58\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3649.21,-2151.74C3649.21,-2143.2 3649.21,-2134.3 3649.21,-2126.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3649.21,-2161.9 3644.71,-2151.9 3649.21,-2156.9 3649.21,-2151.9 3649.21,-2151.9 3649.21,-2151.9 3649.21,-2156.9 3653.71,-2151.9 3649.21,-2161.9 3649.21,-2161.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape8 -->\r\n",
       "<g id=\"edge59\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3526.04,-2164.07C3462.6,-2150.71 3385.82,-2134.55 3324.09,-2121.55\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3536.1,-2166.19 3525.39,-2168.53 3531.21,-2165.16 3526.32,-2164.13 3526.32,-2164.13 3526.32,-2164.13 3531.21,-2165.16 3527.25,-2159.72 3536.1,-2166.19 3536.1,-2166.19\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape9 -->\r\n",
       "<g id=\"node53\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape9</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3655.21\" cy=\"-2285\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3655.21\" y=\"-2281.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_reshape9</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape9&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_batch_dot1 -->\r\n",
       "<g id=\"edge60\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape9&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_batch_dot1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3652.72,-2245.74C3652.16,-2237.2 3651.58,-2228.3 3651.05,-2220.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3653.38,-2255.9 3648.24,-2246.21 3653.05,-2250.91 3652.73,-2245.92 3652.73,-2245.92 3652.73,-2245.92 3653.05,-2250.91 3657.22,-2245.63 3653.38,-2255.9 3653.38,-2255.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_transpose3 -->\r\n",
       "<g id=\"node54\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_transpose3</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3667.21\" cy=\"-2379\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3667.21\" y=\"-2375.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_transpose3</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_transpose3&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape9 -->\r\n",
       "<g id=\"edge61\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_transpose3&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3662.22,-2339.74C3661.11,-2331.2 3659.94,-2322.3 3658.89,-2314.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3663.54,-2349.9 3657.79,-2340.56 3662.9,-2344.94 3662.25,-2339.98 3662.25,-2339.98 3662.25,-2339.98 3662.9,-2344.94 3666.71,-2339.4 3663.54,-2349.9 3663.54,-2349.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape10 -->\r\n",
       "<g id=\"node55\" class=\"node\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape10</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3692.21\" cy=\"-2473\" rx=\"212.92\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3692.21\" y=\"-2469.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_multiheadattentioncell0_reshape10</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_multiheadattentioncell0_reshape10&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_transpose3 -->\r\n",
       "<g id=\"edge62\" class=\"edge\"><title>transformer_3enc_transformer0_multiheadattentioncell0_reshape10&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_transpose3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3681.89,-2434.03C3679.55,-2425.4 3677.1,-2416.39 3674.89,-2408.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3684.57,-2443.9 3677.61,-2435.43 3683.26,-2439.07 3681.95,-2434.25 3681.95,-2434.25 3681.95,-2434.25 3683.26,-2439.07 3686.29,-2433.07 3684.57,-2443.9 3684.57,-2443.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_proj_fwd -->\r\n",
       "<g id=\"node56\" class=\"node\"><title>transformer_3enc_transformer0_proj_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3742.21\" cy=\"-2567\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3742.21\" y=\"-2570.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3742.21\" y=\"-2555.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_proj_fwd&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape10 -->\r\n",
       "<g id=\"edge63\" class=\"edge\"><title>transformer_3enc_transformer0_proj_fwd&#45;&gt;transformer_3enc_transformer0_multiheadattentioncell0_reshape10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3722.39,-2529.54C3717.46,-2520.45 3712.23,-2510.84 3707.55,-2502.22\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3727.21,-2538.4 3718.48,-2531.76 3724.82,-2534 3722.43,-2529.61 3722.43,-2529.61 3722.43,-2529.61 3724.82,-2534 3726.39,-2527.46 3727.21,-2538.4 3727.21,-2538.4\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_dropout0_fwd -->\r\n",
       "<g id=\"node57\" class=\"node\"><title>transformer_3enc_transformer0_dropout0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3841.21\" cy=\"-2661\" rx=\"153.685\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3841.21\" y=\"-2657.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_dropout0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_dropout0_fwd&#45;&gt;transformer_3enc_transformer0_proj_fwd -->\r\n",
       "<g id=\"edge64\" class=\"edge\"><title>transformer_3enc_transformer0_dropout0_fwd&#45;&gt;transformer_3enc_transformer0_proj_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3803.87,-2625.3C3792.58,-2614.81 3780.4,-2603.49 3769.86,-2593.7\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3811.51,-2632.4 3801.12,-2628.89 3807.84,-2628.99 3804.18,-2625.59 3804.18,-2625.59 3804.18,-2625.59 3807.84,-2628.99 3807.25,-2622.29 3811.51,-2632.4 3811.51,-2632.4\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0__plus0 -->\r\n",
       "<g id=\"node58\" class=\"node\"><title>transformer_3enc_transformer0__plus0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3843.21\" cy=\"-2755\" rx=\"130.345\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3843.21\" y=\"-2751.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0__plus0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0__plus0&#45;&gt;transformer_3enc_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge66\" class=\"edge\"><title>transformer_3enc_transformer0__plus0&#45;&gt;transformer_3enc_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3952.41,-2733.77C4039.93,-2710.5 4148.21,-2662.6 4148.21,-2568 4148.21,-2568 4148.21,-2568 4148.21,-968 4148.21,-847.546 3767.06,-803.953 3558.24,-789.109\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3942.66,-2736.28 3951.22,-2729.43 3947.5,-2735.04 3952.34,-2733.79 3952.34,-2733.79 3952.34,-2733.79 3947.5,-2735.04 3953.46,-2738.14 3942.66,-2736.28 3942.66,-2736.28\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0__plus0&#45;&gt;transformer_3enc_transformer0_dropout0_fwd -->\r\n",
       "<g id=\"edge65\" class=\"edge\"><title>transformer_3enc_transformer0__plus0&#45;&gt;transformer_3enc_transformer0_dropout0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3842.38,-2715.74C3842.19,-2707.2 3842,-2698.3 3841.82,-2690.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3842.6,-2725.9 3837.88,-2716 3842.49,-2720.9 3842.38,-2715.9 3842.38,-2715.9 3842.38,-2715.9 3842.49,-2720.9 3846.88,-2715.8 3842.6,-2725.9 3842.6,-2725.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"node59\" class=\"node\"><title>transformer_3enc_transformer0_layernorm0_layernorm0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3843.21\" cy=\"-2849\" rx=\"181.24\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3843.21\" y=\"-2845.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_layernorm0_layernorm0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer0__plus0 -->\r\n",
       "<g id=\"edge67\" class=\"edge\"><title>transformer_3enc_transformer0_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer0__plus0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3843.21,-2809.74C3843.21,-2801.2 3843.21,-2792.3 3843.21,-2784.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3843.21,-2819.9 3838.71,-2809.9 3843.21,-2814.9 3843.21,-2809.9 3843.21,-2809.9 3843.21,-2809.9 3843.21,-2814.9 3847.71,-2809.9 3843.21,-2819.9 3843.21,-2819.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0_ffn_1_fwd -->\r\n",
       "<g id=\"node60\" class=\"node\"><title>transformer_3enc_transformer0_positionwiseffn0_ffn_1_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3900.21\" cy=\"-2943\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3900.21\" y=\"-2946.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3900.21\" y=\"-2931.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1024</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0_ffn_1_fwd&#45;&gt;transformer_3enc_transformer0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge68\" class=\"edge\"><title>transformer_3enc_transformer0_positionwiseffn0_ffn_1_fwd&#45;&gt;transformer_3enc_transformer0_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3877.75,-2905.74C3872.01,-2896.48 3865.93,-2886.67 3860.5,-2877.9\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3883.11,-2914.4 3874.02,-2908.27 3880.48,-2910.15 3877.84,-2905.9 3877.84,-2905.9 3877.84,-2905.9 3880.48,-2910.15 3881.67,-2903.53 3883.11,-2914.4 3883.11,-2914.4\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0_relu0_fwd -->\r\n",
       "<g id=\"node61\" class=\"node\"><title>transformer_3enc_transformer0_positionwiseffn0_relu0_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"3934.21\" cy=\"-3037\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3934.21\" y=\"-3040.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3934.21\" y=\"-3025.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0_relu0_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_ffn_1_fwd -->\r\n",
       "<g id=\"edge69\" class=\"edge\"><title>transformer_3enc_transformer0_positionwiseffn0_relu0_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_ffn_1_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3920.49,-2998.88C3917.16,-2989.87 3913.66,-2980.4 3910.52,-2971.9\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3924.01,-3008.4 3916.32,-3000.58 3922.28,-3003.71 3920.54,-2999.02 3920.54,-2999.02 3920.54,-2999.02 3922.28,-3003.71 3924.76,-2997.46 3924.01,-3008.4 3924.01,-3008.4\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0_ffn_2_fwd -->\r\n",
       "<g id=\"node62\" class=\"node\"><title>transformer_3enc_transformer0_positionwiseffn0_ffn_2_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3952.21\" cy=\"-3131\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3952.21\" y=\"-3134.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3952.21\" y=\"-3119.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0_ffn_2_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_relu0_fwd -->\r\n",
       "<g id=\"edge70\" class=\"edge\"><title>transformer_3enc_transformer0_positionwiseffn0_ffn_2_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_relu0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3944.76,-3091.93C3943.06,-3083.22 3941.28,-3074.12 3939.68,-3065.93\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3946.71,-3101.9 3940.38,-3092.95 3945.75,-3096.99 3944.79,-3092.08 3944.79,-3092.08 3944.79,-3092.08 3945.75,-3096.99 3949.21,-3091.22 3946.71,-3101.9 3946.71,-3101.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0_dropout0_fwd -->\r\n",
       "<g id=\"node63\" class=\"node\"><title>transformer_3enc_transformer0_positionwiseffn0_dropout0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"4022.21\" cy=\"-3225\" rx=\"208.116\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4022.21\" y=\"-3221.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_positionwiseffn0_dropout0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0_dropout0_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_ffn_2_fwd -->\r\n",
       "<g id=\"edge71\" class=\"edge\"><title>transformer_3enc_transformer0_positionwiseffn0_dropout0_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_ffn_2_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3994.58,-3187.68C3987.3,-3178.12 3979.57,-3167.96 3972.74,-3158.99\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4000.83,-3195.9 3991.19,-3190.66 3997.8,-3191.92 3994.77,-3187.94 3994.77,-3187.94 3994.77,-3187.94 3997.8,-3191.92 3998.35,-3185.21 4000.83,-3195.9 4000.83,-3195.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0__plus0 -->\r\n",
       "<g id=\"node64\" class=\"node\"><title>transformer_3enc_transformer0_positionwiseffn0__plus0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3789.21\" cy=\"-3319\" rx=\"184.187\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3789.21\" y=\"-3315.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_positionwiseffn0__plus0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge73\" class=\"edge\"><title>transformer_3enc_transformer0_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer0_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3788.24,-3279.95C3787.36,-3242.36 3786.21,-3183.22 3786.21,-3132 3786.21,-3132 3786.21,-3132 3786.21,-3036 3786.21,-2977.91 3811.94,-2913.91 3828.83,-2878.17\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3788.48,-3289.96 3783.74,-3280.07 3788.36,-3284.96 3788.24,-3279.96 3788.24,-3279.96 3788.24,-3279.96 3788.36,-3284.96 3792.74,-3279.85 3788.48,-3289.96 3788.48,-3289.96\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_dropout0_fwd -->\r\n",
       "<g id=\"edge72\" class=\"edge\"><title>transformer_3enc_transformer0_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_dropout0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3864.66,-3288.21C3893.78,-3276.71 3926.81,-3263.67 3955.09,-3252.5\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3855.36,-3291.88 3863,-3284.02 3860.01,-3290.05 3864.66,-3288.21 3864.66,-3288.21 3864.66,-3288.21 3860.01,-3290.05 3866.31,-3292.4 3855.36,-3291.88 3855.36,-3291.88\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"node65\" class=\"node\"><title>transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3789.21\" cy=\"-3413\" rx=\"235.671\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3789.21\" y=\"-3409.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer0_positionwiseffn0__plus0 -->\r\n",
       "<g id=\"edge74\" class=\"edge\"><title>transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer0_positionwiseffn0__plus0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3789.21,-3373.74C3789.21,-3365.2 3789.21,-3356.3 3789.21,-3348.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3789.21,-3383.9 3784.71,-3373.9 3789.21,-3378.9 3789.21,-3373.9 3789.21,-3373.9 3789.21,-3373.9 3789.21,-3378.9 3793.71,-3373.9 3789.21,-3383.9 3789.21,-3383.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_query_fwd -->\r\n",
       "<g id=\"node66\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_query_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3485.21\" cy=\"-3507\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3485.21\" y=\"-3510.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3485.21\" y=\"-3495.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_query_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge75\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_query_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3550.19,-3486.34C3594.83,-3472.83 3654.56,-3454.75 3703.15,-3440.04\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3540.62,-3489.23 3548.88,-3482.03 3545.4,-3487.78 3550.19,-3486.34 3550.19,-3486.34 3550.19,-3486.34 3545.4,-3487.78 3551.49,-3490.64 3540.62,-3489.23 3540.62,-3489.23\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape0 -->\r\n",
       "<g id=\"node67\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape0</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3286.21\" cy=\"-3601\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3286.21\" y=\"-3597.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_reshape0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_query_fwd -->\r\n",
       "<g id=\"edge76\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_query_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3354.01,-3568.66C3382.31,-3555.57 3414.44,-3540.72 3439.82,-3528.99\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3344.57,-3573.02 3351.76,-3564.74 3349.11,-3570.92 3353.65,-3568.82 3353.65,-3568.82 3353.65,-3568.82 3349.11,-3570.92 3355.54,-3572.91 3344.57,-3573.02 3344.57,-3573.02\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_transpose0 -->\r\n",
       "<g id=\"node68\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_transpose0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3140.21\" cy=\"-3695\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3140.21\" y=\"-3691.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_transpose0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_transpose0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape0 -->\r\n",
       "<g id=\"edge77\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_transpose0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3192.91,-3660.79C3209.25,-3650.5 3227.05,-3639.28 3242.69,-3629.42\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3184.02,-3666.4 3190.08,-3657.26 3188.25,-3663.73 3192.48,-3661.07 3192.48,-3661.07 3192.48,-3661.07 3188.25,-3663.73 3194.87,-3664.87 3184.02,-3666.4 3184.02,-3666.4\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape1 -->\r\n",
       "<g id=\"node69\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape1</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3136.21\" cy=\"-3789\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3136.21\" y=\"-3785.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_reshape1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape1&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_transpose0 -->\r\n",
       "<g id=\"edge78\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape1&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3137.87,-3749.74C3138.25,-3741.2 3138.63,-3732.3 3138.98,-3724.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3137.43,-3759.9 3133.37,-3749.71 3137.65,-3754.9 3137.87,-3749.91 3137.87,-3749.91 3137.87,-3749.91 3137.65,-3754.9 3142.36,-3750.1 3137.43,-3759.9 3137.43,-3759.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_div_sqrt_dim0 -->\r\n",
       "<g id=\"node70\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_div_sqrt_dim0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3134.21\" cy=\"-3883\" rx=\"226.653\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3134.21\" y=\"-3879.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_div_sqrt_dim0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_div_sqrt_dim0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape1 -->\r\n",
       "<g id=\"edge79\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_div_sqrt_dim0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3135.04,-3843.74C3135.23,-3835.2 3135.42,-3826.3 3135.6,-3818.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3134.82,-3853.9 3130.54,-3843.8 3134.93,-3848.9 3135.04,-3843.9 3135.04,-3843.9 3135.04,-3843.9 3134.93,-3848.9 3139.54,-3844 3134.82,-3853.9 3134.82,-3853.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_key_fwd -->\r\n",
       "<g id=\"node71\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_key_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3726.21\" cy=\"-3601\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3726.21\" y=\"-3604.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3726.21\" y=\"-3589.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_key_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge80\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_key_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3738.88,-3562.6C3750.94,-3526.98 3768.83,-3474.17 3779.71,-3442.04\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3735.64,-3572.15 3734.59,-3561.24 3737.25,-3567.42 3738.85,-3562.68 3738.85,-3562.68 3738.85,-3562.68 3737.25,-3567.42 3743.11,-3564.13 3735.64,-3572.15 3735.64,-3572.15\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape2 -->\r\n",
       "<g id=\"node72\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape2</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3585.21\" cy=\"-3695\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3585.21\" y=\"-3691.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_reshape2</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape2&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_key_fwd -->\r\n",
       "<g id=\"edge81\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape2&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_key_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3636.05,-3660.83C3653.79,-3649.25 3673.32,-3636.51 3689.66,-3625.85\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3627.52,-3666.4 3633.43,-3657.16 3631.7,-3663.66 3635.89,-3660.93 3635.89,-3660.93 3635.89,-3660.93 3631.7,-3663.66 3638.35,-3664.7 3627.52,-3666.4 3627.52,-3666.4\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_transpose1 -->\r\n",
       "<g id=\"node73\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_transpose1</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3582.21\" cy=\"-3789\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3582.21\" y=\"-3785.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_transpose1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_transpose1&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape2 -->\r\n",
       "<g id=\"edge82\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_transpose1&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3583.46,-3749.74C3583.74,-3741.2 3584.03,-3732.3 3584.29,-3724.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3583.13,-3759.9 3578.96,-3749.76 3583.29,-3754.9 3583.45,-3749.9 3583.45,-3749.9 3583.45,-3749.9 3583.29,-3754.9 3587.95,-3750.05 3583.13,-3759.9 3583.13,-3759.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape3 -->\r\n",
       "<g id=\"node74\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape3</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3588.21\" cy=\"-3883\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3588.21\" y=\"-3879.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_reshape3</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape3&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_transpose1 -->\r\n",
       "<g id=\"edge83\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape3&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_transpose1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3585.72,-3843.74C3585.16,-3835.2 3584.58,-3826.3 3584.05,-3818.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3586.38,-3853.9 3581.24,-3844.21 3586.05,-3848.91 3585.73,-3843.92 3585.73,-3843.92 3585.73,-3843.92 3586.05,-3848.91 3590.22,-3843.63 3586.38,-3853.9 3586.38,-3853.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_batch_dot0 -->\r\n",
       "<g id=\"node75\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_batch_dot0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3369.21\" cy=\"-3977\" rx=\"216.546\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3369.21\" y=\"-3973.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_batch_dot0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_div_sqrt_dim0 -->\r\n",
       "<g id=\"edge84\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_div_sqrt_dim0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3291.62,-3945.62C3262.8,-3934.34 3230.35,-3921.64 3202.44,-3910.71\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3301.24,-3949.39 3290.29,-3949.93 3296.58,-3947.57 3291.93,-3945.74 3291.93,-3945.74 3291.93,-3945.74 3296.58,-3947.57 3293.57,-3941.55 3301.24,-3949.39 3301.24,-3949.39\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape3 -->\r\n",
       "<g id=\"edge85\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3442.16,-3945.35C3468.91,-3934.12 3498.95,-3921.5 3524.79,-3910.64\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3432.85,-3949.27 3440.33,-3941.24 3437.46,-3947.33 3442.07,-3945.39 3442.07,-3945.39 3442.07,-3945.39 3437.46,-3947.33 3443.81,-3949.54 3432.85,-3949.27 3432.85,-3949.27\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_ones_like0 -->\r\n",
       "<g id=\"node76\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_ones_like0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3384.21\" cy=\"-4071\" rx=\"214.688\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3384.21\" y=\"-4067.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_ones_like0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_ones_like0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_batch_dot0 -->\r\n",
       "<g id=\"edge86\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_ones_like0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_batch_dot0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3378.02,-4032.03C3376.61,-4023.4 3375.14,-4014.39 3373.82,-4006.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3379.63,-4041.9 3373.58,-4032.75 3378.82,-4036.96 3378.02,-4032.03 3378.02,-4032.03 3378.02,-4032.03 3378.82,-4036.96 3382.46,-4031.3 3379.63,-4041.9 3379.63,-4041.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0__mulscalar0 -->\r\n",
       "<g id=\"node77\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0__mulscalar0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3386.21\" cy=\"-4165\" rx=\"218.313\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3386.21\" y=\"-4161.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0__mulscalar0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0__mulscalar0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_ones_like0 -->\r\n",
       "<g id=\"edge87\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0__mulscalar0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_ones_like0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3385.38,-4125.74C3385.19,-4117.2 3385,-4108.3 3384.82,-4100.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3385.6,-4135.9 3380.88,-4126 3385.49,-4130.9 3385.38,-4125.9 3385.38,-4125.9 3385.38,-4125.9 3385.49,-4130.9 3389.88,-4125.8 3385.6,-4135.9 3385.6,-4135.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_where0 -->\r\n",
       "<g id=\"node78\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_where0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3140.21\" cy=\"-4259\" rx=\"203.902\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3140.21\" y=\"-4255.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_where0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape4 -->\r\n",
       "<g id=\"edge88\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3062.55,-4227.98C3032.98,-4216.55 2999.51,-4203.61 2970.83,-4192.53\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3072.01,-4231.64 3061.06,-4232.23 3067.35,-4229.83 3062.68,-4228.03 3062.68,-4228.03 3062.68,-4228.03 3067.35,-4229.83 3064.3,-4223.83 3072.01,-4231.64 3072.01,-4231.64\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_batch_dot0 -->\r\n",
       "<g id=\"edge89\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_batch_dot0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3132.05,-4219.72C3124.35,-4172.47 3119.33,-4092.24 3160.21,-4042 3176.5,-4021.98 3198.88,-4008.09 3222.96,-3998.47\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3133.83,-4229.84 3127.67,-4220.77 3132.96,-4224.92 3132.1,-4219.99 3132.1,-4219.99 3132.1,-4219.99 3132.96,-4224.92 3136.53,-4219.22 3133.83,-4229.84 3133.83,-4229.84\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0__mulscalar0 -->\r\n",
       "<g id=\"edge90\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0__mulscalar0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3219.75,-4228.25C3250.44,-4216.78 3285.26,-4203.75 3315.1,-4192.59\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3210.37,-4231.76 3218.17,-4224.04 3215.06,-4230.01 3219.74,-4228.26 3219.74,-4228.26 3219.74,-4228.26 3215.06,-4230.01 3221.32,-4232.47 3210.37,-4231.76 3210.37,-4231.76\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_softmax0 -->\r\n",
       "<g id=\"node79\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_softmax0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3140.21\" cy=\"-4353\" rx=\"210.474\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3140.21\" y=\"-4349.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_softmax0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_softmax0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_where0 -->\r\n",
       "<g id=\"edge91\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_softmax0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_where0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3140.21,-4313.74C3140.21,-4305.2 3140.21,-4296.3 3140.21,-4288.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3140.21,-4323.9 3135.71,-4313.9 3140.21,-4318.9 3140.21,-4313.9 3140.21,-4313.9 3140.21,-4313.9 3140.21,-4318.9 3144.71,-4313.9 3140.21,-4323.9 3140.21,-4323.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0__mul0 -->\r\n",
       "<g id=\"node80\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0__mul0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3140.21\" cy=\"-4447\" rx=\"200.955\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3140.21\" y=\"-4443.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0__mul0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape4 -->\r\n",
       "<g id=\"edge93\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3011.25,-4421.22C2971.1,-4410.85 2933.97,-4397.56 2921.21,-4382 2877.04,-4328.16 2886.78,-4239.33 2895.59,-4194.2\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3020.95,-4423.66 3010.16,-4425.58 3016.1,-4422.44 3011.25,-4421.22 3011.25,-4421.22 3011.25,-4421.22 3016.1,-4422.44 3012.35,-4416.85 3020.95,-4423.66 3020.95,-4423.66\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_softmax0 -->\r\n",
       "<g id=\"edge92\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_softmax0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3140.21,-4407.74C3140.21,-4399.2 3140.21,-4390.3 3140.21,-4382.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3140.21,-4417.9 3135.71,-4407.9 3140.21,-4412.9 3140.21,-4407.9 3140.21,-4407.9 3140.21,-4407.9 3140.21,-4412.9 3144.71,-4407.9 3140.21,-4417.9 3140.21,-4417.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_dotproductattentioncell0_dropout0_fwd -->\r\n",
       "<g id=\"node81\" class=\"node\"><title>transformer_3enc_transformer1_dotproductattentioncell0_dropout0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3161.21\" cy=\"-4541\" rx=\"231.457\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3161.21\" y=\"-4537.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_dotproductattentioncell0_dropout0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_dotproductattentioncell0_dropout0_fwd&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0__mul0 -->\r\n",
       "<g id=\"edge94\" class=\"edge\"><title>transformer_3enc_transformer1_dotproductattentioncell0_dropout0_fwd&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0__mul0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3152.54,-4502.03C3150.57,-4493.4 3148.52,-4484.39 3146.66,-4476.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3154.8,-4511.9 3148.18,-4503.15 3153.68,-4507.02 3152.57,-4502.15 3152.57,-4502.15 3152.57,-4502.15 3153.68,-4507.02 3156.96,-4501.15 3154.8,-4511.9 3154.8,-4511.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape5 -->\r\n",
       "<g id=\"node82\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape5</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3173.21\" cy=\"-4635\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3173.21\" y=\"-4631.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_reshape5</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape5&#45;&gt;transformer_3enc_transformer1_dotproductattentioncell0_dropout0_fwd -->\r\n",
       "<g id=\"edge95\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape5&#45;&gt;transformer_3enc_transformer1_dotproductattentioncell0_dropout0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3168.22,-4595.74C3167.11,-4587.2 3165.94,-4578.3 3164.89,-4570.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3169.54,-4605.9 3163.79,-4596.56 3168.9,-4600.94 3168.25,-4595.98 3168.25,-4595.98 3168.25,-4595.98 3168.9,-4600.94 3172.71,-4595.4 3169.54,-4605.9 3169.54,-4605.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape6 -->\r\n",
       "<g id=\"node83\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape6</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3175.21\" cy=\"-4729\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3175.21\" y=\"-4725.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_reshape6</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape6&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape5 -->\r\n",
       "<g id=\"edge96\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape6&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3174.38,-4689.74C3174.19,-4681.2 3174,-4672.3 3173.82,-4664.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3174.6,-4699.9 3169.88,-4690 3174.49,-4694.9 3174.38,-4689.9 3174.38,-4689.9 3174.38,-4689.9 3174.49,-4694.9 3178.88,-4689.8 3174.6,-4699.9 3174.6,-4699.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_value_fwd -->\r\n",
       "<g id=\"node84\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_value_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3730.21\" cy=\"-4353\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3730.21\" y=\"-4356.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3730.21\" y=\"-4341.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_value_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge97\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_value_fwd&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3760.43,-4317.42C3788.24,-4281.95 3825.21,-4223.91 3825.21,-4166 3825.21,-4166 3825.21,-4166 3825.21,-3600 3825.21,-3543.1 3808.77,-3478.16 3798.11,-3442.03\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3753.94,-4325.51 3756.69,-4314.89 3757.07,-4321.61 3760.2,-4317.71 3760.2,-4317.71 3760.2,-4317.71 3757.07,-4321.61 3763.71,-4320.53 3753.94,-4325.51 3753.94,-4325.51\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape7 -->\r\n",
       "<g id=\"node85\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape7</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3623.21\" cy=\"-4541\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3623.21\" y=\"-4537.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_reshape7</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape7&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_value_fwd -->\r\n",
       "<g id=\"edge98\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape7&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_value_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3644.48,-4503.03C3665.13,-4467.14 3695.99,-4413.49 3714.5,-4381.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3639.46,-4511.75 3640.55,-4500.84 3641.95,-4507.42 3644.45,-4503.08 3644.45,-4503.08 3644.45,-4503.08 3641.95,-4507.42 3648.35,-4505.33 3639.46,-4511.75 3639.46,-4511.75\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_transpose2 -->\r\n",
       "<g id=\"node86\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_transpose2</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3620.21\" cy=\"-4635\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3620.21\" y=\"-4631.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_transpose2</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_transpose2&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape7 -->\r\n",
       "<g id=\"edge99\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_transpose2&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3621.46,-4595.74C3621.74,-4587.2 3622.03,-4578.3 3622.29,-4570.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3621.13,-4605.9 3616.96,-4595.76 3621.29,-4600.9 3621.45,-4595.9 3621.45,-4595.9 3621.45,-4595.9 3621.29,-4600.9 3625.95,-4596.05 3621.13,-4605.9 3621.13,-4605.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape8 -->\r\n",
       "<g id=\"node87\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape8</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3619.21\" cy=\"-4729\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3619.21\" y=\"-4725.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_reshape8</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape8&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_transpose2 -->\r\n",
       "<g id=\"edge100\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape8&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_transpose2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3619.63,-4689.74C3619.72,-4681.2 3619.82,-4672.3 3619.9,-4664.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3619.52,-4699.9 3615.12,-4689.85 3619.57,-4694.9 3619.62,-4689.9 3619.62,-4689.9 3619.62,-4689.9 3619.57,-4694.9 3624.12,-4689.95 3619.52,-4699.9 3619.52,-4699.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_batch_dot1 -->\r\n",
       "<g id=\"node88\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_batch_dot1</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3618.21\" cy=\"-4823\" rx=\"216.546\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3618.21\" y=\"-4819.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_batch_dot1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape6 -->\r\n",
       "<g id=\"edge101\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3494.28,-4796.26C3429.63,-4782.84 3351.11,-4766.53 3288.14,-4753.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3504.13,-4798.31 3493.42,-4800.68 3499.23,-4797.29 3494.34,-4796.27 3494.34,-4796.27 3494.34,-4796.27 3499.23,-4797.29 3495.25,-4791.87 3504.13,-4798.31 3504.13,-4798.31\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape8 -->\r\n",
       "<g id=\"edge102\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3618.63,-4783.74C3618.72,-4775.2 3618.82,-4766.3 3618.9,-4758.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3618.52,-4793.9 3614.12,-4783.85 3618.57,-4788.9 3618.62,-4783.9 3618.62,-4783.9 3618.62,-4783.9 3618.57,-4788.9 3623.12,-4783.95 3618.52,-4793.9 3618.52,-4793.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape9 -->\r\n",
       "<g id=\"node89\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape9</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3618.21\" cy=\"-4917\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3618.21\" y=\"-4913.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_reshape9</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape9&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_batch_dot1 -->\r\n",
       "<g id=\"edge103\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape9&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_batch_dot1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3618.21,-4877.74C3618.21,-4869.2 3618.21,-4860.3 3618.21,-4852.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3618.21,-4887.9 3613.71,-4877.9 3618.21,-4882.9 3618.21,-4877.9 3618.21,-4877.9 3618.21,-4877.9 3618.21,-4882.9 3622.71,-4877.9 3618.21,-4887.9 3618.21,-4887.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_transpose3 -->\r\n",
       "<g id=\"node90\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_transpose3</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3619.21\" cy=\"-5011\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3619.21\" y=\"-5007.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_transpose3</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_transpose3&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape9 -->\r\n",
       "<g id=\"edge104\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_transpose3&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3618.79,-4971.74C3618.7,-4963.2 3618.6,-4954.3 3618.52,-4946.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3618.9,-4981.9 3614.3,-4971.95 3618.85,-4976.9 3618.8,-4971.9 3618.8,-4971.9 3618.8,-4971.9 3618.85,-4976.9 3623.3,-4971.85 3618.9,-4981.9 3618.9,-4981.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape10 -->\r\n",
       "<g id=\"node91\" class=\"node\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape10</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3621.21\" cy=\"-5105\" rx=\"212.92\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3621.21\" y=\"-5101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_multiheadattentioncell0_reshape10</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_multiheadattentioncell0_reshape10&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_transpose3 -->\r\n",
       "<g id=\"edge105\" class=\"edge\"><title>transformer_3enc_transformer1_multiheadattentioncell0_reshape10&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_transpose3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3620.38,-5065.74C3620.19,-5057.2 3620,-5048.3 3619.82,-5040.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3620.6,-5075.9 3615.88,-5066 3620.49,-5070.9 3620.38,-5065.9 3620.38,-5065.9 3620.38,-5065.9 3620.49,-5070.9 3624.88,-5065.8 3620.6,-5075.9 3620.6,-5075.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_proj_fwd -->\r\n",
       "<g id=\"node92\" class=\"node\"><title>transformer_3enc_transformer1_proj_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3640.21\" cy=\"-5199\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3640.21\" y=\"-5202.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3640.21\" y=\"-5187.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_proj_fwd&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape10 -->\r\n",
       "<g id=\"edge106\" class=\"edge\"><title>transformer_3enc_transformer1_proj_fwd&#45;&gt;transformer_3enc_transformer1_multiheadattentioncell0_reshape10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3632.37,-5160.03C3630.59,-5151.4 3628.72,-5142.39 3627.04,-5134.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3634.41,-5169.9 3627.98,-5161.01 3633.4,-5165 3632.38,-5160.1 3632.38,-5160.1 3632.38,-5160.1 3633.4,-5165 3636.79,-5159.19 3634.41,-5169.9 3634.41,-5169.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_dropout0_fwd -->\r\n",
       "<g id=\"node93\" class=\"node\"><title>transformer_3enc_transformer1_dropout0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3656.21\" cy=\"-5293\" rx=\"153.685\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3656.21\" y=\"-5289.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_dropout0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_dropout0_fwd&#45;&gt;transformer_3enc_transformer1_proj_fwd -->\r\n",
       "<g id=\"edge107\" class=\"edge\"><title>transformer_3enc_transformer1_dropout0_fwd&#45;&gt;transformer_3enc_transformer1_proj_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3649.59,-5253.93C3648.08,-5245.22 3646.49,-5236.12 3645.07,-5227.93\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3651.32,-5263.9 3645.18,-5254.82 3650.47,-5258.97 3649.61,-5254.04 3649.61,-5254.04 3649.61,-5254.04 3650.47,-5258.97 3654.04,-5253.27 3651.32,-5263.9 3651.32,-5263.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1__plus0 -->\r\n",
       "<g id=\"node94\" class=\"node\"><title>transformer_3enc_transformer1__plus0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3702.21\" cy=\"-5387\" rx=\"130.345\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3702.21\" y=\"-5383.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1__plus0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1__plus0&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge109\" class=\"edge\"><title>transformer_3enc_transformer1__plus0&#45;&gt;transformer_3enc_transformer0_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3775.15,-5356.7C3791.32,-5347.52 3807.2,-5336.02 3819.21,-5322 3856.7,-5278.22 3863.21,-5257.64 3863.21,-5200 3863.21,-5200 3863.21,-5200 3863.21,-3600 3863.21,-3540.4 3830,-3477.18 3808.08,-3441.94\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3766.16,-5361.57 3772.81,-5352.85 3770.56,-5359.19 3774.96,-5356.81 3774.96,-5356.81 3774.96,-5356.81 3770.56,-5359.19 3777.1,-5360.76 3766.16,-5361.57 3766.16,-5361.57\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1__plus0&#45;&gt;transformer_3enc_transformer1_dropout0_fwd -->\r\n",
       "<g id=\"edge108\" class=\"edge\"><title>transformer_3enc_transformer1__plus0&#45;&gt;transformer_3enc_transformer1_dropout0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3683.6,-5348.78C3679.12,-5339.82 3674.4,-5330.39 3670.18,-5321.93\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3688.16,-5357.9 3679.66,-5350.97 3685.92,-5353.42 3683.69,-5348.95 3683.69,-5348.95 3683.69,-5348.95 3685.92,-5353.42 3687.71,-5346.94 3688.16,-5357.9 3688.16,-5357.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_layernorm0_layernorm0 -->\r\n",
       "<g id=\"node95\" class=\"node\"><title>transformer_3enc_transformer1_layernorm0_layernorm0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3702.21\" cy=\"-5481\" rx=\"181.24\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3702.21\" y=\"-5477.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_layernorm0_layernorm0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer1__plus0 -->\r\n",
       "<g id=\"edge110\" class=\"edge\"><title>transformer_3enc_transformer1_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer1__plus0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3702.21,-5441.74C3702.21,-5433.2 3702.21,-5424.3 3702.21,-5416.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3702.21,-5451.9 3697.71,-5441.9 3702.21,-5446.9 3702.21,-5441.9 3702.21,-5441.9 3702.21,-5441.9 3702.21,-5446.9 3706.71,-5441.9 3702.21,-5451.9 3702.21,-5451.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0_ffn_1_fwd -->\r\n",
       "<g id=\"node96\" class=\"node\"><title>transformer_3enc_transformer1_positionwiseffn0_ffn_1_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3697.21\" cy=\"-5575\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3697.21\" y=\"-5578.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3697.21\" y=\"-5563.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1024</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0_ffn_1_fwd&#45;&gt;transformer_3enc_transformer1_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge111\" class=\"edge\"><title>transformer_3enc_transformer1_positionwiseffn0_ffn_1_fwd&#45;&gt;transformer_3enc_transformer1_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3699.29,-5535.74C3699.75,-5527.2 3700.24,-5518.3 3700.68,-5510.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3698.74,-5545.9 3694.79,-5535.67 3699.01,-5540.9 3699.28,-5535.91 3699.28,-5535.91 3699.28,-5535.91 3699.01,-5540.9 3703.77,-5536.16 3698.74,-5545.9 3698.74,-5545.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0_relu0_fwd -->\r\n",
       "<g id=\"node97\" class=\"node\"><title>transformer_3enc_transformer1_positionwiseffn0_relu0_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"3677.21\" cy=\"-5669\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3677.21\" y=\"-5672.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3677.21\" y=\"-5657.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0_relu0_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_ffn_1_fwd -->\r\n",
       "<g id=\"edge112\" class=\"edge\"><title>transformer_3enc_transformer1_positionwiseffn0_relu0_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_ffn_1_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3685.49,-5629.93C3687.38,-5621.22 3689.36,-5612.12 3691.14,-5603.93\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3683.32,-5639.9 3681.05,-5629.17 3684.38,-5635.01 3685.44,-5630.13 3685.44,-5630.13 3685.44,-5630.13 3684.38,-5635.01 3689.84,-5631.08 3683.32,-5639.9 3683.32,-5639.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0_ffn_2_fwd -->\r\n",
       "<g id=\"node98\" class=\"node\"><title>transformer_3enc_transformer1_positionwiseffn0_ffn_2_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3667.21\" cy=\"-5763\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3667.21\" y=\"-5766.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3667.21\" y=\"-5751.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0_ffn_2_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_relu0_fwd -->\r\n",
       "<g id=\"edge113\" class=\"edge\"><title>transformer_3enc_transformer1_positionwiseffn0_ffn_2_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_relu0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3671.37,-5723.74C3672.3,-5715.2 3673.27,-5706.3 3674.14,-5698.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3670.27,-5733.9 3666.87,-5723.47 3670.81,-5728.93 3671.35,-5723.96 3671.35,-5723.96 3671.35,-5723.96 3670.81,-5728.93 3675.82,-5724.44 3670.27,-5733.9 3670.27,-5733.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0_dropout0_fwd -->\r\n",
       "<g id=\"node99\" class=\"node\"><title>transformer_3enc_transformer1_positionwiseffn0_dropout0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3627.21\" cy=\"-5857\" rx=\"208.116\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3627.21\" y=\"-5853.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_positionwiseffn0_dropout0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0_dropout0_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_ffn_2_fwd -->\r\n",
       "<g id=\"edge114\" class=\"edge\"><title>transformer_3enc_transformer1_positionwiseffn0_dropout0_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_ffn_2_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3643.43,-5818.7C3647.37,-5809.64 3651.5,-5800.13 3655.2,-5791.61\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3639.43,-5827.9 3639.29,-5816.93 3641.42,-5823.31 3643.42,-5818.73 3643.42,-5818.73 3643.42,-5818.73 3641.42,-5823.31 3647.54,-5820.52 3639.43,-5827.9 3639.43,-5827.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0__plus0 -->\r\n",
       "<g id=\"node100\" class=\"node\"><title>transformer_3enc_transformer1_positionwiseffn0__plus0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3643.21\" cy=\"-5951\" rx=\"184.187\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3643.21\" y=\"-5947.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_positionwiseffn0__plus0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer1_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge116\" class=\"edge\"><title>transformer_3enc_transformer1_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer1_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3784.66,-5927.05C3807.28,-5917.64 3828.4,-5904.45 3844.21,-5886 3879.92,-5844.33 3863.21,-5818.88 3863.21,-5764 3863.21,-5764 3863.21,-5764 3863.21,-5668 3863.21,-5597.53 3796.33,-5540.63 3748.78,-5509.09\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3775.24,-5930.73 3782.92,-5922.9 3779.9,-5928.91 3784.56,-5927.09 3784.56,-5927.09 3784.56,-5927.09 3779.9,-5928.91 3786.19,-5931.28 3775.24,-5930.73 3775.24,-5930.73\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_dropout0_fwd -->\r\n",
       "<g id=\"edge115\" class=\"edge\"><title>transformer_3enc_transformer1_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_dropout0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3636.61,-5912.03C3635.11,-5903.4 3633.54,-5894.39 3632.12,-5886.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3638.32,-5921.9 3632.18,-5912.82 3637.47,-5916.97 3636.61,-5912.04 3636.61,-5912.04 3636.61,-5912.04 3637.47,-5916.97 3641.04,-5911.27 3638.32,-5921.9 3638.32,-5921.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"node101\" class=\"node\"><title>transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3643.21\" cy=\"-6045\" rx=\"235.671\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3643.21\" y=\"-6041.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer1_positionwiseffn0__plus0 -->\r\n",
       "<g id=\"edge117\" class=\"edge\"><title>transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer1_positionwiseffn0__plus0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3643.21,-6005.74C3643.21,-5997.2 3643.21,-5988.3 3643.21,-5980.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3643.21,-6015.9 3638.71,-6005.9 3643.21,-6010.9 3643.21,-6005.9 3643.21,-6005.9 3643.21,-6005.9 3643.21,-6010.9 3647.71,-6005.9 3643.21,-6015.9 3643.21,-6015.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_query_fwd -->\r\n",
       "<g id=\"node102\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_query_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3485.21\" cy=\"-6139\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3485.21\" y=\"-6142.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3485.21\" y=\"-6127.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_query_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge118\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_query_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3533.56,-6109.84C3553.43,-6098.27 3576.37,-6084.92 3596.1,-6073.43\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3524.67,-6115.02 3531.05,-6106.1 3528.99,-6112.51 3533.31,-6109.99 3533.31,-6109.99 3533.31,-6109.99 3528.99,-6112.51 3535.58,-6113.88 3524.67,-6115.02 3524.67,-6115.02\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape0 -->\r\n",
       "<g id=\"node103\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape0</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3410.21\" cy=\"-6233\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3410.21\" y=\"-6229.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_reshape0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_query_fwd -->\r\n",
       "<g id=\"edge119\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_query_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3439.64,-6195.9C3447.58,-6186.16 3456.03,-6175.8 3463.47,-6166.67\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3433.12,-6203.9 3435.95,-6193.3 3436.28,-6200.02 3439.44,-6196.15 3439.44,-6196.15 3439.44,-6196.15 3436.28,-6200.02 3442.93,-6198.99 3433.12,-6203.9 3433.12,-6203.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_transpose0 -->\r\n",
       "<g id=\"node104\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_transpose0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3407.21\" cy=\"-6327\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3407.21\" y=\"-6323.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_transpose0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_transpose0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape0 -->\r\n",
       "<g id=\"edge120\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_transpose0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3408.46,-6287.74C3408.74,-6279.2 3409.03,-6270.3 3409.29,-6262.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3408.13,-6297.9 3403.96,-6287.76 3408.29,-6292.9 3408.45,-6287.9 3408.45,-6287.9 3408.45,-6287.9 3408.29,-6292.9 3412.95,-6288.05 3408.13,-6297.9 3408.13,-6297.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape1 -->\r\n",
       "<g id=\"node105\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape1</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3403.21\" cy=\"-6421\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3403.21\" y=\"-6417.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_reshape1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape1&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_transpose0 -->\r\n",
       "<g id=\"edge121\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape1&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3404.87,-6381.74C3405.25,-6373.2 3405.63,-6364.3 3405.98,-6356.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3404.43,-6391.9 3400.37,-6381.71 3404.65,-6386.9 3404.87,-6381.91 3404.87,-6381.91 3404.87,-6381.91 3404.65,-6386.9 3409.36,-6382.1 3404.43,-6391.9 3404.43,-6391.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_div_sqrt_dim0 -->\r\n",
       "<g id=\"node106\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_div_sqrt_dim0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3401.21\" cy=\"-6515\" rx=\"226.653\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3401.21\" y=\"-6511.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_div_sqrt_dim0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_div_sqrt_dim0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape1 -->\r\n",
       "<g id=\"edge122\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_div_sqrt_dim0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3402.04,-6475.74C3402.23,-6467.2 3402.42,-6458.3 3402.6,-6450.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3401.82,-6485.9 3397.54,-6475.8 3401.93,-6480.9 3402.04,-6475.9 3402.04,-6475.9 3402.04,-6475.9 3401.93,-6480.9 3406.54,-6476 3401.82,-6485.9 3401.82,-6485.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_key_fwd -->\r\n",
       "<g id=\"node107\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_key_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3035.21\" cy=\"-6233\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3035.21\" y=\"-6236.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3035.21\" y=\"-6221.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_key_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge123\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_key_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3097.19,-6210.58C3170.78,-6185.39 3297.38,-6142.88 3407.21,-6110 3452.25,-6096.52 3502.49,-6082.72 3545,-6071.41\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3087.61,-6213.86 3095.61,-6206.36 3092.34,-6212.24 3097.07,-6210.62 3097.07,-6210.62 3097.07,-6210.62 3092.34,-6212.24 3098.53,-6214.87 3087.61,-6213.86 3087.61,-6213.86\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape2 -->\r\n",
       "<g id=\"node108\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape2</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2957.21\" cy=\"-6327\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2957.21\" y=\"-6323.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_reshape2</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape2&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_key_fwd -->\r\n",
       "<g id=\"edge124\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape2&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_key_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2987.57,-6290.19C2995.9,-6280.37 3004.78,-6269.89 3012.6,-6260.67\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2981.04,-6297.9 2984.07,-6287.36 2984.27,-6294.08 2987.5,-6290.27 2987.5,-6290.27 2987.5,-6290.27 2984.27,-6294.08 2990.94,-6293.18 2981.04,-6297.9 2981.04,-6297.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_transpose1 -->\r\n",
       "<g id=\"node109\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_transpose1</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2956.21\" cy=\"-6421\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2956.21\" y=\"-6417.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_transpose1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_transpose1&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape2 -->\r\n",
       "<g id=\"edge125\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_transpose1&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2956.63,-6381.74C2956.72,-6373.2 2956.82,-6364.3 2956.9,-6356.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2956.52,-6391.9 2952.12,-6381.85 2956.57,-6386.9 2956.62,-6381.9 2956.62,-6381.9 2956.62,-6381.9 2956.57,-6386.9 2961.12,-6381.95 2956.52,-6391.9 2956.52,-6391.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape3 -->\r\n",
       "<g id=\"node110\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape3</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2947.21\" cy=\"-6515\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2947.21\" y=\"-6511.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_reshape3</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape3&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_transpose1 -->\r\n",
       "<g id=\"edge126\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape3&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_transpose1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2950.95,-6475.74C2951.79,-6467.2 2952.66,-6458.3 2953.45,-6450.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2949.96,-6485.9 2946.45,-6475.51 2950.45,-6480.92 2950.93,-6475.94 2950.93,-6475.94 2950.93,-6475.94 2950.45,-6480.92 2955.41,-6476.38 2949.96,-6485.9 2949.96,-6485.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_batch_dot0 -->\r\n",
       "<g id=\"node111\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_batch_dot0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3193.21\" cy=\"-6609\" rx=\"216.546\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3193.21\" y=\"-6605.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_batch_dot0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_div_sqrt_dim0 -->\r\n",
       "<g id=\"edge127\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_div_sqrt_dim0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3263.31,-6576.99C3288.19,-6565.99 3315.98,-6553.7 3340.05,-6543.05\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3253.93,-6581.14 3261.26,-6572.98 3258.5,-6579.12 3263.08,-6577.1 3263.08,-6577.1 3263.08,-6577.1 3258.5,-6579.12 3264.9,-6581.21 3253.93,-6581.14 3253.93,-6581.14\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape3 -->\r\n",
       "<g id=\"edge128\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_batch_dot0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3113.02,-6578.01C3082.37,-6566.55 3047.67,-6553.57 3017.96,-6542.46\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3122.39,-6581.51 3111.44,-6582.23 3117.7,-6579.76 3113.02,-6578.01 3113.02,-6578.01 3113.02,-6578.01 3117.7,-6579.76 3114.6,-6573.8 3122.39,-6581.51 3122.39,-6581.51\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_ones_like0 -->\r\n",
       "<g id=\"node112\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_ones_like0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3203.21\" cy=\"-6703\" rx=\"214.688\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3203.21\" y=\"-6699.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_ones_like0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_ones_like0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_batch_dot0 -->\r\n",
       "<g id=\"edge129\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_ones_like0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_batch_dot0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3199.05,-6663.74C3198.12,-6655.2 3197.16,-6646.3 3196.28,-6638.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3200.16,-6673.9 3194.6,-6664.44 3199.62,-6668.93 3199.08,-6663.96 3199.08,-6663.96 3199.08,-6663.96 3199.62,-6668.93 3203.55,-6663.47 3200.16,-6673.9 3200.16,-6673.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0__mulscalar0 -->\r\n",
       "<g id=\"node113\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0__mulscalar0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3204.21\" cy=\"-6797\" rx=\"218.313\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3204.21\" y=\"-6793.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0__mulscalar0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0__mulscalar0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_ones_like0 -->\r\n",
       "<g id=\"edge130\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0__mulscalar0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_ones_like0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3203.79,-6757.74C3203.7,-6749.2 3203.6,-6740.3 3203.52,-6732.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3203.9,-6767.9 3199.3,-6757.95 3203.85,-6762.9 3203.8,-6757.9 3203.8,-6757.9 3203.8,-6757.9 3203.85,-6762.9 3208.3,-6757.85 3203.9,-6767.9 3203.9,-6767.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_where0 -->\r\n",
       "<g id=\"node114\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_where0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2959.21\" cy=\"-6891\" rx=\"203.902\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2959.21\" y=\"-6887.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_where0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape4 -->\r\n",
       "<g id=\"edge131\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2881.55,-6859.98C2851.98,-6848.55 2818.51,-6835.61 2789.83,-6824.53\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2891.01,-6863.64 2880.06,-6864.23 2886.35,-6861.83 2881.68,-6860.03 2881.68,-6860.03 2881.68,-6860.03 2886.35,-6861.83 2883.3,-6855.83 2891.01,-6863.64 2891.01,-6863.64\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_batch_dot0 -->\r\n",
       "<g id=\"edge132\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_batch_dot0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2951,-6851.67C2943.25,-6804.38 2938.17,-6724.11 2979.21,-6674 2995.86,-6653.68 3018.68,-6639.63 3043.25,-6629.95\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2952.78,-6861.81 2946.62,-6852.74 2951.92,-6856.89 2951.05,-6851.96 2951.05,-6851.96 2951.05,-6851.96 2951.92,-6856.89 2955.48,-6851.18 2952.78,-6861.81 2952.78,-6861.81\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0__mulscalar0 -->\r\n",
       "<g id=\"edge133\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_where0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0__mulscalar0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3038.83,-6860.1C3069.29,-6848.66 3103.8,-6835.7 3133.39,-6824.59\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3029.09,-6863.76 3036.87,-6856.03 3033.77,-6862 3038.45,-6860.24 3038.45,-6860.24 3038.45,-6860.24 3033.77,-6862 3040.03,-6864.46 3029.09,-6863.76 3029.09,-6863.76\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_softmax0 -->\r\n",
       "<g id=\"node115\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_softmax0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2959.21\" cy=\"-6985\" rx=\"210.474\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2959.21\" y=\"-6981.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_softmax0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_softmax0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_where0 -->\r\n",
       "<g id=\"edge134\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_softmax0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_where0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2959.21,-6945.74C2959.21,-6937.2 2959.21,-6928.3 2959.21,-6920.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2959.21,-6955.9 2954.71,-6945.9 2959.21,-6950.9 2959.21,-6945.9 2959.21,-6945.9 2959.21,-6945.9 2959.21,-6950.9 2963.71,-6945.9 2959.21,-6955.9 2959.21,-6955.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0__mul0 -->\r\n",
       "<g id=\"node116\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0__mul0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2959.21\" cy=\"-7079\" rx=\"200.955\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2959.21\" y=\"-7075.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0__mul0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape4 -->\r\n",
       "<g id=\"edge136\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2830.25,-7053.22C2790.1,-7042.85 2752.97,-7029.56 2740.21,-7014 2696.04,-6960.16 2705.78,-6871.33 2714.59,-6826.2\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2839.95,-7055.66 2829.16,-7057.58 2835.1,-7054.44 2830.25,-7053.22 2830.25,-7053.22 2830.25,-7053.22 2835.1,-7054.44 2831.35,-7048.85 2839.95,-7055.66 2839.95,-7055.66\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_softmax0 -->\r\n",
       "<g id=\"edge135\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0__mul0&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_softmax0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2959.21,-7039.74C2959.21,-7031.2 2959.21,-7022.3 2959.21,-7014.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2959.21,-7049.9 2954.71,-7039.9 2959.21,-7044.9 2959.21,-7039.9 2959.21,-7039.9 2959.21,-7039.9 2959.21,-7044.9 2963.71,-7039.9 2959.21,-7049.9 2959.21,-7049.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_dotproductattentioncell0_dropout0_fwd -->\r\n",
       "<g id=\"node117\" class=\"node\"><title>transformer_3enc_transformer2_dotproductattentioncell0_dropout0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2966.21\" cy=\"-7173\" rx=\"231.457\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2966.21\" y=\"-7169.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_dotproductattentioncell0_dropout0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_dotproductattentioncell0_dropout0_fwd&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0__mul0 -->\r\n",
       "<g id=\"edge137\" class=\"edge\"><title>transformer_3enc_transformer2_dotproductattentioncell0_dropout0_fwd&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0__mul0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2963.3,-7133.74C2962.65,-7125.2 2961.97,-7116.3 2961.36,-7108.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2964.07,-7143.9 2958.83,-7134.27 2963.69,-7138.91 2963.31,-7133.93 2963.31,-7133.93 2963.31,-7133.93 2963.69,-7138.91 2967.8,-7133.58 2964.07,-7143.9 2964.07,-7143.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape5 -->\r\n",
       "<g id=\"node118\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape5</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2967.21\" cy=\"-7267\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2967.21\" y=\"-7263.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_reshape5</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape5&#45;&gt;transformer_3enc_transformer2_dotproductattentioncell0_dropout0_fwd -->\r\n",
       "<g id=\"edge138\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape5&#45;&gt;transformer_3enc_transformer2_dotproductattentioncell0_dropout0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2966.79,-7227.74C2966.7,-7219.2 2966.6,-7210.3 2966.52,-7202.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2966.9,-7237.9 2962.3,-7227.95 2966.85,-7232.9 2966.8,-7227.9 2966.8,-7227.9 2966.8,-7227.9 2966.85,-7232.9 2971.3,-7227.85 2966.9,-7237.9 2966.9,-7237.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape6 -->\r\n",
       "<g id=\"node119\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape6</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2968.21\" cy=\"-7361\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2968.21\" y=\"-7357.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_reshape6</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape6&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape5 -->\r\n",
       "<g id=\"edge139\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape6&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2967.79,-7321.74C2967.7,-7313.2 2967.6,-7304.3 2967.52,-7296.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2967.9,-7331.9 2963.3,-7321.95 2967.85,-7326.9 2967.8,-7321.9 2967.8,-7321.9 2967.8,-7321.9 2967.85,-7326.9 2972.3,-7321.85 2967.9,-7331.9 2967.9,-7331.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_value_fwd -->\r\n",
       "<g id=\"node120\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_value_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3560.21\" cy=\"-6985\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3560.21\" y=\"-6988.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3560.21\" y=\"-6973.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_value_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge140\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_value_fwd&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3590.75,-6949.48C3618.85,-6914.04 3656.21,-6856.03 3656.21,-6798 3656.21,-6798 3656.21,-6798 3656.21,-6232 3656.21,-6175.84 3650.24,-6110.37 3646.39,-6074\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3584.19,-6957.55 3587,-6946.95 3587.34,-6953.67 3590.49,-6949.79 3590.49,-6949.79 3590.49,-6949.79 3587.34,-6953.67 3593.98,-6952.63 3584.19,-6957.55 3584.19,-6957.55\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape7 -->\r\n",
       "<g id=\"node121\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape7</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3447.21\" cy=\"-7173\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3447.21\" y=\"-7169.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_reshape7</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape7&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_value_fwd -->\r\n",
       "<g id=\"edge141\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape7&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_value_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3469.67,-7135.03C3491.48,-7099.14 3524.07,-7045.49 3543.62,-7013.3\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3464.37,-7143.75 3465.72,-7132.87 3466.97,-7139.48 3469.56,-7135.2 3469.56,-7135.2 3469.56,-7135.2 3466.97,-7139.48 3473.41,-7137.54 3464.37,-7143.75 3464.37,-7143.75\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_transpose2 -->\r\n",
       "<g id=\"node122\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_transpose2</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3437.21\" cy=\"-7267\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3437.21\" y=\"-7263.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_transpose2</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_transpose2&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape7 -->\r\n",
       "<g id=\"edge142\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_transpose2&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3441.37,-7227.74C3442.3,-7219.2 3443.27,-7210.3 3444.14,-7202.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3440.27,-7237.9 3436.87,-7227.47 3440.81,-7232.93 3441.35,-7227.96 3441.35,-7227.96 3441.35,-7227.96 3440.81,-7232.93 3445.82,-7228.44 3440.27,-7237.9 3440.27,-7237.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape8 -->\r\n",
       "<g id=\"node123\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape8</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3434.21\" cy=\"-7361\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3434.21\" y=\"-7357.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_reshape8</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape8&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_transpose2 -->\r\n",
       "<g id=\"edge143\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape8&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_transpose2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3435.46,-7321.74C3435.74,-7313.2 3436.03,-7304.3 3436.29,-7296.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3435.13,-7331.9 3430.96,-7321.76 3435.29,-7326.9 3435.45,-7321.9 3435.45,-7321.9 3435.45,-7321.9 3435.29,-7326.9 3439.95,-7322.05 3435.13,-7331.9 3435.13,-7331.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_batch_dot1 -->\r\n",
       "<g id=\"node124\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_batch_dot1</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3402.21\" cy=\"-7455\" rx=\"216.546\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3402.21\" y=\"-7451.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_batch_dot1</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape6 -->\r\n",
       "<g id=\"edge144\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3279.91,-7428.07C3217.02,-7414.74 3140.95,-7398.62 3079.69,-7385.63\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3289.88,-7430.19 3279.16,-7432.52 3284.99,-7429.15 3280.1,-7428.11 3280.1,-7428.11 3280.1,-7428.11 3284.99,-7429.15 3281.03,-7423.71 3289.88,-7430.19 3289.88,-7430.19\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape8 -->\r\n",
       "<g id=\"edge145\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_batch_dot1&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3415.32,-7416.31C3418.35,-7407.6 3421.52,-7398.47 3424.39,-7390.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3411.99,-7425.9 3411.02,-7414.97 3413.63,-7421.17 3415.27,-7416.45 3415.27,-7416.45 3415.27,-7416.45 3413.63,-7421.17 3419.52,-7417.93 3411.99,-7425.9 3411.99,-7425.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape9 -->\r\n",
       "<g id=\"node125\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape9</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3402.21\" cy=\"-7549\" rx=\"209.295\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3402.21\" y=\"-7545.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_reshape9</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape9&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_batch_dot1 -->\r\n",
       "<g id=\"edge146\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape9&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_batch_dot1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3402.21,-7509.74C3402.21,-7501.2 3402.21,-7492.3 3402.21,-7484.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3402.21,-7519.9 3397.71,-7509.9 3402.21,-7514.9 3402.21,-7509.9 3402.21,-7509.9 3402.21,-7509.9 3402.21,-7514.9 3406.71,-7509.9 3402.21,-7519.9 3402.21,-7519.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_transpose3 -->\r\n",
       "<g id=\"node126\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_transpose3</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3402.21\" cy=\"-7643\" rx=\"215.278\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3402.21\" y=\"-7639.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_transpose3</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_transpose3&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape9 -->\r\n",
       "<g id=\"edge147\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_transpose3&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3402.21,-7603.74C3402.21,-7595.2 3402.21,-7586.3 3402.21,-7578.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3402.21,-7613.9 3397.71,-7603.9 3402.21,-7608.9 3402.21,-7603.9 3402.21,-7603.9 3402.21,-7603.9 3402.21,-7608.9 3406.71,-7603.9 3402.21,-7613.9 3402.21,-7613.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape10 -->\r\n",
       "<g id=\"node127\" class=\"node\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape10</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"3402.21\" cy=\"-7737\" rx=\"212.92\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3402.21\" y=\"-7733.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_multiheadattentioncell0_reshape10</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_multiheadattentioncell0_reshape10&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_transpose3 -->\r\n",
       "<g id=\"edge148\" class=\"edge\"><title>transformer_3enc_transformer2_multiheadattentioncell0_reshape10&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_transpose3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3402.21,-7697.74C3402.21,-7689.2 3402.21,-7680.3 3402.21,-7672.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3402.21,-7707.9 3397.71,-7697.9 3402.21,-7702.9 3402.21,-7697.9 3402.21,-7697.9 3402.21,-7697.9 3402.21,-7702.9 3406.71,-7697.9 3402.21,-7707.9 3402.21,-7707.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_proj_fwd -->\r\n",
       "<g id=\"node128\" class=\"node\"><title>transformer_3enc_transformer2_proj_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3402.21\" cy=\"-7831\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3402.21\" y=\"-7834.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3402.21\" y=\"-7819.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_proj_fwd&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape10 -->\r\n",
       "<g id=\"edge149\" class=\"edge\"><title>transformer_3enc_transformer2_proj_fwd&#45;&gt;transformer_3enc_transformer2_multiheadattentioncell0_reshape10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3402.21,-7791.74C3402.21,-7783.2 3402.21,-7774.3 3402.21,-7766.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3402.21,-7801.9 3397.71,-7791.9 3402.21,-7796.9 3402.21,-7791.9 3402.21,-7791.9 3402.21,-7791.9 3402.21,-7796.9 3406.71,-7791.9 3402.21,-7801.9 3402.21,-7801.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_dropout0_fwd -->\r\n",
       "<g id=\"node129\" class=\"node\"><title>transformer_3enc_transformer2_dropout0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3402.21\" cy=\"-7925\" rx=\"153.685\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3402.21\" y=\"-7921.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_dropout0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_dropout0_fwd&#45;&gt;transformer_3enc_transformer2_proj_fwd -->\r\n",
       "<g id=\"edge150\" class=\"edge\"><title>transformer_3enc_transformer2_dropout0_fwd&#45;&gt;transformer_3enc_transformer2_proj_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3402.21,-7885.74C3402.21,-7877.2 3402.21,-7868.3 3402.21,-7860.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3402.21,-7895.9 3397.71,-7885.9 3402.21,-7890.9 3402.21,-7885.9 3402.21,-7885.9 3402.21,-7885.9 3402.21,-7890.9 3406.71,-7885.9 3402.21,-7895.9 3402.21,-7895.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2__plus0 -->\r\n",
       "<g id=\"node130\" class=\"node\"><title>transformer_3enc_transformer2__plus0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3402.21\" cy=\"-8019\" rx=\"130.345\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3402.21\" y=\"-8015.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2__plus0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2__plus0&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge152\" class=\"edge\"><title>transformer_3enc_transformer2__plus0&#45;&gt;transformer_3enc_transformer1_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3506.86,-7996.31C3590.64,-7972.1 3694.21,-7923.64 3694.21,-7832 3694.21,-7832 3694.21,-7832 3694.21,-6232 3694.21,-6174.24 3671.05,-6109.87 3655.95,-6074.02\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3497.01,-7999.07 3505.43,-7992.03 3501.83,-7997.72 3506.64,-7996.37 3506.64,-7996.37 3506.64,-7996.37 3501.83,-7997.72 3507.86,-8000.7 3497.01,-7999.07 3497.01,-7999.07\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2__plus0&#45;&gt;transformer_3enc_transformer2_dropout0_fwd -->\r\n",
       "<g id=\"edge151\" class=\"edge\"><title>transformer_3enc_transformer2__plus0&#45;&gt;transformer_3enc_transformer2_dropout0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3402.21,-7979.74C3402.21,-7971.2 3402.21,-7962.3 3402.21,-7954.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3402.21,-7989.9 3397.71,-7979.9 3402.21,-7984.9 3402.21,-7979.9 3402.21,-7979.9 3402.21,-7979.9 3402.21,-7984.9 3406.71,-7979.9 3402.21,-7989.9 3402.21,-7989.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_layernorm0_layernorm0 -->\r\n",
       "<g id=\"node131\" class=\"node\"><title>transformer_3enc_transformer2_layernorm0_layernorm0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3307.21\" cy=\"-8113\" rx=\"181.24\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3307.21\" y=\"-8109.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_layernorm0_layernorm0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer2__plus0 -->\r\n",
       "<g id=\"edge153\" class=\"edge\"><title>transformer_3enc_transformer2_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer2__plus0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3343.2,-8077.15C3353.35,-8067.32 3364.24,-8056.77 3373.87,-8047.44\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3335.97,-8084.15 3340.02,-8073.96 3339.56,-8080.67 3343.15,-8077.19 3343.15,-8077.19 3343.15,-8077.19 3339.56,-8080.67 3346.29,-8080.42 3335.97,-8084.15 3335.97,-8084.15\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0_ffn_1_fwd -->\r\n",
       "<g id=\"node132\" class=\"node\"><title>transformer_3enc_transformer2_positionwiseffn0_ffn_1_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3176.21\" cy=\"-8207\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3176.21\" y=\"-8210.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3176.21\" y=\"-8195.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1024</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0_ffn_1_fwd&#45;&gt;transformer_3enc_transformer2_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge154\" class=\"edge\"><title>transformer_3enc_transformer2_positionwiseffn0_ffn_1_fwd&#45;&gt;transformer_3enc_transformer2_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3219.47,-8175.62C3235.17,-8164.59 3252.8,-8152.21 3268.12,-8141.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3210.97,-8181.59 3216.57,-8172.16 3215.06,-8178.71 3219.16,-8175.84 3219.16,-8175.84 3219.16,-8175.84 3215.06,-8178.71 3221.74,-8179.52 3210.97,-8181.59 3210.97,-8181.59\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0_relu0_fwd -->\r\n",
       "<g id=\"node133\" class=\"node\"><title>transformer_3enc_transformer2_positionwiseffn0_relu0_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"3158.21\" cy=\"-8301\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3158.21\" y=\"-8304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3158.21\" y=\"-8289.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0_relu0_fwd&#45;&gt;transformer_3enc_transformer2_positionwiseffn0_ffn_1_fwd -->\r\n",
       "<g id=\"edge155\" class=\"edge\"><title>transformer_3enc_transformer2_positionwiseffn0_relu0_fwd&#45;&gt;transformer_3enc_transformer2_positionwiseffn0_ffn_1_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3165.66,-8261.93C3167.36,-8253.22 3169.14,-8244.12 3170.75,-8235.93\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3163.71,-8271.9 3161.21,-8261.22 3164.67,-8266.99 3165.63,-8262.08 3165.63,-8262.08 3165.63,-8262.08 3164.67,-8266.99 3170.05,-8262.95 3163.71,-8271.9 3163.71,-8271.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0_ffn_2_fwd -->\r\n",
       "<g id=\"node134\" class=\"node\"><title>transformer_3enc_transformer2_positionwiseffn0_ffn_2_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3141.21\" cy=\"-8395\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3141.21\" y=\"-8398.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3141.21\" y=\"-8383.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">128</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0_ffn_2_fwd&#45;&gt;transformer_3enc_transformer2_positionwiseffn0_relu0_fwd -->\r\n",
       "<g id=\"edge156\" class=\"edge\"><title>transformer_3enc_transformer2_positionwiseffn0_ffn_2_fwd&#45;&gt;transformer_3enc_transformer2_positionwiseffn0_relu0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3148.24,-8355.93C3149.85,-8347.22 3151.54,-8338.12 3153.05,-8329.93\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3146.4,-8365.9 3143.8,-8355.25 3147.31,-8360.98 3148.22,-8356.06 3148.22,-8356.06 3148.22,-8356.06 3147.31,-8360.98 3152.65,-8356.88 3146.4,-8365.9 3146.4,-8365.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0_dropout0_fwd -->\r\n",
       "<g id=\"node135\" class=\"node\"><title>transformer_3enc_transformer2_positionwiseffn0_dropout0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3071.21\" cy=\"-8489\" rx=\"208.116\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3071.21\" y=\"-8485.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_positionwiseffn0_dropout0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0_dropout0_fwd&#45;&gt;transformer_3enc_transformer2_positionwiseffn0_ffn_2_fwd -->\r\n",
       "<g id=\"edge157\" class=\"edge\"><title>transformer_3enc_transformer2_positionwiseffn0_dropout0_fwd&#45;&gt;transformer_3enc_transformer2_positionwiseffn0_ffn_2_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3098.84,-8451.68C3106.12,-8442.12 3113.85,-8431.96 3120.68,-8422.99\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3092.59,-8459.9 3095.07,-8449.21 3095.62,-8455.92 3098.65,-8451.94 3098.65,-8451.94 3098.65,-8451.94 3095.62,-8455.92 3102.23,-8454.66 3092.59,-8459.9 3092.59,-8459.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0__plus0 -->\r\n",
       "<g id=\"node136\" class=\"node\"><title>transformer_3enc_transformer2_positionwiseffn0__plus0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3071.21\" cy=\"-8583\" rx=\"184.187\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3071.21\" y=\"-8579.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_positionwiseffn0__plus0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer2_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge159\" class=\"edge\"><title>transformer_3enc_transformer2_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer2_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3223.35,-8561.11C3247.94,-8551.5 3270.94,-8537.72 3288.21,-8518 3324.36,-8476.72 3307.21,-8450.88 3307.21,-8396 3307.21,-8396 3307.21,-8396 3307.21,-8300 3307.21,-8243.97 3307.21,-8178.46 3307.21,-8142.04\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3213.86,-8564.59 3221.7,-8556.92 3218.56,-8562.87 3223.25,-8561.15 3223.25,-8561.15 3223.25,-8561.15 3218.56,-8562.87 3224.8,-8565.37 3213.86,-8564.59 3213.86,-8564.59\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer2_positionwiseffn0_dropout0_fwd -->\r\n",
       "<g id=\"edge158\" class=\"edge\"><title>transformer_3enc_transformer2_positionwiseffn0__plus0&#45;&gt;transformer_3enc_transformer2_positionwiseffn0_dropout0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3071.21,-8543.74C3071.21,-8535.2 3071.21,-8526.3 3071.21,-8518.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3071.21,-8553.9 3066.71,-8543.9 3071.21,-8548.9 3071.21,-8543.9 3071.21,-8543.9 3071.21,-8543.9 3071.21,-8548.9 3075.71,-8543.9 3071.21,-8553.9 3071.21,-8553.9\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"node137\" class=\"node\"><title>transformer_3enc_transformer2_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2882.21\" cy=\"-8677\" rx=\"235.671\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2882.21\" y=\"-8673.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_transformer2_positionwiseffn0_layernorm0_layernorm0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_transformer2_positionwiseffn0_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer2_positionwiseffn0__plus0 -->\r\n",
       "<g id=\"edge160\" class=\"edge\"><title>transformer_3enc_transformer2_positionwiseffn0_layernorm0_layernorm0&#45;&gt;transformer_3enc_transformer2_positionwiseffn0__plus0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2947.26,-8644.34C2969.66,-8633.43 2994.53,-8621.33 3016.07,-8610.84\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2938.15,-8648.77 2945.17,-8640.35 2942.65,-8646.58 2947.14,-8644.39 2947.14,-8644.39 2947.14,-8644.39 2942.65,-8646.58 2949.11,-8648.44 2938.15,-8648.77 2938.15,-8648.77\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_sequencemask0 -->\r\n",
       "<g id=\"node138\" class=\"node\"><title>transformer_3enc_sequencemask0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2834.21\" cy=\"-8771\" rx=\"114.255\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2834.21\" y=\"-8767.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">transformer_3enc_sequencemask0</text>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_sequencemask0&#45;&gt;IL_valid_length -->\r\n",
       "<g id=\"edge162\" class=\"edge\"><title>transformer_3enc_sequencemask0&#45;&gt;IL_valid_length</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2715.14,-8760.74C2604.01,-8744.83 2455.21,-8701.57 2455.21,-8584 2455.21,-8584 2455.21,-8584 2455.21,-1062 2455.21,-1004.21 2457.19,-978.592 2500.21,-940 2529.67,-913.576 2635.94,-893.671 2701.95,-883.519\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2725.1,-8762.11 2714.58,-8765.21 2720.14,-8761.43 2715.19,-8760.75 2715.19,-8760.75 2715.19,-8760.75 2720.14,-8761.43 2715.8,-8756.29 2725.1,-8762.11 2725.1,-8762.11\"/>\r\n",
       "</g>\r\n",
       "<!-- transformer_3enc_sequencemask0&#45;&gt;transformer_3enc_transformer2_positionwiseffn0_layernorm0_layernorm0 -->\r\n",
       "<g id=\"edge161\" class=\"edge\"><title>transformer_3enc_sequencemask0&#45;&gt;transformer_3enc_transformer2_positionwiseffn0_layernorm0_layernorm0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2853.58,-8732.87C2858.22,-8723.99 2863.09,-8714.65 2867.47,-8706.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2848.87,-8741.9 2849.51,-8730.95 2851.19,-8737.46 2853.5,-8733.03 2853.5,-8733.03 2853.5,-8733.03 2851.19,-8737.46 2857.49,-8735.11 2848.87,-8741.9 2848.87,-8741.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_transpose0 -->\r\n",
       "<g id=\"node139\" class=\"node\"><title>ilnet0_transpose0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2834.21\" cy=\"-8865\" rx=\"62.1815\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2834.21\" y=\"-8861.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_transpose0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_transpose0&#45;&gt;transformer_3enc_sequencemask0 -->\r\n",
       "<g id=\"edge163\" class=\"edge\"><title>ilnet0_transpose0&#45;&gt;transformer_3enc_sequencemask0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2834.21,-8825.74C2834.21,-8817.2 2834.21,-8808.3 2834.21,-8800.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2834.21,-8835.9 2829.71,-8825.9 2834.21,-8830.9 2834.21,-8825.9 2834.21,-8825.9 2834.21,-8825.9 2834.21,-8830.9 2838.71,-8825.9 2834.21,-8835.9 2834.21,-8835.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"node140\" class=\"node\"><title>ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2834.21\" cy=\"-8959\" rx=\"135.149\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2834.21\" y=\"-8955.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_transpose0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_transpose0&#45;&gt;ilnet0_transpose0 -->\r\n",
       "<g id=\"edge164\" class=\"edge\"><title>ilnet0_convolutionalencoder0_transpose0&#45;&gt;ilnet0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2834.21,-8919.74C2834.21,-8911.2 2834.21,-8902.3 2834.21,-8894.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2834.21,-8929.9 2829.71,-8919.9 2834.21,-8924.9 2834.21,-8919.9 2834.21,-8919.9 2834.21,-8919.9 2834.21,-8924.9 2838.71,-8919.9 2834.21,-8929.9 2834.21,-8929.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv0_fwd -->\r\n",
       "<g id=\"node141\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv0_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"724.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"724.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"724.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1/1, 100</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv0_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge165\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv0_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M788.84,-9042.89C836.409,-9036.54 902.708,-9028.45 961.21,-9024 1611.08,-8974.59 2390.7,-8963.32 2699.14,-8960.75\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"778.682,-9044.26 787.992,-9038.46 783.637,-9043.59 788.592,-9042.92 788.592,-9042.92 788.592,-9042.92 783.637,-9043.59 789.193,-9047.38 778.682,-9044.26 778.682,-9044.26\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda0_max0 -->\r\n",
       "<g id=\"node142\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda0_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"228.21\" cy=\"-9147\" rx=\"228.421\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"228.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda0_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda0_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv0_fwd -->\r\n",
       "<g id=\"edge166\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda0_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M363.725,-9120.86C465.247,-9102.03 598.678,-9077.28 671.384,-9063.8\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"353.693,-9122.73 362.704,-9116.48 358.609,-9121.81 363.525,-9120.9 363.525,-9120.9 363.525,-9120.9 358.609,-9121.81 364.346,-9125.33 353.693,-9122.73 353.693,-9122.73\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu0_fwd -->\r\n",
       "<g id=\"node143\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu0_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"591.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"591.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"591.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu0_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda0_max0 -->\r\n",
       "<g id=\"edge167\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu0_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda0_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M536.775,-9226.2C481.605,-9212.22 395,-9190.27 327.567,-9173.18\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"546.7,-9228.72 535.9,-9230.62 541.853,-9227.49 537.006,-9226.26 537.006,-9226.26 537.006,-9226.26 541.853,-9227.49 538.112,-9221.9 546.7,-9228.72 546.7,-9228.72\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv1_fwd -->\r\n",
       "<g id=\"node144\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv1_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"1027.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1027.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1027.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2/1, 200</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv1_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge168\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv1_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1093.49,-9046.74C1171.41,-9040.67 1304.65,-9030.68 1419.21,-9024 1890.56,-8996.51 2450.82,-8974.26 2701.49,-8964.85\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1083.33,-9047.53 1092.95,-9042.26 1088.32,-9047.14 1093.3,-9046.75 1093.3,-9046.75 1093.3,-9046.75 1088.32,-9047.14 1093.65,-9051.24 1083.33,-9047.53 1083.33,-9047.53\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda1_max0 -->\r\n",
       "<g id=\"node145\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda1_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"702.21\" cy=\"-9147\" rx=\"228.421\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"702.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda1_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda1_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv1_fwd -->\r\n",
       "<g id=\"edge169\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda1_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv1_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M802.711,-9117.55C860.917,-9101.07 931.609,-9081.06 977.919,-9067.95\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"792.741,-9120.37 801.137,-9113.32 797.552,-9119.01 802.363,-9117.65 802.363,-9117.65 802.363,-9117.65 797.552,-9119.01 803.589,-9121.98 792.741,-9120.37 792.741,-9120.37\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu1_fwd -->\r\n",
       "<g id=\"node146\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu1_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"1071.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1071.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1071.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu1_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda1_max0 -->\r\n",
       "<g id=\"edge170\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu1_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda1_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1016.57,-9226.38C960.377,-9212.37 871.572,-9190.23 802.661,-9173.04\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1026.33,-9228.81 1015.54,-9230.76 1021.48,-9227.6 1016.63,-9226.39 1016.63,-9226.39 1016.63,-9226.39 1021.48,-9227.6 1017.72,-9222.03 1026.33,-9228.81 1026.33,-9228.81\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv2_fwd -->\r\n",
       "<g id=\"node147\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv2_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"1485.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1485.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1485.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3/1, 200</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv2_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge171\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv2_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1551.51,-9046.89C1626.62,-9041.14 1752.7,-9031.61 1861.21,-9024 2163.92,-9002.77 2519.75,-8979.9 2705.91,-8968.08\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1541.26,-9047.67 1550.88,-9042.42 1546.24,-9047.29 1551.23,-9046.91 1551.23,-9046.91 1551.23,-9046.91 1546.24,-9047.29 1551.57,-9051.4 1541.26,-9047.67 1541.26,-9047.67\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda2_max0 -->\r\n",
       "<g id=\"node148\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda2_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"1176.21\" cy=\"-9147\" rx=\"228.421\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1176.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda2_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda2_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv2_fwd -->\r\n",
       "<g id=\"edge172\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda2_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv2_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1272.8,-9117.24C1327.31,-9101.01 1393.07,-9081.43 1436.84,-9068.4\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1263.11,-9120.13 1271.41,-9112.96 1267.9,-9118.7 1272.69,-9117.27 1272.69,-9117.27 1272.69,-9117.27 1267.9,-9118.7 1273.97,-9121.59 1263.11,-9120.13 1263.11,-9120.13\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu2_fwd -->\r\n",
       "<g id=\"node149\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu2_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"1556.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1556.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1556.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu2_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda2_max0 -->\r\n",
       "<g id=\"edge173\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu2_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda2_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1501.08,-9226.65C1443.13,-9212.62 1350.63,-9190.23 1279.13,-9172.92\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1511.13,-9229.09 1500.35,-9231.11 1506.27,-9227.91 1501.41,-9226.73 1501.41,-9226.73 1501.41,-9226.73 1506.27,-9227.91 1502.47,-9222.36 1511.13,-9229.09 1511.13,-9229.09\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv3_fwd -->\r\n",
       "<g id=\"node150\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv3_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"1927.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1927.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1927.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4/1, 200</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv3_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge174\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv3_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1993.01,-9045.33C2144.51,-9029.96 2519.84,-8991.89 2713.83,-8972.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1982.92,-9046.35 1992.42,-9040.86 1987.9,-9045.84 1992.87,-9045.34 1992.87,-9045.34 1992.87,-9045.34 1987.9,-9045.84 1993.33,-9049.82 1982.92,-9046.35 1982.92,-9046.35\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda3_max0 -->\r\n",
       "<g id=\"node151\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda3_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"1650.21\" cy=\"-9147\" rx=\"228.421\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1650.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda3_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda3_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv3_fwd -->\r\n",
       "<g id=\"edge175\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda3_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv3_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1738.79,-9116.58C1785.76,-9100.98 1841.58,-9082.44 1880.21,-9069.61\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1729.22,-9119.76 1737.29,-9112.34 1733.96,-9118.18 1738.71,-9116.61 1738.71,-9116.61 1738.71,-9116.61 1733.96,-9118.18 1740.13,-9120.88 1729.22,-9119.76 1729.22,-9119.76\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu3_fwd -->\r\n",
       "<g id=\"node152\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu3_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"2052.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2052.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2052.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu3_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda3_max0 -->\r\n",
       "<g id=\"edge176\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu3_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda3_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1997.01,-9227.37C1935.65,-9213.32 1835.05,-9190.3 1757.96,-9172.66\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2006.88,-9229.63 1996.13,-9231.78 2002,-9228.51 1997.13,-9227.39 1997.13,-9227.39 1997.13,-9227.39 2002,-9228.51 1998.13,-9223.01 2006.88,-9229.63 2006.88,-9229.63\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv4_fwd -->\r\n",
       "<g id=\"node153\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv4_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"2337.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2337.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2337.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5/1, 200</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv4_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge177\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv4_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2400.32,-9040.32C2484.42,-9024.75 2634.17,-8997.03 2733.85,-8978.58\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2390.4,-9042.15 2399.41,-9035.91 2395.31,-9041.24 2400.23,-9040.33 2400.23,-9040.33 2400.23,-9040.33 2395.31,-9041.24 2401.05,-9044.76 2390.4,-9042.15 2390.4,-9042.15\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda4_max0 -->\r\n",
       "<g id=\"node154\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda4_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2124.21\" cy=\"-9147\" rx=\"228.421\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2124.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda4_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda4_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv4_fwd -->\r\n",
       "<g id=\"edge178\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda4_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv4_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2196.21,-9114.9C2228.93,-9100.77 2266.52,-9084.53 2294.66,-9072.38\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2186.68,-9119.02 2194.07,-9110.92 2191.27,-9117.04 2195.86,-9115.05 2195.86,-9115.05 2195.86,-9115.05 2191.27,-9117.04 2197.64,-9119.18 2186.68,-9119.02 2186.68,-9119.02\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu4_fwd -->\r\n",
       "<g id=\"node155\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu4_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"2347.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2347.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2347.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu4_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda4_max0 -->\r\n",
       "<g id=\"edge179\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu4_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda4_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2298.01,-9219.7C2266.03,-9206.51 2223.96,-9189.15 2189.23,-9174.82\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2307.6,-9223.66 2296.64,-9224 2302.98,-9221.75 2298.36,-9219.84 2298.36,-9219.84 2298.36,-9219.84 2302.98,-9221.75 2300.07,-9215.68 2307.6,-9223.66 2307.6,-9223.66\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv5_fwd -->\r\n",
       "<g id=\"node156\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv5_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"2683.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2683.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2683.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6/1, 100</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv5_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge180\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv5_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2727.57,-9024.97C2747.44,-9012.86 2770.81,-8998.63 2790.6,-8986.57\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2719,-9030.2 2725.19,-9021.15 2723.27,-9027.6 2727.54,-9024.99 2727.54,-9024.99 2727.54,-9024.99 2723.27,-9027.6 2729.88,-9028.84 2719,-9030.2 2719,-9030.2\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda5_max0 -->\r\n",
       "<g id=\"node157\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda5_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2598.21\" cy=\"-9147\" rx=\"228.421\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2598.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda5_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda5_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv5_fwd -->\r\n",
       "<g id=\"edge181\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda5_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv5_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2630.99,-9110.52C2640.57,-9100.15 2650.84,-9089.04 2659.72,-9079.43\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2624.18,-9117.9 2627.66,-9107.5 2627.57,-9114.22 2630.96,-9110.55 2630.96,-9110.55 2630.96,-9110.55 2627.57,-9114.22 2634.27,-9113.61 2624.18,-9117.9 2624.18,-9117.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu5_fwd -->\r\n",
       "<g id=\"node158\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu5_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"2687.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2687.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2687.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu5_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda5_max0 -->\r\n",
       "<g id=\"edge182\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu5_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda5_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2656.23,-9207.98C2646.15,-9197.56 2635.04,-9186.08 2625.27,-9175.97\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2663.36,-9215.35 2653.17,-9211.29 2659.88,-9211.75 2656.41,-9208.16 2656.41,-9208.16 2656.41,-9208.16 2659.88,-9211.75 2659.64,-9205.03 2663.36,-9215.35 2663.36,-9215.35\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv6_fwd -->\r\n",
       "<g id=\"node159\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv6_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"2986.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2986.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2986.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">7/1, 100</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv6_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge183\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv6_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2941.56,-9024.97C2921.55,-9012.86 2898.03,-8998.63 2878.11,-8986.57\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2950.19,-9030.2 2939.3,-9028.87 2945.91,-9027.61 2941.63,-9025.02 2941.63,-9025.02 2941.63,-9025.02 2945.91,-9027.61 2943.96,-9021.17 2950.19,-9030.2 2950.19,-9030.2\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda6_max0 -->\r\n",
       "<g id=\"node160\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda6_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3072.21\" cy=\"-9147\" rx=\"228.421\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3072.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda6_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda6_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv6_fwd -->\r\n",
       "<g id=\"edge184\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda6_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv6_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3039.04,-9110.52C3029.35,-9100.15 3018.96,-9089.04 3009.98,-9079.43\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3045.94,-9117.9 3035.82,-9113.66 3042.53,-9114.24 3039.11,-9110.59 3039.11,-9110.59 3039.11,-9110.59 3042.53,-9114.24 3042.4,-9107.52 3045.94,-9117.9 3045.94,-9117.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu6_fwd -->\r\n",
       "<g id=\"node161\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu6_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"2982.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2982.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2982.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu6_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda6_max0 -->\r\n",
       "<g id=\"edge185\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu6_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda6_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3013.54,-9207.98C3023.73,-9197.56 3034.96,-9186.08 3044.84,-9175.97\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3006.33,-9215.35 3010.1,-9205.05 3009.83,-9211.77 3013.32,-9208.2 3013.32,-9208.2 3013.32,-9208.2 3009.83,-9211.77 3016.54,-9211.34 3006.33,-9215.35 3006.33,-9215.35\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv7_fwd -->\r\n",
       "<g id=\"node162\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv7_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3374.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3374.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3374.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8/1, 100</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv7_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge186\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv7_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3310.47,-9041.14C3218.61,-9025.49 3047.99,-8996.42 2937.86,-8977.66\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3320.46,-9042.84 3309.85,-9045.6 3315.53,-9042 3310.6,-9041.16 3310.6,-9041.16 3310.6,-9041.16 3315.53,-9042 3311.36,-9036.73 3320.46,-9042.84 3320.46,-9042.84\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda7_max0 -->\r\n",
       "<g id=\"node163\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda7_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"3546.21\" cy=\"-9147\" rx=\"228.421\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3546.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda7_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda7_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv7_fwd -->\r\n",
       "<g id=\"edge187\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda7_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv7_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3486.22,-9113.91C3461.78,-9100.84 3434.24,-9086.11 3412.59,-9074.53\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3495.07,-9118.65 3484.13,-9117.9 3490.66,-9116.29 3486.25,-9113.93 3486.25,-9113.93 3486.25,-9113.93 3490.66,-9116.29 3488.38,-9109.96 3495.07,-9118.65 3495.07,-9118.65\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu7_fwd -->\r\n",
       "<g id=\"node164\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu7_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"3366.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3366.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3366.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu7_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda7_max0 -->\r\n",
       "<g id=\"edge188\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu7_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda7_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3411.77,-9216.71C3436.42,-9204.12 3467,-9188.49 3492.77,-9175.32\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3402.64,-9221.38 3409.49,-9212.82 3407.09,-9219.11 3411.54,-9216.83 3411.54,-9216.83 3411.54,-9216.83 3407.09,-9219.11 3413.59,-9220.84 3402.64,-9221.38 3402.64,-9221.38\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv8_fwd -->\r\n",
       "<g id=\"node165\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv8_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"3805.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3805.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3805.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">9/1, 100</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv8_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge189\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv8_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3739.29,-9045.75C3578.37,-9030.51 3163.51,-8991.2 2956.08,-8971.55\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3749.52,-9046.72 3739.14,-9050.26 3744.54,-9046.25 3739.56,-9045.78 3739.56,-9045.78 3739.56,-9045.78 3744.54,-9046.25 3739.99,-9041.3 3749.52,-9046.72 3749.52,-9046.72\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda8_max0 -->\r\n",
       "<g id=\"node166\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda8_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"4020.21\" cy=\"-9147\" rx=\"228.421\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4020.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda8_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda8_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv8_fwd -->\r\n",
       "<g id=\"edge190\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda8_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv8_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3947.93,-9115.07C3914.68,-9100.84 3876.38,-9084.45 3847.83,-9072.24\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3957.16,-9119.02 3946.19,-9119.22 3952.56,-9117.05 3947.96,-9115.08 3947.96,-9115.08 3947.96,-9115.08 3952.56,-9117.05 3949.73,-9110.95 3957.16,-9119.02 3957.16,-9119.02\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu8_fwd -->\r\n",
       "<g id=\"node167\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu8_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"3795.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3795.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"3795.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu8_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda8_max0 -->\r\n",
       "<g id=\"edge191\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu8_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda8_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3844.58,-9219.81C3876.84,-9206.62 3919.35,-9189.24 3954.46,-9174.88\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3834.92,-9223.76 3842.47,-9215.81 3839.55,-9221.87 3844.17,-9219.98 3844.17,-9219.98 3844.17,-9219.98 3839.55,-9221.87 3845.88,-9224.14 3834.92,-9223.76 3834.92,-9223.76\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv9_fwd -->\r\n",
       "<g id=\"node168\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv9_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"4258.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4258.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"4258.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">10/1, 100</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv9_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge192\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv9_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4192.1,-9047C4115.07,-9041.23 3983.94,-9031.56 3871.21,-9024 3544.56,-9002.1 3159.83,-8979.09 2963.57,-8967.54\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4202.15,-9047.76 4191.84,-9051.5 4197.16,-9047.38 4192.17,-9047.01 4192.17,-9047.01 4192.17,-9047.01 4197.16,-9047.38 4192.51,-9042.52 4202.15,-9047.76 4202.15,-9047.76\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda9_max0 -->\r\n",
       "<g id=\"node169\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda9_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"4494.21\" cy=\"-9147\" rx=\"228.421\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4494.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda9_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda9_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv9_fwd -->\r\n",
       "<g id=\"edge193\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda9_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv9_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4416.2,-9115.59C4378.51,-9100.9 4334.66,-9083.8 4302.73,-9071.35\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4425.63,-9119.27 4414.68,-9119.83 4420.97,-9117.45 4416.32,-9115.63 4416.32,-9115.63 4416.32,-9115.63 4420.97,-9117.45 4417.95,-9111.44 4425.63,-9119.27 4425.63,-9119.27\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu9_fwd -->\r\n",
       "<g id=\"node170\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu9_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"4247.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4247.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"4247.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu9_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda9_max0 -->\r\n",
       "<g id=\"edge194\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu9_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda9_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4297.81,-9221.15C4333.87,-9207.72 4382.85,-9189.48 4422.88,-9174.57\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4288,-9224.81 4295.8,-9217.1 4292.68,-9223.06 4297.37,-9221.32 4297.37,-9221.32 4297.37,-9221.32 4292.68,-9223.06 4298.94,-9225.53 4288,-9224.81 4288,-9224.81\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv10_fwd -->\r\n",
       "<g id=\"node171\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv10_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"4723.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4723.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"4723.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">15/1, 160</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv10_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge195\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv10_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4656.76,-9046.78C4577.6,-9040.7 4441.32,-9030.62 4324.21,-9024 3823.52,-8995.68 3227.54,-8973.58 2967.08,-8964.5\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4667.08,-9047.58 4656.76,-9051.3 4662.09,-9047.19 4657.1,-9046.81 4657.1,-9046.81 4657.1,-9046.81 4662.09,-9047.19 4657.45,-9042.32 4667.08,-9047.58 4667.08,-9047.58\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda10_max0 -->\r\n",
       "<g id=\"node172\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda10_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"4972.21\" cy=\"-9147\" rx=\"231.457\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4972.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda10_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda10_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv10_fwd -->\r\n",
       "<g id=\"edge196\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda10_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv10_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4890.57,-9115.84C4849.97,-9100.83 4802.44,-9083.27 4768.43,-9070.71\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4900.19,-9119.39 4889.25,-9120.15 4895.5,-9117.66 4890.81,-9115.92 4890.81,-9115.92 4890.81,-9115.92 4895.5,-9117.66 4892.37,-9111.7 4900.19,-9119.39 4900.19,-9119.39\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu10_fwd -->\r\n",
       "<g id=\"node173\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu10_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"4712.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4712.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"4712.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu10_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda10_max0 -->\r\n",
       "<g id=\"edge197\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu10_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda10_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4763.57,-9221.83C4801.76,-9208.31 4854.45,-9189.67 4897.33,-9174.5\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4753.7,-9225.32 4761.62,-9217.74 4758.41,-9223.65 4763.12,-9221.98 4763.12,-9221.98 4763.12,-9221.98 4758.41,-9223.65 4764.62,-9226.23 4753.7,-9225.32 4753.7,-9225.32\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv11_fwd -->\r\n",
       "<g id=\"node174\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv11_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"5196.21\" cy=\"-9053\" rx=\"56.8351\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5196.21\" y=\"-9056.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Convolution</text>\r\n",
       "<text text-anchor=\"middle\" x=\"5196.21\" y=\"-9041.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">20/1, 160</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_conv11_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0 -->\r\n",
       "<g id=\"edge198\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_conv11_fwd&#45;&gt;ilnet0_convolutionalencoder0_transpose0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5130.3,-9046.73C5049.84,-9040.47 4909.62,-9030.11 4789.21,-9024 4104.97,-8989.27 3285,-8969.53 2968.2,-8962.73\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5140.29,-9047.51 5129.97,-9051.22 5135.3,-9047.12 5130.32,-9046.74 5130.32,-9046.74 5130.32,-9046.74 5135.3,-9047.12 5130.67,-9042.25 5140.29,-9047.51 5140.29,-9047.51\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda11_max0 -->\r\n",
       "<g id=\"node175\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda11_max0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"5453.21\" cy=\"-9147\" rx=\"231.457\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5453.21\" y=\"-9143.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda11_max0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda11_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv11_fwd -->\r\n",
       "<g id=\"edge199\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda11_max0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_conv11_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5369.72,-9116.11C5327.24,-9100.9 5277.24,-9083.01 5241.86,-9070.34\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5379.22,-9119.51 5368.29,-9120.38 5374.51,-9117.83 5369.81,-9116.14 5369.81,-9116.14 5369.81,-9116.14 5374.51,-9117.83 5371.32,-9111.91 5379.22,-9119.51 5379.22,-9119.51\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu11_fwd -->\r\n",
       "<g id=\"node176\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu11_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"5185.21\" cy=\"-9241\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5185.21\" y=\"-9244.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"5185.21\" y=\"-9229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_relu11_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda11_max0 -->\r\n",
       "<g id=\"edge200\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_relu11_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_hybridlambda11_max0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5236.79,-9222.29C5276.34,-9208.72 5331.56,-9189.76 5376.32,-9174.39\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5227.09,-9225.63 5235.08,-9218.12 5231.81,-9224 5236.54,-9222.38 5236.54,-9222.38 5236.54,-9222.38 5231.81,-9224 5238,-9226.63 5227.09,-9225.63 5227.09,-9225.63\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0 -->\r\n",
       "<g id=\"node177\" class=\"node\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2834.21\" cy=\"-9335\" rx=\"186.044\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2834.21\" y=\"-9331.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_hybridconcurrent0_concat0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu0_fwd -->\r\n",
       "<g id=\"edge201\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2641.04,-9329.19C2308.44,-9320.46 1606.16,-9300.08 1013.21,-9270 877.732,-9263.13 718.011,-9251.59 639.598,-9245.7\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2651.26,-9329.45 2641.15,-9333.69 2646.26,-9329.32 2641.27,-9329.19 2641.27,-9329.19 2641.27,-9329.19 2646.26,-9329.32 2641.38,-9324.69 2651.26,-9329.45 2651.26,-9329.45\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu1_fwd -->\r\n",
       "<g id=\"edge202\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu1_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2645.89,-9326.03C2387.18,-9314.83 1907.3,-9293.21 1498.21,-9270 1360.99,-9262.21 1199.1,-9251.06 1119.86,-9245.47\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2656.14,-9326.47 2645.96,-9330.53 2651.15,-9326.25 2646.15,-9326.04 2646.15,-9326.04 2646.15,-9326.04 2651.15,-9326.25 2646.35,-9321.54 2656.14,-9326.47 2656.14,-9326.47\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu2_fwd -->\r\n",
       "<g id=\"edge203\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu2_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2657.45,-9321.28C2360.29,-9299.88 1776.26,-9257.84 1604.69,-9245.49\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2667.46,-9322 2657.16,-9325.77 2662.48,-9321.64 2657.49,-9321.28 2657.49,-9321.28 2657.49,-9321.28 2662.48,-9321.64 2657.81,-9316.79 2667.46,-9322 2667.46,-9322\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu3_fwd -->\r\n",
       "<g id=\"edge204\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu3_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2678.39,-9315.73C2569.39,-9302.94 2420.41,-9285.45 2289.21,-9270 2223.79,-9262.29 2148.21,-9253.36 2100.32,-9247.69\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2688.48,-9316.91 2678.02,-9320.22 2683.51,-9316.33 2678.54,-9315.75 2678.54,-9315.75 2678.54,-9315.75 2683.51,-9316.33 2679.07,-9311.28 2688.48,-9316.91 2688.48,-9316.91\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu4_fwd -->\r\n",
       "<g id=\"edge205\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu4_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2708.93,-9310.33C2605.72,-9290.84 2465.1,-9264.27 2393.39,-9250.72\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2718.8,-9312.2 2708.14,-9314.76 2713.89,-9311.27 2708.97,-9310.34 2708.97,-9310.34 2708.97,-9310.34 2713.89,-9311.27 2709.81,-9305.92 2718.8,-9312.2 2718.8,-9312.2\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu5_fwd -->\r\n",
       "<g id=\"edge206\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu5_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2781.87,-9301.24C2761.34,-9288.39 2738.4,-9274.04 2720.24,-9262.67\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2790.5,-9306.65 2779.64,-9305.16 2786.27,-9303.99 2782.03,-9301.34 2782.03,-9301.34 2782.03,-9301.34 2786.27,-9303.99 2784.41,-9297.53 2790.5,-9306.65 2790.5,-9306.65\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu6_fwd -->\r\n",
       "<g id=\"edge207\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu6_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2886.9,-9301.24C2907.58,-9288.39 2930.68,-9274.04 2948.95,-9262.67\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2878.21,-9306.65 2884.33,-9297.54 2882.46,-9304.01 2886.71,-9301.37 2886.71,-9301.37 2886.71,-9301.37 2882.46,-9304.01 2889.08,-9305.19 2878.21,-9306.65 2878.21,-9306.65\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu7_fwd -->\r\n",
       "<g id=\"edge208\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu7_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2965.86,-9311.23C3080.83,-9291.35 3241.19,-9263.62 3319.48,-9250.08\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2955.93,-9312.95 2965.02,-9306.81 2960.86,-9312.1 2965.78,-9311.25 2965.78,-9311.25 2965.78,-9311.25 2960.86,-9312.1 2966.55,-9315.68 2955.93,-9312.95 2955.93,-9312.95\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu8_fwd -->\r\n",
       "<g id=\"edge209\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu8_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3000.43,-9318.09C3224.61,-9296.63 3611.37,-9259.6 3746.73,-9246.64\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2990.21,-9319.07 2999.74,-9313.63 2995.19,-9318.59 3000.17,-9318.11 3000.17,-9318.11 3000.17,-9318.11 2995.19,-9318.59 3000.6,-9322.59 2990.21,-9319.07 2990.21,-9319.07\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu9_fwd -->\r\n",
       "<g id=\"edge210\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu9_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3016.18,-9323.02C3220.05,-9310.62 3560.36,-9289.6 3853.21,-9270 3977.74,-9261.66 4124.34,-9251.03 4198.69,-9245.58\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3005.97,-9323.64 3015.68,-9318.55 3010.96,-9323.34 3015.95,-9323.04 3015.95,-9323.04 3015.95,-9323.04 3010.96,-9323.34 3016.23,-9327.53 3005.97,-9323.64 3005.97,-9323.64\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu10_fwd -->\r\n",
       "<g id=\"edge211\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu10_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3024.88,-9327.24C3305.42,-9316.95 3845.9,-9295.79 4305.21,-9270 4434.8,-9262.72 4587.41,-9251.52 4663.68,-9245.74\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3014.59,-9327.62 3024.42,-9322.75 3019.59,-9327.43 3024.59,-9327.25 3024.59,-9327.25 3024.59,-9327.25 3019.59,-9327.43 3024.75,-9331.75 3014.59,-9327.62 3014.59,-9327.62\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu11_fwd -->\r\n",
       "<g id=\"edge212\" class=\"edge\"><title>ilnet0_convolutionalencoder0_hybridconcurrent0_concat0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_relu11_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3028.01,-9329.79C3376.69,-9321.74 4132.88,-9302.03 4770.21,-9270 4902.91,-9263.33 5059.25,-9251.78 5136.69,-9245.82\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3017.81,-9330.03 3027.7,-9325.3 3022.81,-9329.91 3027.81,-9329.8 3027.81,-9329.8 3027.81,-9329.8 3022.81,-9329.91 3027.91,-9334.3 3017.81,-9330.03 3017.81,-9330.03\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0_hybridsequential0_dense0_fwd -->\r\n",
       "<g id=\"node178\" class=\"node\"><title>ilnet0_convolutionalencoder0_highway0_hybridsequential0_dense0_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"2743.21\" cy=\"-9429\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2743.21\" y=\"-9432.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2743.21\" y=\"-9417.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3440</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0_hybridsequential0_dense0_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_concat0 -->\r\n",
       "<g id=\"edge213\" class=\"edge\"><title>ilnet0_convolutionalencoder0_highway0_hybridsequential0_dense0_fwd&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_concat0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2776.16,-9394.69C2786.19,-9384.55 2797.1,-9373.52 2806.72,-9363.79\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2769.04,-9401.88 2772.88,-9391.61 2772.56,-9398.33 2776.08,-9394.77 2776.08,-9394.77 2776.08,-9394.77 2772.56,-9398.33 2779.28,-9397.94 2769.04,-9401.88 2769.04,-9401.88\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0_split0 -->\r\n",
       "<g id=\"node179\" class=\"node\"><title>ilnet0_convolutionalencoder0_highway0_split0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2656.21\" cy=\"-9523\" rx=\"151.328\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2656.21\" y=\"-9519.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_highway0_split0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0_split0&#45;&gt;ilnet0_convolutionalencoder0_highway0_hybridsequential0_dense0_fwd -->\r\n",
       "<g id=\"edge214\" class=\"edge\"><title>ilnet0_convolutionalencoder0_highway0_split0&#45;&gt;ilnet0_convolutionalencoder0_highway0_hybridsequential0_dense0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2689.19,-9487.13C2698.85,-9476.91 2709.25,-9465.91 2718.32,-9456.32\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2682.31,-9494.4 2685.91,-9484.04 2685.75,-9490.76 2689.18,-9487.13 2689.18,-9487.13 2689.18,-9487.13 2685.75,-9490.76 2692.45,-9490.22 2682.31,-9494.4 2682.31,-9494.4\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0_sigmoid0 -->\r\n",
       "<g id=\"node180\" class=\"node\"><title>ilnet0_convolutionalencoder0_highway0_sigmoid0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2656.21\" cy=\"-9617\" rx=\"162.704\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2656.21\" y=\"-9613.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_highway0_sigmoid0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0_sigmoid0&#45;&gt;ilnet0_convolutionalencoder0_highway0_split0 -->\r\n",
       "<g id=\"edge215\" class=\"edge\"><title>ilnet0_convolutionalencoder0_highway0_sigmoid0&#45;&gt;ilnet0_convolutionalencoder0_highway0_split0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2656.21,-9577.74C2656.21,-9569.2 2656.21,-9560.3 2656.21,-9552.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2656.21,-9587.9 2651.71,-9577.9 2656.21,-9582.9 2656.21,-9577.9 2656.21,-9577.9 2656.21,-9577.9 2656.21,-9582.9 2660.71,-9577.9 2656.21,-9587.9 2656.21,-9587.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0__rminusscalar0 -->\r\n",
       "<g id=\"node181\" class=\"node\"><title>ilnet0_convolutionalencoder0_highway0__rminusscalar0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2717.21\" cy=\"-9711\" rx=\"180.651\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2717.21\" y=\"-9707.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_highway0__rminusscalar0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0__rminusscalar0&#45;&gt;ilnet0_convolutionalencoder0_highway0_sigmoid0 -->\r\n",
       "<g id=\"edge216\" class=\"edge\"><title>ilnet0_convolutionalencoder0_highway0__rminusscalar0&#45;&gt;ilnet0_convolutionalencoder0_highway0_sigmoid0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2692.91,-9673.35C2686.85,-9664.21 2680.46,-9654.57 2674.73,-9645.93\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2698.58,-9681.9 2689.3,-9676.05 2695.81,-9677.73 2693.05,-9673.56 2693.05,-9673.56 2693.05,-9673.56 2695.81,-9677.73 2696.8,-9671.08 2698.58,-9681.9 2698.58,-9681.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0__mul0 -->\r\n",
       "<g id=\"node182\" class=\"node\"><title>ilnet0_convolutionalencoder0_highway0__mul0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2717.21\" cy=\"-9805\" rx=\"153.685\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2717.21\" y=\"-9801.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_highway0__mul0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0__mul0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_concat0 -->\r\n",
       "<g id=\"edge218\" class=\"edge\"><title>ilnet0_convolutionalencoder0_highway0__mul0&#45;&gt;ilnet0_convolutionalencoder0_hybridconcurrent0_concat0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2844.31,-9782.54C2868.18,-9773.09 2890.78,-9759.5 2907.21,-9740 2942.57,-9698.04 2926.21,-9672.88 2926.21,-9618 2926.21,-9618 2926.21,-9618 2926.21,-9522 2926.21,-9460.58 2885.4,-9398.47 2858.14,-9363.83\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2834.74,-9786.09 2842.55,-9778.39 2839.43,-9784.35 2844.12,-9782.61 2844.12,-9782.61 2844.12,-9782.61 2839.43,-9784.35 2845.68,-9786.83 2834.74,-9786.09 2834.74,-9786.09\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0__mul0&#45;&gt;ilnet0_convolutionalencoder0_highway0__rminusscalar0 -->\r\n",
       "<g id=\"edge217\" class=\"edge\"><title>ilnet0_convolutionalencoder0_highway0__mul0&#45;&gt;ilnet0_convolutionalencoder0_highway0__rminusscalar0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2717.21,-9765.74C2717.21,-9757.2 2717.21,-9748.3 2717.21,-9740.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2717.21,-9775.9 2712.71,-9765.9 2717.21,-9770.9 2717.21,-9765.9 2717.21,-9765.9 2717.21,-9765.9 2717.21,-9770.9 2721.71,-9765.9 2717.21,-9775.9 2717.21,-9775.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0_relu0_fwd -->\r\n",
       "<g id=\"node183\" class=\"node\"><title>ilnet0_convolutionalencoder0_highway0_relu0_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"2396.21\" cy=\"-9617\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2396.21\" y=\"-9620.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2396.21\" y=\"-9605.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0_relu0_fwd&#45;&gt;ilnet0_convolutionalencoder0_highway0_split0 -->\r\n",
       "<g id=\"edge219\" class=\"edge\"><title>ilnet0_convolutionalencoder0_highway0_relu0_fwd&#45;&gt;ilnet0_convolutionalencoder0_highway0_split0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2447.17,-9597.97C2486.86,-9583.92 2542.38,-9564.28 2586.23,-9548.76\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2437.7,-9601.32 2445.62,-9593.74 2442.41,-9599.65 2447.12,-9597.98 2447.12,-9597.98 2447.12,-9597.98 2442.41,-9599.65 2448.62,-9602.23 2437.7,-9601.32 2437.7,-9601.32\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0__mul1 -->\r\n",
       "<g id=\"node184\" class=\"node\"><title>ilnet0_convolutionalencoder0_highway0__mul1</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2365.21\" cy=\"-9711\" rx=\"153.685\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2365.21\" y=\"-9707.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_highway0__mul1</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0__mul1&#45;&gt;ilnet0_convolutionalencoder0_highway0_sigmoid0 -->\r\n",
       "<g id=\"edge220\" class=\"edge\"><title>ilnet0_convolutionalencoder0_highway0__mul1&#45;&gt;ilnet0_convolutionalencoder0_highway0_sigmoid0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2451.22,-9682.81C2491.55,-9670.06 2539.26,-9654.97 2578.49,-9642.57\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2441.67,-9685.83 2449.85,-9678.52 2446.43,-9684.32 2451.2,-9682.81 2451.2,-9682.81 2451.2,-9682.81 2446.43,-9684.32 2452.56,-9687.1 2441.67,-9685.83 2441.67,-9685.83\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0__mul1&#45;&gt;ilnet0_convolutionalencoder0_highway0_relu0_fwd -->\r\n",
       "<g id=\"edge221\" class=\"edge\"><title>ilnet0_convolutionalencoder0_highway0__mul1&#45;&gt;ilnet0_convolutionalencoder0_highway0_relu0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2377.88,-9672.41C2380.9,-9663.44 2384.07,-9654.04 2386.91,-9645.61\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2374.68,-9681.9 2373.61,-9670.98 2376.28,-9677.16 2377.87,-9672.42 2377.87,-9672.42 2377.87,-9672.42 2376.28,-9677.16 2382.14,-9673.86 2374.68,-9681.9 2374.68,-9681.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0__plus0 -->\r\n",
       "<g id=\"node185\" class=\"node\"><title>ilnet0_convolutionalencoder0_highway0__plus0</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2626.21\" cy=\"-9899\" rx=\"155.454\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2626.21\" y=\"-9895.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_convolutionalencoder0_highway0__plus0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0__plus0&#45;&gt;ilnet0_convolutionalencoder0_highway0__mul0 -->\r\n",
       "<g id=\"edge222\" class=\"edge\"><title>ilnet0_convolutionalencoder0_highway0__plus0&#45;&gt;ilnet0_convolutionalencoder0_highway0__mul0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2660.73,-9863.1C2670.39,-9853.34 2680.75,-9842.86 2689.93,-9833.58\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2653.51,-9870.4 2657.35,-9860.12 2657.03,-9866.84 2660.55,-9863.29 2660.55,-9863.29 2660.55,-9863.29 2657.03,-9866.84 2663.75,-9866.45 2653.51,-9870.4 2653.51,-9870.4\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_convolutionalencoder0_highway0__plus0&#45;&gt;ilnet0_convolutionalencoder0_highway0__mul1 -->\r\n",
       "<g id=\"edge223\" class=\"edge\"><title>ilnet0_convolutionalencoder0_highway0__plus0&#45;&gt;ilnet0_convolutionalencoder0_highway0__mul1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2579.56,-9864.75C2529.31,-9828.95 2450.3,-9772.64 2403.54,-9739.32\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2587.98,-9870.75 2577.22,-9868.62 2583.91,-9867.85 2579.84,-9864.95 2579.84,-9864.95 2579.84,-9864.95 2583.91,-9867.85 2582.45,-9861.29 2587.98,-9870.75 2587.98,-9870.75\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_reshape2 -->\r\n",
       "<g id=\"node186\" class=\"node\"><title>ilnet0_reshape2</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2662.21\" cy=\"-9993\" rx=\"56.1991\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2662.21\" y=\"-9989.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_reshape2</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_reshape2&#45;&gt;ilnet0_convolutionalencoder0_highway0__plus0 -->\r\n",
       "<g id=\"edge224\" class=\"edge\"><title>ilnet0_reshape2&#45;&gt;ilnet0_convolutionalencoder0_highway0__plus0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2647.72,-9954.97C2644.23,-9946.05 2640.56,-9936.66 2637.25,-9928.22\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2651.41,-9964.4 2643.57,-9956.72 2649.59,-9959.74 2647.77,-9955.08 2647.77,-9955.08 2647.77,-9955.08 2649.59,-9959.74 2651.96,-9953.44 2651.41,-9964.4 2651.41,-9964.4\"/>\r\n",
       "</g>\r\n",
       "<!-- T -->\r\n",
       "<g id=\"node187\" class=\"node\"><title>T</title>\r\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"2846.21\" cy=\"-9899\" rx=\"47\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2846.21\" y=\"-9895.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_reshape0 -->\r\n",
       "<g id=\"node188\" class=\"node\"><title>ilnet0_reshape0</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2837.21\" cy=\"-9993\" rx=\"56.1991\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-9989.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_reshape0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_reshape0&#45;&gt;T -->\r\n",
       "<g id=\"edge225\" class=\"edge\"><title>ilnet0_reshape0&#45;&gt;T</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2840.95,-9953.74C2841.79,-9945.2 2842.66,-9936.3 2843.45,-9928.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2839.96,-9963.9 2836.45,-9953.51 2840.45,-9958.92 2840.93,-9953.94 2840.93,-9953.94 2840.93,-9953.94 2840.45,-9958.92 2845.41,-9954.38 2839.96,-9963.9 2839.96,-9963.9\"/>\r\n",
       "</g>\r\n",
       "<!-- P -->\r\n",
       "<g id=\"node189\" class=\"node\"><title>P</title>\r\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"2967.21\" cy=\"-9899\" rx=\"47\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2967.21\" y=\"-9895.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_reshape1 -->\r\n",
       "<g id=\"node190\" class=\"node\"><title>ilnet0_reshape1</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2967.21\" cy=\"-9993\" rx=\"56.1991\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2967.21\" y=\"-9989.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_reshape1</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_reshape1&#45;&gt;P -->\r\n",
       "<g id=\"edge226\" class=\"edge\"><title>ilnet0_reshape1&#45;&gt;P</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2967.21,-9953.74C2967.21,-9945.2 2967.21,-9936.3 2967.21,-9928.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2967.21,-9963.9 2962.71,-9953.9 2967.21,-9958.9 2967.21,-9953.9 2967.21,-9953.9 2967.21,-9953.9 2967.21,-9958.9 2971.71,-9953.9 2967.21,-9963.9 2967.21,-9963.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_concat0 -->\r\n",
       "<g id=\"node191\" class=\"node\"><title>ilnet0_concat0</title>\r\n",
       "<ellipse fill=\"#fdb462\" stroke=\"black\" cx=\"2837.21\" cy=\"-10087\" rx=\"53.2527\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10083.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_concat0</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_concat0&#45;&gt;ilnet0_reshape2 -->\r\n",
       "<g id=\"edge227\" class=\"edge\"><title>ilnet0_concat0&#45;&gt;ilnet0_reshape2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2790.81,-10061.6C2762.66,-10046.8 2727.16,-10028.1 2700.6,-10014.2\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2799.67,-10066.3 2788.72,-10065.6 2795.24,-10063.9 2790.82,-10061.6 2790.82,-10061.6 2790.82,-10061.6 2795.24,-10063.9 2792.91,-10057.6 2799.67,-10066.3 2799.67,-10066.3\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_concat0&#45;&gt;ilnet0_reshape0 -->\r\n",
       "<g id=\"edge228\" class=\"edge\"><title>ilnet0_concat0&#45;&gt;ilnet0_reshape0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2837.21,-10047.7C2837.21,-10039.2 2837.21,-10030.3 2837.21,-10022.2\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2837.21,-10057.9 2832.71,-10047.9 2837.21,-10052.9 2837.21,-10047.9 2837.21,-10047.9 2837.21,-10047.9 2837.21,-10052.9 2841.71,-10047.9 2837.21,-10057.9 2837.21,-10057.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_concat0&#45;&gt;ilnet0_reshape1 -->\r\n",
       "<g id=\"edge229\" class=\"edge\"><title>ilnet0_concat0&#45;&gt;ilnet0_reshape1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2877.26,-10057.7C2895.74,-10044.6 2917.4,-10029.2 2934.83,-10016.9\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2869.01,-10063.5 2874.58,-10054 2873.09,-10060.6 2877.17,-10057.7 2877.17,-10057.7 2877.17,-10057.7 2873.09,-10060.6 2879.77,-10061.4 2869.01,-10063.5 2869.01,-10063.5\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_dense0_fwd -->\r\n",
       "<g id=\"node192\" class=\"node\"><title>ilnet0_hybridsequential0_dense0_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"2837.21\" cy=\"-10181\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10184.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10169.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1024</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_dense0_fwd&#45;&gt;ilnet0_concat0 -->\r\n",
       "<g id=\"edge230\" class=\"edge\"><title>ilnet0_hybridsequential0_dense0_fwd&#45;&gt;ilnet0_concat0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2837.21,-10141.7C2837.21,-10133.2 2837.21,-10124.3 2837.21,-10116.2\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2837.21,-10151.9 2832.71,-10141.9 2837.21,-10146.9 2837.21,-10141.9 2837.21,-10141.9 2837.21,-10141.9 2837.21,-10146.9 2841.71,-10141.9 2837.21,-10151.9 2837.21,-10151.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_relu0_fwd -->\r\n",
       "<g id=\"node193\" class=\"node\"><title>ilnet0_hybridsequential0_relu0_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"2837.21\" cy=\"-10275\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10278.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10263.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_relu0_fwd&#45;&gt;ilnet0_hybridsequential0_dense0_fwd -->\r\n",
       "<g id=\"edge231\" class=\"edge\"><title>ilnet0_hybridsequential0_relu0_fwd&#45;&gt;ilnet0_hybridsequential0_dense0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2837.21,-10235.7C2837.21,-10227.2 2837.21,-10218.3 2837.21,-10210.2\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2837.21,-10245.9 2832.71,-10235.9 2837.21,-10240.9 2837.21,-10235.9 2837.21,-10235.9 2837.21,-10235.9 2837.21,-10240.9 2841.71,-10235.9 2837.21,-10245.9 2837.21,-10245.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_dropout0_fwd -->\r\n",
       "<g id=\"node194\" class=\"node\"><title>ilnet0_hybridsequential0_dropout0_fwd</title>\r\n",
       "<ellipse fill=\"#fccde5\" stroke=\"black\" cx=\"2837.21\" cy=\"-10369\" rx=\"130.345\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10365.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ilnet0_hybridsequential0_dropout0_fwd</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_dropout0_fwd&#45;&gt;ilnet0_hybridsequential0_relu0_fwd -->\r\n",
       "<g id=\"edge232\" class=\"edge\"><title>ilnet0_hybridsequential0_dropout0_fwd&#45;&gt;ilnet0_hybridsequential0_relu0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2837.21,-10329.7C2837.21,-10321.2 2837.21,-10312.3 2837.21,-10304.2\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2837.21,-10339.9 2832.71,-10329.9 2837.21,-10334.9 2837.21,-10329.9 2837.21,-10329.9 2837.21,-10329.9 2837.21,-10334.9 2841.71,-10329.9 2837.21,-10339.9 2837.21,-10339.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_dense1_fwd -->\r\n",
       "<g id=\"node195\" class=\"node\"><title>ilnet0_hybridsequential0_dense1_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"2837.21\" cy=\"-10463\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10466.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10451.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">512</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_dense1_fwd&#45;&gt;ilnet0_hybridsequential0_dropout0_fwd -->\r\n",
       "<g id=\"edge233\" class=\"edge\"><title>ilnet0_hybridsequential0_dense1_fwd&#45;&gt;ilnet0_hybridsequential0_dropout0_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2837.21,-10423.7C2837.21,-10415.2 2837.21,-10406.3 2837.21,-10398.2\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2837.21,-10433.9 2832.71,-10423.9 2837.21,-10428.9 2837.21,-10423.9 2837.21,-10423.9 2837.21,-10423.9 2837.21,-10428.9 2841.71,-10423.9 2837.21,-10433.9 2837.21,-10433.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_relu1_fwd -->\r\n",
       "<g id=\"node196\" class=\"node\"><title>ilnet0_hybridsequential0_relu1_fwd</title>\r\n",
       "<ellipse fill=\"#ffffb3\" stroke=\"black\" cx=\"2837.21\" cy=\"-10557\" rx=\"48.9511\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10560.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Activation</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10545.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">relu</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_relu1_fwd&#45;&gt;ilnet0_hybridsequential0_dense1_fwd -->\r\n",
       "<g id=\"edge234\" class=\"edge\"><title>ilnet0_hybridsequential0_relu1_fwd&#45;&gt;ilnet0_hybridsequential0_dense1_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2837.21,-10517.7C2837.21,-10509.2 2837.21,-10500.3 2837.21,-10492.2\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2837.21,-10527.9 2832.71,-10517.9 2837.21,-10522.9 2837.21,-10517.9 2837.21,-10517.9 2837.21,-10517.9 2837.21,-10522.9 2841.71,-10517.9 2837.21,-10527.9 2837.21,-10527.9\"/>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_dense2_fwd -->\r\n",
       "<g id=\"node197\" class=\"node\"><title>ilnet0_hybridsequential0_dense2_fwd</title>\r\n",
       "<ellipse fill=\"#fb8072\" stroke=\"black\" cx=\"2837.21\" cy=\"-10651\" rx=\"69.4846\" ry=\"29\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10654.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">FullyConnected</text>\r\n",
       "<text text-anchor=\"middle\" x=\"2837.21\" y=\"-10639.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- ilnet0_hybridsequential0_dense2_fwd&#45;&gt;ilnet0_hybridsequential0_relu1_fwd -->\r\n",
       "<g id=\"edge235\" class=\"edge\"><title>ilnet0_hybridsequential0_dense2_fwd&#45;&gt;ilnet0_hybridsequential0_relu1_fwd</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2837.21,-10611.7C2837.21,-10603.2 2837.21,-10594.3 2837.21,-10586.2\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2837.21,-10621.9 2832.71,-10611.9 2837.21,-10616.9 2837.21,-10611.9 2837.21,-10611.9 2837.21,-10611.9 2837.21,-10616.9 2841.71,-10611.9 2837.21,-10621.9 2837.21,-10621.9\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x192b5d960c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.viz.plot_network(net(mx.sym.var('IL_smiles'),mx.sym.var('IL_valid_length'),mx.sym.var('T'),mx.sym.var('P'))[0],\n",
    "                    node_attrs={\n",
    "                        \"shape\": \"oval\",\n",
    "                        \"fixedsize\": \"false\"\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:57.477604Z",
     "start_time": "2021-05-08T08:17:57.447605Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def get_r2(label, pred, multioutput='uniform_average'):\n",
    "    label = label.asnumpy()\n",
    "    pred = pred.asnumpy()\n",
    "    r2 = metrics.r2_score(label,pred,multioutput=multioutput)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:57.493604Z",
     "start_time": "2021-05-08T08:17:57.478605Z"
    }
   },
   "outputs": [],
   "source": [
    "home_dir = 'C:\\\\Users\\\\QI_LAB\\\\Desktop\\\\IL-PROPERTY-PREDICT-PUBCHEM\\\\density'\n",
    "save_dir = os.path.join(home_dir,'textcnn')\n",
    "\n",
    "def train(net, train_data, batch_size, learning_rate, context, epochs,log_interval=10, dev_data=None, fold=None ):\n",
    "    start_pipeline_time = time.time()\n",
    "    #net.cation_textcnn.initialize(mx.init.Xavier(), ctx=context, force_reinit=True)\n",
    "    #net.anion_textcnn.initialize(mx.init.Xavier(), ctx=context, force_reinit=True)\n",
    "    net.IL_textcnn.initialize(mx.init.Xavier(), ctx=context, force_reinit=True)\n",
    "    #net.IL_dropout.initialize(mx.init.Xavier(), ctx=context, force_reinit=True)\n",
    "    #net.mlp.initialize(mx.init.Xavier(), ctx=context, force_reinit=True)\n",
    "    net.output.initialize(mx.init.Xavier(), ctx=context, force_reinit=True)\n",
    "    num_epoch_lr = 10\n",
    "    factor = 0.5\n",
    "    schedule = mx.lr_scheduler.FactorScheduler(base_lr = learning_rate, step=len(train_data)* num_epoch_lr,factor=factor)\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'adam', {'lr_scheduler': schedule})\n",
    "    #trainer = gluon.Trainer(net.collect_params(), 'adam',{'learning_rate': learning_rate})\n",
    "    loss = gluon.loss.L2Loss()\n",
    "    # Training/Testing.\n",
    "    best_epoch_L = 10000\n",
    "    for epoch in range(epochs):\n",
    "        # Epoch training stats.\n",
    "        start_epoch_time = time.time()\n",
    "        epoch_L = 0.0\n",
    "        epoch_r2 = 0.0\n",
    "        epoch_sent_num = 0\n",
    "        r2_num = 0\n",
    "        epoch_wc = 0\n",
    "        # Log interval training stats.\n",
    "        start_log_interval_time = time.time()\n",
    "        log_interval_wc = 0\n",
    "        log_interval_sent_num = 0\n",
    "        log_interval_L = 0.0\n",
    "        for i, ((IL_data, IL_length), T,P,label) in enumerate(train_data):\n",
    "            #cation_data = cation_data.as_in_context(context)\n",
    "            #cation_length = cation_length.as_in_context(context).astype(np.float32)\n",
    "            #anion_data = anion_data.as_in_context(context)\n",
    "            #anion_length = anion_length.as_in_context(context).astype(np.float32)\n",
    "            IL_data = IL_data.as_in_context(context)\n",
    "            IL_length = IL_length.as_in_context(context).astype(np.float32)\n",
    "            T = T.as_in_context(context)\n",
    "            P = P.as_in_context(context)\n",
    "            label = label.as_in_context(context)\n",
    "            wc = max_len\n",
    "            log_interval_wc += wc\n",
    "            epoch_wc += wc\n",
    "            log_interval_sent_num += label.shape[0]\n",
    "            epoch_sent_num += label.shape[0]\n",
    "            with autograd.record():\n",
    "                output = net(IL_data, IL_length,T,P)\n",
    "                L = loss(output, label).sum()\n",
    "                r2 = get_r2(output,label)\n",
    "            L.backward()\n",
    "            # Update parameter.\n",
    "            trainer.step(batch_size)\n",
    "            log_interval_L += L.asscalar()\n",
    "            epoch_L += L.asscalar()\n",
    "            epoch_r2+=r2\n",
    "            r2_num+=1\n",
    "            if (i + 1) % log_interval == 0:\n",
    "                print('[Epoch %d Batch %d/%d] avg loss %g, throughput %gK wps' % (\n",
    "                    epoch, i + 1, len(train_data),\n",
    "                    log_interval_L / log_interval_sent_num,\n",
    "                    log_interval_wc / 1000 / (time.time() - start_log_interval_time)))\n",
    "                # Clear log interval training stats.\n",
    "                start_log_interval_time = time.time()\n",
    "                log_interval_wc = 0\n",
    "                log_interval_sent_num = 0\n",
    "                log_interval_L = 0\n",
    "        end_epoch_time = time.time()\n",
    "        \n",
    "        if  (epoch_L/ epoch_sent_num) < best_epoch_L:\n",
    "            best_epoch_L = epoch_L\n",
    "            save_path = os.path.join(save_dir, 'density_best.params')\n",
    "            net.save_parameters(save_path)\n",
    "         \n",
    "        \n",
    "        print('[Epoch %d] train avg loss %g, train avg r2 %g,'\n",
    "              'throughput %gK wps' % (\n",
    "                  epoch, epoch_L / epoch_sent_num, epoch_r2 / r2_num,\n",
    "                  epoch_wc / 1000 / (end_epoch_time - start_epoch_time)))\n",
    "        print('learning rate:',trainer.learning_rate)\n",
    "        '''\n",
    "        if epoch + 1 >= (epochs * 2) // 3:\n",
    "            new_lr = trainer.learning_rate * lr_update_factor\n",
    "            trainer.set_learning_rate(new_lr)\n",
    "        '''\n",
    "    print('Total time cost %.2fs'%(time.time()-start_pipeline_time))\n",
    "    return epoch_L / epoch_sent_num, epoch_r2 / r2_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:17:57.524604Z",
     "start_time": "2021-05-08T08:17:57.494604Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloader(train_dataset):\n",
    "\n",
    "    # Pad data, stack label and lengths\n",
    "    batchify_fn = nlp.data.batchify.Tuple(\n",
    "        nlp.data.batchify.Pad(axis=0, pad_val=0, ret_length=True),\n",
    "        nlp.data.batchify.Stack(dtype='float32'),nlp.data.batchify.Stack(dtype='float32'),nlp.data.batchify.Stack(dtype='float32'))\n",
    "\n",
    "    \n",
    "    # Construct a DataLoader object for both the training and test data\n",
    "    train_dataloader = gluon.data.DataLoader(dataset=train_dataset,\n",
    "                                             batchify_fn=batchify_fn,batch_size = train_batch_size)\n",
    "\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:18:44.553964Z",
     "start_time": "2021-05-08T08:17:57.525605Z"
    }
   },
   "outputs": [],
   "source": [
    "density_database = pd.read_excel('density_P.xlsx',sheet_name='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:18:54.581177Z",
     "start_time": "2021-05-08T08:18:44.554964Z"
    }
   },
   "outputs": [],
   "source": [
    "train_IL_smiles = density_database['IL SMILES'].map(canonical_smile).map(no_split).map(preprocess)\n",
    "train_T =density_database['normalized_T']\n",
    "train_P = density_database['normalized_P']\n",
    "train_lngamma = density_database['ρ / kg/m3']\n",
    "train_dataset = gluon.data.SimpleDataset(gluon.data.ArrayDataset(train_IL_smiles,train_T,train_P,train_lngamma))\n",
    "train_dataloader = get_dataloader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T08:52:29.337397Z",
     "start_time": "2021-05-08T08:18:54.582167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 10/244] avg loss 638257, throughput 0.0102184K wps\n",
      "[Epoch 0 Batch 20/244] avg loss 50728.3, throughput 0.0198441K wps\n",
      "[Epoch 0 Batch 30/244] avg loss 15263, throughput 0.0403185K wps\n",
      "[Epoch 0 Batch 40/244] avg loss 8304.63, throughput 0.128238K wps\n",
      "[Epoch 0 Batch 50/244] avg loss 6411.53, throughput 0.138985K wps\n",
      "[Epoch 0 Batch 60/244] avg loss 19966.6, throughput 0.0123562K wps\n",
      "[Epoch 0 Batch 70/244] avg loss 24472.6, throughput 0.0183493K wps\n",
      "[Epoch 0 Batch 80/244] avg loss 10771.8, throughput 0.0582954K wps\n",
      "[Epoch 0 Batch 90/244] avg loss 14458.4, throughput 0.0173379K wps\n",
      "[Epoch 0 Batch 100/244] avg loss 22359.6, throughput 0.323311K wps\n",
      "[Epoch 0 Batch 110/244] avg loss 13891.9, throughput 0.0472768K wps\n",
      "[Epoch 0 Batch 120/244] avg loss 33820.1, throughput 0.0577701K wps\n",
      "[Epoch 0 Batch 130/244] avg loss 15060.5, throughput 0.0478675K wps\n",
      "[Epoch 0 Batch 140/244] avg loss 7141.02, throughput 0.0559315K wps\n",
      "[Epoch 0 Batch 150/244] avg loss 12796.7, throughput 0.0279728K wps\n",
      "[Epoch 0 Batch 160/244] avg loss 4834.24, throughput 0.0400224K wps\n",
      "[Epoch 0 Batch 170/244] avg loss 6269.46, throughput 0.025939K wps\n",
      "[Epoch 0 Batch 180/244] avg loss 4604.56, throughput 0.0429941K wps\n",
      "[Epoch 0 Batch 190/244] avg loss 5567.95, throughput 0.0514721K wps\n",
      "[Epoch 0 Batch 200/244] avg loss 7501.72, throughput 0.213584K wps\n",
      "[Epoch 0 Batch 210/244] avg loss 9302.85, throughput 2.89855K wps\n",
      "[Epoch 0 Batch 220/244] avg loss 4099.82, throughput 3.08643K wps\n",
      "[Epoch 0 Batch 230/244] avg loss 8321.07, throughput 2.65957K wps\n",
      "[Epoch 0 Batch 240/244] avg loss 3497.93, throughput 2.64549K wps\n",
      "[Epoch 0] train avg loss 38968.7, train avg r2 -1.79649e+07,throughput 0.0373357K wps\n",
      "learning rate: 0.001\n",
      "[Epoch 1 Batch 10/244] avg loss 21522.8, throughput 2.33645K wps\n",
      "[Epoch 1 Batch 20/244] avg loss 19542.5, throughput 2.78552K wps\n",
      "[Epoch 1 Batch 30/244] avg loss 11165.5, throughput 2.90698K wps\n",
      "[Epoch 1 Batch 40/244] avg loss 6303.42, throughput 3.861K wps\n",
      "[Epoch 1 Batch 50/244] avg loss 4569.59, throughput 3.96826K wps\n",
      "[Epoch 1 Batch 60/244] avg loss 5997.64, throughput 2.58398K wps\n",
      "[Epoch 1 Batch 70/244] avg loss 6148.64, throughput 3.2258K wps\n",
      "[Epoch 1 Batch 80/244] avg loss 1965.79, throughput 3.6765K wps\n",
      "[Epoch 1 Batch 90/244] avg loss 4785.73, throughput 2.69541K wps\n",
      "[Epoch 1 Batch 100/244] avg loss 5095.53, throughput 3.64962K wps\n",
      "[Epoch 1 Batch 110/244] avg loss 8197.3, throughput 2.77778K wps\n",
      "[Epoch 1 Batch 120/244] avg loss 15326.5, throughput 3.06749K wps\n",
      "[Epoch 1 Batch 130/244] avg loss 15085.8, throughput 3.26794K wps\n",
      "[Epoch 1 Batch 140/244] avg loss 14359.4, throughput 2.89019K wps\n",
      "[Epoch 1 Batch 150/244] avg loss 6294.73, throughput 2.44499K wps\n",
      "[Epoch 1 Batch 160/244] avg loss 2221.4, throughput 3.43642K wps\n",
      "[Epoch 1 Batch 170/244] avg loss 2685.09, throughput 2.72479K wps\n",
      "[Epoch 1 Batch 180/244] avg loss 4362.51, throughput 2.27791K wps\n",
      "[Epoch 1 Batch 190/244] avg loss 5131.58, throughput 2.43902K wps\n",
      "[Epoch 1 Batch 200/244] avg loss 6287.97, throughput 2.48756K wps\n",
      "[Epoch 1 Batch 210/244] avg loss 6659.54, throughput 2.88183K wps\n",
      "[Epoch 1 Batch 220/244] avg loss 4154.95, throughput 3.11527K wps\n",
      "[Epoch 1 Batch 230/244] avg loss 3863.17, throughput 2.67378K wps\n",
      "[Epoch 1 Batch 240/244] avg loss 2047.7, throughput 2.66668K wps\n",
      "[Epoch 1] train avg loss 7589.29, train avg r2 -10.5748,throughput 2.86958K wps\n",
      "learning rate: 0.001\n",
      "[Epoch 2 Batch 10/244] avg loss 12750.7, throughput 2.38095K wps\n",
      "[Epoch 2 Batch 20/244] avg loss 9460.68, throughput 2.78551K wps\n",
      "[Epoch 2 Batch 30/244] avg loss 4672.64, throughput 2.93256K wps\n",
      "[Epoch 2 Batch 40/244] avg loss 8092.15, throughput 3.84616K wps\n",
      "[Epoch 2 Batch 50/244] avg loss 4421.91, throughput 3.95257K wps\n",
      "[Epoch 2 Batch 60/244] avg loss 6031.21, throughput 2.57732K wps\n",
      "[Epoch 2 Batch 70/244] avg loss 2774.01, throughput 3.23625K wps\n",
      "[Epoch 2 Batch 80/244] avg loss 1040.27, throughput 3.69002K wps\n",
      "[Epoch 2 Batch 90/244] avg loss 1861.98, throughput 2.68817K wps\n",
      "[Epoch 2 Batch 100/244] avg loss 3222.96, throughput 3.663K wps\n",
      "[Epoch 2 Batch 110/244] avg loss 5447.5, throughput 2.76242K wps\n",
      "[Epoch 2 Batch 120/244] avg loss 5739.98, throughput 3.06749K wps\n",
      "[Epoch 2 Batch 130/244] avg loss 3051.98, throughput 3.26796K wps\n",
      "[Epoch 2 Batch 140/244] avg loss 2779.54, throughput 2.89017K wps\n",
      "[Epoch 2 Batch 150/244] avg loss 8139.18, throughput 2.45097K wps\n",
      "[Epoch 2 Batch 160/244] avg loss 2111.43, throughput 3.43641K wps\n",
      "[Epoch 2 Batch 170/244] avg loss 3928.37, throughput 2.80112K wps\n",
      "[Epoch 2 Batch 180/244] avg loss 2308.92, throughput 2.35294K wps\n",
      "[Epoch 2 Batch 190/244] avg loss 1140.73, throughput 2.44498K wps\n",
      "[Epoch 2 Batch 200/244] avg loss 3937.69, throughput 2.48139K wps\n",
      "[Epoch 2 Batch 210/244] avg loss 4005.8, throughput 2.90698K wps\n",
      "[Epoch 2 Batch 220/244] avg loss 4361.91, throughput 3.10557K wps\n",
      "[Epoch 2 Batch 230/244] avg loss 5077.46, throughput 2.66667K wps\n",
      "[Epoch 2 Batch 240/244] avg loss 6221.45, throughput 2.66666K wps\n",
      "[Epoch 2] train avg loss 4730.24, train avg r2 -3.91905,throughput 2.8794K wps\n",
      "learning rate: 0.001\n",
      "[Epoch 3 Batch 10/244] avg loss 12403.2, throughput 2.3753K wps\n",
      "[Epoch 3 Batch 20/244] avg loss 12900.3, throughput 2.77777K wps\n",
      "[Epoch 3 Batch 30/244] avg loss 6243.84, throughput 2.92399K wps\n",
      "[Epoch 3 Batch 40/244] avg loss 8016.86, throughput 3.84614K wps\n",
      "[Epoch 3 Batch 50/244] avg loss 5488, throughput 3.95256K wps\n",
      "[Epoch 3 Batch 60/244] avg loss 9537.27, throughput 2.58398K wps\n",
      "[Epoch 3 Batch 70/244] avg loss 1536.21, throughput 3.23625K wps\n",
      "[Epoch 3 Batch 80/244] avg loss 3345.5, throughput 3.69004K wps\n",
      "[Epoch 3 Batch 90/244] avg loss 3495.83, throughput 2.69542K wps\n",
      "[Epoch 3 Batch 100/244] avg loss 2531.42, throughput 3.64964K wps\n",
      "[Epoch 3 Batch 110/244] avg loss 4057.39, throughput 2.78551K wps\n",
      "[Epoch 3 Batch 120/244] avg loss 9852.63, throughput 3.06748K wps\n",
      "[Epoch 3 Batch 130/244] avg loss 7320.85, throughput 3.27867K wps\n",
      "[Epoch 3 Batch 140/244] avg loss 5786.73, throughput 2.89854K wps\n",
      "[Epoch 3 Batch 150/244] avg loss 8360.63, throughput 2.45098K wps\n",
      "[Epoch 3 Batch 160/244] avg loss 1351.94, throughput 3.43643K wps\n",
      "[Epoch 3 Batch 170/244] avg loss 2621.29, throughput 2.80899K wps\n",
      "[Epoch 3 Batch 180/244] avg loss 2947.11, throughput 2.35294K wps\n",
      "[Epoch 3 Batch 190/244] avg loss 2741.93, throughput 2.44498K wps\n",
      "[Epoch 3 Batch 200/244] avg loss 7036.18, throughput 2.48756K wps\n",
      "[Epoch 3 Batch 210/244] avg loss 8721.82, throughput 2.92397K wps\n",
      "[Epoch 3 Batch 220/244] avg loss 8345.91, throughput 3.13479K wps\n",
      "[Epoch 3 Batch 230/244] avg loss 16452.5, throughput 2.67378K wps\n",
      "[Epoch 3 Batch 240/244] avg loss 11344.5, throughput 2.6738K wps\n",
      "[Epoch 3] train avg loss 6775.65, train avg r2 -5.55816,throughput 2.88382K wps\n",
      "learning rate: 0.001\n",
      "[Epoch 4 Batch 10/244] avg loss 13058.6, throughput 2.38097K wps\n",
      "[Epoch 4 Batch 20/244] avg loss 13443.9, throughput 2.79329K wps\n",
      "[Epoch 4 Batch 30/244] avg loss 11368.9, throughput 2.93256K wps\n",
      "[Epoch 4 Batch 40/244] avg loss 4703.27, throughput 3.86101K wps\n",
      "[Epoch 4 Batch 50/244] avg loss 6584.67, throughput 3.95256K wps\n",
      "[Epoch 4 Batch 60/244] avg loss 12812.9, throughput 2.57731K wps\n",
      "[Epoch 4 Batch 70/244] avg loss 2093.36, throughput 3.21543K wps\n",
      "[Epoch 4 Batch 80/244] avg loss 2714.42, throughput 3.67647K wps\n",
      "[Epoch 4 Batch 90/244] avg loss 4735.82, throughput 2.69542K wps\n",
      "[Epoch 4 Batch 100/244] avg loss 2956.51, throughput 3.6496K wps\n",
      "[Epoch 4 Batch 110/244] avg loss 4964.04, throughput 2.78553K wps\n",
      "[Epoch 4 Batch 120/244] avg loss 4950.65, throughput 3.06748K wps\n",
      "[Epoch 4 Batch 130/244] avg loss 8060.71, throughput 3.25732K wps\n",
      "[Epoch 4 Batch 140/244] avg loss 5777.13, throughput 2.89855K wps\n",
      "[Epoch 4 Batch 150/244] avg loss 7805.41, throughput 2.45098K wps\n",
      "[Epoch 4 Batch 160/244] avg loss 3469.92, throughput 3.43643K wps\n",
      "[Epoch 4 Batch 170/244] avg loss 4559.56, throughput 2.809K wps\n",
      "[Epoch 4 Batch 180/244] avg loss 5742.06, throughput 2.35849K wps\n",
      "[Epoch 4 Batch 190/244] avg loss 2846.82, throughput 2.43903K wps\n",
      "[Epoch 4 Batch 200/244] avg loss 6332.76, throughput 2.48138K wps\n",
      "[Epoch 4 Batch 210/244] avg loss 5576.8, throughput 2.91544K wps\n",
      "[Epoch 4 Batch 220/244] avg loss 5461.62, throughput 3.12501K wps\n",
      "[Epoch 4 Batch 230/244] avg loss 2885.27, throughput 2.6738K wps\n",
      "[Epoch 4 Batch 240/244] avg loss 2355.08, throughput 2.65957K wps\n",
      "[Epoch 4] train avg loss 6036.92, train avg r2 -4.70581,throughput 2.88042K wps\n",
      "learning rate: 0.001\n",
      "[Epoch 5 Batch 10/244] avg loss 12355.4, throughput 2.3753K wps\n",
      "[Epoch 5 Batch 20/244] avg loss 13553.6, throughput 2.77778K wps\n",
      "[Epoch 5 Batch 30/244] avg loss 5622.83, throughput 2.92396K wps\n",
      "[Epoch 5 Batch 40/244] avg loss 2695.19, throughput 3.86104K wps\n",
      "[Epoch 5 Batch 50/244] avg loss 2749.48, throughput 3.96826K wps\n",
      "[Epoch 5 Batch 60/244] avg loss 5653.09, throughput 2.57731K wps\n",
      "[Epoch 5 Batch 70/244] avg loss 2591.42, throughput 3.21545K wps\n",
      "[Epoch 5 Batch 80/244] avg loss 2543.06, throughput 3.69004K wps\n",
      "[Epoch 5 Batch 90/244] avg loss 1428.88, throughput 2.68817K wps\n",
      "[Epoch 5 Batch 100/244] avg loss 1234.77, throughput 3.64964K wps\n",
      "[Epoch 5 Batch 110/244] avg loss 3303.38, throughput 2.78551K wps\n",
      "[Epoch 5 Batch 120/244] avg loss 4578.97, throughput 3.0581K wps\n",
      "[Epoch 5 Batch 130/244] avg loss 4120.61, throughput 3.26795K wps\n",
      "[Epoch 5 Batch 140/244] avg loss 2530.61, throughput 2.89855K wps\n",
      "[Epoch 5 Batch 150/244] avg loss 4363, throughput 2.45099K wps\n",
      "[Epoch 5 Batch 160/244] avg loss 1261.1, throughput 3.41298K wps\n",
      "[Epoch 5 Batch 170/244] avg loss 1944.3, throughput 2.80899K wps\n",
      "[Epoch 5 Batch 180/244] avg loss 2237.7, throughput 2.36406K wps\n",
      "[Epoch 5 Batch 190/244] avg loss 3151.61, throughput 2.43903K wps\n",
      "[Epoch 5 Batch 200/244] avg loss 4621.66, throughput 2.49376K wps\n",
      "[Epoch 5 Batch 210/244] avg loss 4344.89, throughput 2.92398K wps\n",
      "[Epoch 5 Batch 220/244] avg loss 3696.22, throughput 3.125K wps\n",
      "[Epoch 5 Batch 230/244] avg loss 1496.23, throughput 2.6738K wps\n",
      "[Epoch 5 Batch 240/244] avg loss 1284.98, throughput 2.67379K wps\n",
      "[Epoch 5] train avg loss 3875.65, train avg r2 -2.41534,throughput 2.88348K wps\n",
      "learning rate: 0.001\n",
      "[Epoch 6 Batch 10/244] avg loss 4433.37, throughput 2.38663K wps\n",
      "[Epoch 6 Batch 20/244] avg loss 4223.25, throughput 2.77778K wps\n",
      "[Epoch 6 Batch 30/244] avg loss 3234, throughput 2.94118K wps\n",
      "[Epoch 6 Batch 40/244] avg loss 2964.23, throughput 3.861K wps\n",
      "[Epoch 6 Batch 50/244] avg loss 1726.81, throughput 3.96828K wps\n",
      "[Epoch 6 Batch 60/244] avg loss 4157, throughput 2.57731K wps\n",
      "[Epoch 6 Batch 70/244] avg loss 4574.78, throughput 3.2258K wps\n",
      "[Epoch 6 Batch 80/244] avg loss 2857.46, throughput 3.66301K wps\n",
      "[Epoch 6 Batch 90/244] avg loss 1211.75, throughput 2.68818K wps\n",
      "[Epoch 6 Batch 100/244] avg loss 963.1, throughput 3.64962K wps\n",
      "[Epoch 6 Batch 110/244] avg loss 2513.26, throughput 2.7933K wps\n",
      "[Epoch 6 Batch 120/244] avg loss 3191.07, throughput 3.06749K wps\n",
      "[Epoch 6 Batch 130/244] avg loss 2966.75, throughput 3.26797K wps\n",
      "[Epoch 6 Batch 140/244] avg loss 3159.26, throughput 2.89017K wps\n",
      "[Epoch 6 Batch 150/244] avg loss 3333.02, throughput 2.43902K wps\n",
      "[Epoch 6 Batch 160/244] avg loss 2436.32, throughput 3.44829K wps\n",
      "[Epoch 6 Batch 170/244] avg loss 1833.9, throughput 2.8169K wps\n",
      "[Epoch 6 Batch 180/244] avg loss 1412.56, throughput 2.35294K wps\n",
      "[Epoch 6 Batch 190/244] avg loss 1865.91, throughput 2.44499K wps\n",
      "[Epoch 6 Batch 200/244] avg loss 2768.89, throughput 2.48756K wps\n",
      "[Epoch 6 Batch 210/244] avg loss 1716.08, throughput 2.91545K wps\n",
      "[Epoch 6 Batch 220/244] avg loss 2207.95, throughput 3.13481K wps\n",
      "[Epoch 6 Batch 230/244] avg loss 1789.8, throughput 2.67379K wps\n",
      "[Epoch 6 Batch 240/244] avg loss 3274.73, throughput 2.67379K wps\n",
      "[Epoch 6] train avg loss 2713.53, train avg r2 -1.34135,throughput 2.88552K wps\n",
      "learning rate: 0.001\n",
      "[Epoch 7 Batch 10/244] avg loss 4995.15, throughput 2.38663K wps\n",
      "[Epoch 7 Batch 20/244] avg loss 2933.65, throughput 2.77777K wps\n",
      "[Epoch 7 Batch 30/244] avg loss 1246.16, throughput 2.93257K wps\n",
      "[Epoch 7 Batch 40/244] avg loss 1568.51, throughput 3.86099K wps\n",
      "[Epoch 7 Batch 50/244] avg loss 2320.2, throughput 3.95257K wps\n",
      "[Epoch 7 Batch 60/244] avg loss 4128.08, throughput 2.57733K wps\n",
      "[Epoch 7 Batch 70/244] avg loss 3909.86, throughput 3.23623K wps\n",
      "[Epoch 7 Batch 80/244] avg loss 3900.06, throughput 3.69003K wps\n",
      "[Epoch 7 Batch 90/244] avg loss 1034.65, throughput 2.69541K wps\n",
      "[Epoch 7 Batch 100/244] avg loss 2266.32, throughput 3.66301K wps\n",
      "[Epoch 7 Batch 110/244] avg loss 3233.83, throughput 2.78553K wps\n",
      "[Epoch 7 Batch 120/244] avg loss 4851.52, throughput 3.05808K wps\n",
      "[Epoch 7 Batch 130/244] avg loss 3671.17, throughput 3.27872K wps\n",
      "[Epoch 7 Batch 140/244] avg loss 2781.82, throughput 2.90697K wps\n",
      "[Epoch 7 Batch 150/244] avg loss 2463.29, throughput 2.44499K wps\n",
      "[Epoch 7 Batch 160/244] avg loss 3991.91, throughput 3.43642K wps\n",
      "[Epoch 7 Batch 170/244] avg loss 5054.34, throughput 2.8169K wps\n",
      "[Epoch 7 Batch 180/244] avg loss 2685.05, throughput 2.36406K wps\n",
      "[Epoch 7 Batch 190/244] avg loss 1793.99, throughput 2.44499K wps\n",
      "[Epoch 7 Batch 200/244] avg loss 5006.2, throughput 2.48139K wps\n",
      "[Epoch 7 Batch 210/244] avg loss 1905.02, throughput 2.90696K wps\n",
      "[Epoch 7 Batch 220/244] avg loss 2403.79, throughput 3.1348K wps\n",
      "[Epoch 7 Batch 230/244] avg loss 8388.31, throughput 2.67378K wps\n",
      "[Epoch 7 Batch 240/244] avg loss 8236.68, throughput 2.68098K wps\n",
      "[Epoch 7] train avg loss 3527.99, train avg r2 -2.12106,throughput 2.88689K wps\n",
      "learning rate: 0.001\n",
      "[Epoch 8 Batch 10/244] avg loss 8034.28, throughput 2.38663K wps\n",
      "[Epoch 8 Batch 20/244] avg loss 2962.19, throughput 2.79331K wps\n",
      "[Epoch 8 Batch 30/244] avg loss 2587.63, throughput 2.93254K wps\n",
      "[Epoch 8 Batch 40/244] avg loss 2673.73, throughput 3.86102K wps\n",
      "[Epoch 8 Batch 50/244] avg loss 3783.6, throughput 3.98406K wps\n",
      "[Epoch 8 Batch 60/244] avg loss 7939.15, throughput 2.58398K wps\n",
      "[Epoch 8 Batch 70/244] avg loss 6017.71, throughput 3.24675K wps\n",
      "[Epoch 8 Batch 80/244] avg loss 4881.09, throughput 3.69004K wps\n",
      "[Epoch 8 Batch 90/244] avg loss 1274.75, throughput 2.69542K wps\n",
      "[Epoch 8 Batch 100/244] avg loss 2115.01, throughput 3.64964K wps\n",
      "[Epoch 8 Batch 110/244] avg loss 3203.75, throughput 2.78551K wps\n",
      "[Epoch 8 Batch 120/244] avg loss 5808.85, throughput 3.06747K wps\n",
      "[Epoch 8 Batch 130/244] avg loss 4484.49, throughput 3.27871K wps\n",
      "[Epoch 8 Batch 140/244] avg loss 3150.87, throughput 2.89017K wps\n",
      "[Epoch 8 Batch 150/244] avg loss 3464.26, throughput 2.45699K wps\n",
      "[Epoch 8 Batch 160/244] avg loss 3433.38, throughput 3.44826K wps\n",
      "[Epoch 8 Batch 170/244] avg loss 2077.4, throughput 2.74725K wps\n",
      "[Epoch 8 Batch 180/244] avg loss 1745.38, throughput 2.331K wps\n",
      "[Epoch 8 Batch 190/244] avg loss 1406.16, throughput 2.44499K wps\n",
      "[Epoch 8 Batch 200/244] avg loss 3387.06, throughput 2.48139K wps\n",
      "[Epoch 8 Batch 210/244] avg loss 1293.92, throughput 2.90697K wps\n",
      "[Epoch 8 Batch 220/244] avg loss 2201.74, throughput 3.1348K wps\n",
      "[Epoch 8 Batch 230/244] avg loss 3243.12, throughput 2.66667K wps\n",
      "[Epoch 8 Batch 240/244] avg loss 4880.57, throughput 2.67378K wps\n",
      "[Epoch 8] train avg loss 3572.57, train avg r2 -2.07505,throughput 2.8828K wps\n",
      "learning rate: 0.001\n",
      "[Epoch 9 Batch 10/244] avg loss 5984, throughput 2.38095K wps\n",
      "[Epoch 9 Batch 20/244] avg loss 4365.49, throughput 2.78551K wps\n",
      "[Epoch 9 Batch 30/244] avg loss 1551.84, throughput 2.92397K wps\n",
      "[Epoch 9 Batch 40/244] avg loss 2250.91, throughput 3.86102K wps\n",
      "[Epoch 9 Batch 50/244] avg loss 3200.56, throughput 3.96825K wps\n",
      "[Epoch 9 Batch 60/244] avg loss 6069.89, throughput 2.57732K wps\n",
      "[Epoch 9 Batch 70/244] avg loss 6160.18, throughput 3.22581K wps\n",
      "[Epoch 9 Batch 80/244] avg loss 3518.3, throughput 3.7037K wps\n",
      "[Epoch 9 Batch 90/244] avg loss 2035.01, throughput 2.70269K wps\n",
      "[Epoch 9 Batch 100/244] avg loss 1620.41, throughput 3.66302K wps\n",
      "[Epoch 9 Batch 110/244] avg loss 7300.08, throughput 2.79329K wps\n",
      "[Epoch 9 Batch 120/244] avg loss 6420.11, throughput 3.0581K wps\n",
      "[Epoch 9 Batch 130/244] avg loss 3190.59, throughput 3.2787K wps\n",
      "[Epoch 9 Batch 140/244] avg loss 2219.34, throughput 2.89854K wps\n",
      "[Epoch 9 Batch 150/244] avg loss 3980.05, throughput 2.45097K wps\n",
      "[Epoch 9 Batch 160/244] avg loss 2448.09, throughput 3.43643K wps\n",
      "[Epoch 9 Batch 170/244] avg loss 1468.66, throughput 2.809K wps\n",
      "[Epoch 9 Batch 180/244] avg loss 1152.53, throughput 2.35849K wps\n",
      "[Epoch 9 Batch 190/244] avg loss 1155.1, throughput 2.45098K wps\n",
      "[Epoch 9 Batch 200/244] avg loss 2875.78, throughput 2.49377K wps\n",
      "[Epoch 9 Batch 210/244] avg loss 1115.65, throughput 2.92398K wps\n",
      "[Epoch 9 Batch 220/244] avg loss 697.179, throughput 3.1348K wps\n",
      "[Epoch 9 Batch 230/244] avg loss 4173.36, throughput 2.68097K wps\n",
      "[Epoch 9 Batch 240/244] avg loss 7112.18, throughput 2.66666K wps\n",
      "[Epoch 9] train avg loss 3440.81, train avg r2 -1.93687,throughput 2.88723K wps\n",
      "learning rate: 0.001\n",
      "[Epoch 10 Batch 10/244] avg loss 14684.5, throughput 2.38664K wps\n",
      "[Epoch 10 Batch 20/244] avg loss 4717.1, throughput 2.79329K wps\n",
      "[Epoch 10 Batch 30/244] avg loss 4079.03, throughput 2.94116K wps\n",
      "[Epoch 10 Batch 40/244] avg loss 1620.94, throughput 3.86099K wps\n",
      "[Epoch 10 Batch 50/244] avg loss 1384.36, throughput 3.98408K wps\n",
      "[Epoch 10 Batch 60/244] avg loss 2646.21, throughput 2.58399K wps\n",
      "[Epoch 10 Batch 70/244] avg loss 2236.56, throughput 3.23621K wps\n",
      "[Epoch 10 Batch 80/244] avg loss 893.731, throughput 3.67649K wps\n",
      "[Epoch 10 Batch 90/244] avg loss 806.788, throughput 2.70269K wps\n",
      "[Epoch 10 Batch 100/244] avg loss 912.487, throughput 3.66302K wps\n",
      "[Epoch 10 Batch 110/244] avg loss 1498.66, throughput 2.79328K wps\n",
      "[Epoch 10 Batch 120/244] avg loss 929.805, throughput 3.0675K wps\n",
      "[Epoch 10 Batch 130/244] avg loss 4512.26, throughput 3.28947K wps\n",
      "[Epoch 10 Batch 140/244] avg loss 7103.77, throughput 2.89016K wps\n",
      "[Epoch 10 Batch 150/244] avg loss 3823.38, throughput 2.45701K wps\n",
      "[Epoch 10 Batch 160/244] avg loss 993.815, throughput 3.43642K wps\n",
      "[Epoch 10 Batch 170/244] avg loss 2818.76, throughput 2.80899K wps\n",
      "[Epoch 10 Batch 180/244] avg loss 1741.93, throughput 2.35294K wps\n",
      "[Epoch 10 Batch 190/244] avg loss 1237, throughput 2.44499K wps\n",
      "[Epoch 10 Batch 200/244] avg loss 4984.01, throughput 2.48139K wps\n",
      "[Epoch 10 Batch 210/244] avg loss 2610.56, throughput 2.90698K wps\n",
      "[Epoch 10 Batch 220/244] avg loss 1172.05, throughput 3.13481K wps\n",
      "[Epoch 10 Batch 230/244] avg loss 2247.69, throughput 2.66666K wps\n",
      "[Epoch 10 Batch 240/244] avg loss 1835.75, throughput 2.65957K wps\n",
      "[Epoch 10] train avg loss 2983.67, train avg r2 -0.84597,throughput 2.88757K wps\n",
      "learning rate: 0.0005\n",
      "[Epoch 11 Batch 10/244] avg loss 3502.17, throughput 2.38663K wps\n",
      "[Epoch 11 Batch 20/244] avg loss 2014.8, throughput 2.78552K wps\n",
      "[Epoch 11 Batch 30/244] avg loss 1276.78, throughput 2.93256K wps\n",
      "[Epoch 11 Batch 40/244] avg loss 1831.8, throughput 3.861K wps\n",
      "[Epoch 11 Batch 50/244] avg loss 671.189, throughput 3.96827K wps\n",
      "[Epoch 11 Batch 60/244] avg loss 1694.69, throughput 2.57732K wps\n",
      "[Epoch 11 Batch 70/244] avg loss 1495.93, throughput 3.2258K wps\n",
      "[Epoch 11 Batch 80/244] avg loss 1310.71, throughput 3.69004K wps\n",
      "[Epoch 11 Batch 90/244] avg loss 538.522, throughput 2.69542K wps\n",
      "[Epoch 11 Batch 100/244] avg loss 465.886, throughput 3.67644K wps\n",
      "[Epoch 11 Batch 110/244] avg loss 1417.29, throughput 2.80113K wps\n",
      "[Epoch 11 Batch 120/244] avg loss 949.679, throughput 3.07692K wps\n",
      "[Epoch 11 Batch 130/244] avg loss 3471.66, throughput 3.27868K wps\n",
      "[Epoch 11 Batch 140/244] avg loss 2719.68, throughput 2.89855K wps\n",
      "[Epoch 11 Batch 150/244] avg loss 2229.42, throughput 2.45098K wps\n",
      "[Epoch 11 Batch 160/244] avg loss 1429.24, throughput 3.43644K wps\n",
      "[Epoch 11 Batch 170/244] avg loss 2191.22, throughput 2.8169K wps\n",
      "[Epoch 11 Batch 180/244] avg loss 1148.59, throughput 2.35849K wps\n",
      "[Epoch 11 Batch 190/244] avg loss 445.155, throughput 2.43903K wps\n",
      "[Epoch 11 Batch 200/244] avg loss 2336.25, throughput 2.49376K wps\n",
      "[Epoch 11 Batch 210/244] avg loss 1579.74, throughput 2.91544K wps\n",
      "[Epoch 11 Batch 220/244] avg loss 1247.35, throughput 3.14465K wps\n",
      "[Epoch 11 Batch 230/244] avg loss 2234.01, throughput 2.68096K wps\n",
      "[Epoch 11 Batch 240/244] avg loss 3340.07, throughput 2.6738K wps\n",
      "[Epoch 11] train avg loss 1735.03, train avg r2 -0.257505,throughput 2.8886K wps\n",
      "learning rate: 0.0005\n",
      "[Epoch 12 Batch 10/244] avg loss 2606.32, throughput 2.38096K wps\n",
      "[Epoch 12 Batch 20/244] avg loss 1371.67, throughput 2.79329K wps\n",
      "[Epoch 12 Batch 30/244] avg loss 1252.77, throughput 2.94117K wps\n",
      "[Epoch 12 Batch 40/244] avg loss 1340.78, throughput 3.861K wps\n",
      "[Epoch 12 Batch 50/244] avg loss 1197.1, throughput 3.96826K wps\n",
      "[Epoch 12 Batch 60/244] avg loss 1805.01, throughput 2.58398K wps\n",
      "[Epoch 12 Batch 70/244] avg loss 708.225, throughput 3.22581K wps\n",
      "[Epoch 12 Batch 80/244] avg loss 460.571, throughput 3.67649K wps\n",
      "[Epoch 12 Batch 90/244] avg loss 1087.75, throughput 2.68817K wps\n",
      "[Epoch 12 Batch 100/244] avg loss 977.852, throughput 3.62318K wps\n",
      "[Epoch 12 Batch 110/244] avg loss 1263.21, throughput 2.78551K wps\n",
      "[Epoch 12 Batch 120/244] avg loss 538.057, throughput 3.06748K wps\n",
      "[Epoch 12 Batch 130/244] avg loss 1003.93, throughput 3.28948K wps\n",
      "[Epoch 12 Batch 140/244] avg loss 1149.01, throughput 2.89017K wps\n",
      "[Epoch 12 Batch 150/244] avg loss 1636.3, throughput 2.45098K wps\n",
      "[Epoch 12 Batch 160/244] avg loss 1730.83, throughput 3.43642K wps\n",
      "[Epoch 12 Batch 170/244] avg loss 3194.52, throughput 2.80899K wps\n",
      "[Epoch 12 Batch 180/244] avg loss 2294.7, throughput 2.35295K wps\n",
      "[Epoch 12 Batch 190/244] avg loss 730.437, throughput 2.45098K wps\n",
      "[Epoch 12 Batch 200/244] avg loss 2755.04, throughput 2.49376K wps\n",
      "[Epoch 12 Batch 210/244] avg loss 1912.59, throughput 2.90698K wps\n",
      "[Epoch 12 Batch 220/244] avg loss 2222.7, throughput 3.1348K wps\n",
      "[Epoch 12 Batch 230/244] avg loss 3808.01, throughput 2.67379K wps\n",
      "[Epoch 12 Batch 240/244] avg loss 4534.17, throughput 2.6738K wps\n",
      "[Epoch 12] train avg loss 1736.52, train avg r2 -0.0904642,throughput 2.88587K wps\n",
      "learning rate: 0.0005\n",
      "[Epoch 13 Batch 10/244] avg loss 2509.81, throughput 2.38095K wps\n",
      "[Epoch 13 Batch 20/244] avg loss 2040.01, throughput 2.78552K wps\n",
      "[Epoch 13 Batch 30/244] avg loss 3041.58, throughput 2.92397K wps\n",
      "[Epoch 13 Batch 40/244] avg loss 2407.36, throughput 3.86101K wps\n",
      "[Epoch 13 Batch 50/244] avg loss 2117.1, throughput 3.95258K wps\n",
      "[Epoch 13 Batch 60/244] avg loss 2268.81, throughput 2.57732K wps\n",
      "[Epoch 13 Batch 70/244] avg loss 1030.52, throughput 3.22581K wps\n",
      "[Epoch 13 Batch 80/244] avg loss 595.912, throughput 3.69003K wps\n",
      "[Epoch 13 Batch 90/244] avg loss 1690.56, throughput 2.69541K wps\n",
      "[Epoch 13 Batch 100/244] avg loss 967.265, throughput 3.66299K wps\n",
      "[Epoch 13 Batch 110/244] avg loss 1227.83, throughput 2.7933K wps\n",
      "[Epoch 13 Batch 120/244] avg loss 562.808, throughput 3.06749K wps\n",
      "[Epoch 13 Batch 130/244] avg loss 690.644, throughput 3.26797K wps\n",
      "[Epoch 13 Batch 140/244] avg loss 1586.26, throughput 2.90697K wps\n",
      "[Epoch 13 Batch 150/244] avg loss 1757.62, throughput 2.45097K wps\n",
      "[Epoch 13 Batch 160/244] avg loss 1639.02, throughput 3.44825K wps\n",
      "[Epoch 13 Batch 170/244] avg loss 4341.26, throughput 2.80112K wps\n",
      "[Epoch 13 Batch 180/244] avg loss 2555.75, throughput 2.36406K wps\n",
      "[Epoch 13 Batch 190/244] avg loss 1722.31, throughput 2.44499K wps\n",
      "[Epoch 13 Batch 200/244] avg loss 3230.71, throughput 2.4814K wps\n",
      "[Epoch 13 Batch 210/244] avg loss 2258.77, throughput 2.92397K wps\n",
      "[Epoch 13 Batch 220/244] avg loss 3761.73, throughput 3.12501K wps\n",
      "[Epoch 13 Batch 230/244] avg loss 4616.32, throughput 2.67379K wps\n",
      "[Epoch 13 Batch 240/244] avg loss 5040.46, throughput 2.67379K wps\n",
      "[Epoch 13] train avg loss 2226.83, train avg r2 -0.767406,throughput 2.88655K wps\n",
      "learning rate: 0.0005\n",
      "[Epoch 14 Batch 10/244] avg loss 2744.66, throughput 2.38096K wps\n",
      "[Epoch 14 Batch 20/244] avg loss 1917, throughput 2.78551K wps\n",
      "[Epoch 14 Batch 30/244] avg loss 2458.52, throughput 2.94116K wps\n",
      "[Epoch 14 Batch 40/244] avg loss 2863.45, throughput 3.83144K wps\n",
      "[Epoch 14 Batch 50/244] avg loss 2055.74, throughput 3.95258K wps\n",
      "[Epoch 14 Batch 60/244] avg loss 2337.38, throughput 2.58397K wps\n",
      "[Epoch 14 Batch 70/244] avg loss 881.447, throughput 3.23623K wps\n",
      "[Epoch 14 Batch 80/244] avg loss 717.396, throughput 3.69003K wps\n",
      "[Epoch 14 Batch 90/244] avg loss 1508.24, throughput 2.68817K wps\n",
      "[Epoch 14 Batch 100/244] avg loss 959.063, throughput 3.64965K wps\n",
      "[Epoch 14 Batch 110/244] avg loss 1181.51, throughput 2.78551K wps\n",
      "[Epoch 14 Batch 120/244] avg loss 631.393, throughput 3.06749K wps\n",
      "[Epoch 14 Batch 130/244] avg loss 668.27, throughput 3.27868K wps\n",
      "[Epoch 14 Batch 140/244] avg loss 1231.32, throughput 2.90697K wps\n",
      "[Epoch 14 Batch 150/244] avg loss 1522.8, throughput 2.45699K wps\n",
      "[Epoch 14 Batch 160/244] avg loss 1508.15, throughput 3.43643K wps\n",
      "[Epoch 14 Batch 170/244] avg loss 2079.56, throughput 2.80899K wps\n",
      "[Epoch 14 Batch 180/244] avg loss 1939.91, throughput 2.36406K wps\n",
      "[Epoch 14 Batch 190/244] avg loss 1441.44, throughput 2.43903K wps\n",
      "[Epoch 14 Batch 200/244] avg loss 2872.09, throughput 2.48756K wps\n",
      "[Epoch 14 Batch 210/244] avg loss 2069.02, throughput 2.90697K wps\n",
      "[Epoch 14 Batch 220/244] avg loss 3847.55, throughput 3.12501K wps\n",
      "[Epoch 14 Batch 230/244] avg loss 5900.12, throughput 2.66666K wps\n",
      "[Epoch 14 Batch 240/244] avg loss 7840.74, throughput 2.6738K wps\n",
      "[Epoch 14] train avg loss 2216.28, train avg r2 -0.847485,throughput 2.88553K wps\n",
      "learning rate: 0.0005\n",
      "[Epoch 15 Batch 10/244] avg loss 3218.76, throughput 2.38095K wps\n",
      "[Epoch 15 Batch 20/244] avg loss 2112.43, throughput 2.7933K wps\n",
      "[Epoch 15 Batch 30/244] avg loss 1914.78, throughput 2.94118K wps\n",
      "[Epoch 15 Batch 40/244] avg loss 3048.1, throughput 3.861K wps\n",
      "[Epoch 15 Batch 50/244] avg loss 1890.14, throughput 3.96827K wps\n",
      "[Epoch 15 Batch 60/244] avg loss 2041.25, throughput 2.5773K wps\n",
      "[Epoch 15 Batch 70/244] avg loss 894.278, throughput 3.23627K wps\n",
      "[Epoch 15 Batch 80/244] avg loss 699.914, throughput 3.67648K wps\n",
      "[Epoch 15 Batch 90/244] avg loss 1246.79, throughput 2.68817K wps\n",
      "[Epoch 15 Batch 100/244] avg loss 1200.93, throughput 3.64962K wps\n",
      "[Epoch 15 Batch 110/244] avg loss 1224.09, throughput 2.7933K wps\n",
      "[Epoch 15 Batch 120/244] avg loss 429.816, throughput 3.06748K wps\n",
      "[Epoch 15 Batch 130/244] avg loss 605.373, throughput 3.2787K wps\n",
      "[Epoch 15 Batch 140/244] avg loss 1210.46, throughput 2.89854K wps\n",
      "[Epoch 15 Batch 150/244] avg loss 1926.44, throughput 2.45097K wps\n",
      "[Epoch 15 Batch 160/244] avg loss 1307.84, throughput 3.44827K wps\n",
      "[Epoch 15 Batch 170/244] avg loss 1159.23, throughput 2.80113K wps\n",
      "[Epoch 15 Batch 180/244] avg loss 1113.26, throughput 2.35848K wps\n",
      "[Epoch 15 Batch 190/244] avg loss 1192.71, throughput 2.445K wps\n",
      "[Epoch 15 Batch 200/244] avg loss 5685.73, throughput 2.49376K wps\n",
      "[Epoch 15 Batch 210/244] avg loss 3227.12, throughput 2.91544K wps\n",
      "[Epoch 15 Batch 220/244] avg loss 3574.8, throughput 3.1348K wps\n",
      "[Epoch 15 Batch 230/244] avg loss 3770.25, throughput 2.68096K wps\n",
      "[Epoch 15 Batch 240/244] avg loss 4231.93, throughput 2.66667K wps\n",
      "[Epoch 15] train avg loss 2034.04, train avg r2 -0.530533,throughput 2.88757K wps\n",
      "learning rate: 0.0005\n",
      "[Epoch 16 Batch 10/244] avg loss 3024.72, throughput 2.38664K wps\n",
      "[Epoch 16 Batch 20/244] avg loss 1500.42, throughput 2.78551K wps\n",
      "[Epoch 16 Batch 30/244] avg loss 868.558, throughput 2.93255K wps\n",
      "[Epoch 16 Batch 40/244] avg loss 1567.95, throughput 3.86099K wps\n",
      "[Epoch 16 Batch 50/244] avg loss 1018.82, throughput 3.96826K wps\n",
      "[Epoch 16 Batch 60/244] avg loss 2039.81, throughput 2.57069K wps\n",
      "[Epoch 16 Batch 70/244] avg loss 1744.92, throughput 3.23624K wps\n",
      "[Epoch 16 Batch 80/244] avg loss 1281.26, throughput 3.69002K wps\n",
      "[Epoch 16 Batch 90/244] avg loss 510.255, throughput 2.69544K wps\n",
      "[Epoch 16 Batch 100/244] avg loss 599.566, throughput 3.64962K wps\n",
      "[Epoch 16 Batch 110/244] avg loss 1153.73, throughput 2.59067K wps\n",
      "[Epoch 16 Batch 120/244] avg loss 450.122, throughput 3.07692K wps\n",
      "[Epoch 16 Batch 130/244] avg loss 832.879, throughput 3.26797K wps\n",
      "[Epoch 16 Batch 140/244] avg loss 1298.21, throughput 2.90698K wps\n",
      "[Epoch 16 Batch 150/244] avg loss 1724.56, throughput 2.43902K wps\n",
      "[Epoch 16 Batch 160/244] avg loss 770.679, throughput 3.44828K wps\n",
      "[Epoch 16 Batch 170/244] avg loss 819.054, throughput 2.8169K wps\n",
      "[Epoch 16 Batch 180/244] avg loss 1376.31, throughput 2.35848K wps\n",
      "[Epoch 16 Batch 190/244] avg loss 1766.09, throughput 2.45098K wps\n",
      "[Epoch 16 Batch 200/244] avg loss 5585.63, throughput 2.49376K wps\n",
      "[Epoch 16 Batch 210/244] avg loss 4331.66, throughput 2.90697K wps\n",
      "[Epoch 16 Batch 220/244] avg loss 5938.9, throughput 3.13481K wps\n",
      "[Epoch 16 Batch 230/244] avg loss 3617.45, throughput 2.68096K wps\n",
      "[Epoch 16 Batch 240/244] avg loss 3536.38, throughput 2.67379K wps\n",
      "[Epoch 16] train avg loss 1971.77, train avg r2 -0.4047,throughput 2.87838K wps\n",
      "learning rate: 0.0005\n",
      "[Epoch 17 Batch 10/244] avg loss 2464.52, throughput 2.38095K wps\n",
      "[Epoch 17 Batch 20/244] avg loss 1262.46, throughput 2.79329K wps\n",
      "[Epoch 17 Batch 30/244] avg loss 804.994, throughput 2.94118K wps\n",
      "[Epoch 17 Batch 40/244] avg loss 1207.77, throughput 3.86099K wps\n",
      "[Epoch 17 Batch 50/244] avg loss 1131.4, throughput 3.95255K wps\n",
      "[Epoch 17 Batch 60/244] avg loss 1836.93, throughput 2.57733K wps\n",
      "[Epoch 17 Batch 70/244] avg loss 2962.79, throughput 3.22581K wps\n",
      "[Epoch 17 Batch 80/244] avg loss 2544.68, throughput 3.69003K wps\n",
      "[Epoch 17 Batch 90/244] avg loss 513.764, throughput 2.68817K wps\n",
      "[Epoch 17 Batch 100/244] avg loss 437.905, throughput 3.64962K wps\n",
      "[Epoch 17 Batch 110/244] avg loss 1432.11, throughput 2.7933K wps\n",
      "[Epoch 17 Batch 120/244] avg loss 561.242, throughput 3.04876K wps\n",
      "[Epoch 17 Batch 130/244] avg loss 977.436, throughput 3.2787K wps\n",
      "[Epoch 17 Batch 140/244] avg loss 1589.05, throughput 2.89855K wps\n",
      "[Epoch 17 Batch 150/244] avg loss 2102.4, throughput 2.457K wps\n",
      "[Epoch 17 Batch 160/244] avg loss 627.729, throughput 3.43642K wps\n",
      "[Epoch 17 Batch 170/244] avg loss 885.857, throughput 2.81691K wps\n",
      "[Epoch 17 Batch 180/244] avg loss 1147.87, throughput 2.35849K wps\n",
      "[Epoch 17 Batch 190/244] avg loss 2172.6, throughput 2.44499K wps\n",
      "[Epoch 17 Batch 200/244] avg loss 5075.91, throughput 2.49376K wps\n",
      "[Epoch 17 Batch 210/244] avg loss 4667.22, throughput 2.90698K wps\n",
      "[Epoch 17 Batch 220/244] avg loss 4915.77, throughput 3.13481K wps\n",
      "[Epoch 17 Batch 230/244] avg loss 2604.78, throughput 2.67379K wps\n",
      "[Epoch 17 Batch 240/244] avg loss 2067.9, throughput 2.6738K wps\n",
      "[Epoch 17] train avg loss 1921.71, train avg r2 -0.447833,throughput 2.88689K wps\n",
      "learning rate: 0.0005\n",
      "[Epoch 18 Batch 10/244] avg loss 2164.63, throughput 2.38663K wps\n",
      "[Epoch 18 Batch 20/244] avg loss 990.911, throughput 2.78552K wps\n",
      "[Epoch 18 Batch 30/244] avg loss 517.552, throughput 2.93254K wps\n",
      "[Epoch 18 Batch 40/244] avg loss 1241.27, throughput 3.86102K wps\n",
      "[Epoch 18 Batch 50/244] avg loss 1261.76, throughput 3.96826K wps\n",
      "[Epoch 18 Batch 60/244] avg loss 1712.73, throughput 2.57732K wps\n",
      "[Epoch 18 Batch 70/244] avg loss 1172.34, throughput 3.2258K wps\n",
      "[Epoch 18 Batch 80/244] avg loss 1249.5, throughput 3.7037K wps\n",
      "[Epoch 18 Batch 90/244] avg loss 1209.56, throughput 2.7027K wps\n",
      "[Epoch 18 Batch 100/244] avg loss 525.788, throughput 3.67647K wps\n",
      "[Epoch 18 Batch 110/244] avg loss 1459.25, throughput 2.7933K wps\n",
      "[Epoch 18 Batch 120/244] avg loss 726.227, throughput 3.06747K wps\n",
      "[Epoch 18 Batch 130/244] avg loss 717.398, throughput 3.26799K wps\n",
      "[Epoch 18 Batch 140/244] avg loss 2659.3, throughput 2.89017K wps\n",
      "[Epoch 18 Batch 150/244] avg loss 2928.29, throughput 2.45699K wps\n",
      "[Epoch 18 Batch 160/244] avg loss 789.669, throughput 3.44827K wps\n",
      "[Epoch 18 Batch 170/244] avg loss 1213.35, throughput 2.80898K wps\n",
      "[Epoch 18 Batch 180/244] avg loss 1161.17, throughput 2.36407K wps\n",
      "[Epoch 18 Batch 190/244] avg loss 1306.8, throughput 2.45097K wps\n",
      "[Epoch 18 Batch 200/244] avg loss 2395.18, throughput 2.48754K wps\n",
      "[Epoch 18 Batch 210/244] avg loss 3070.24, throughput 2.91547K wps\n",
      "[Epoch 18 Batch 220/244] avg loss 2860.39, throughput 3.125K wps\n",
      "[Epoch 18 Batch 230/244] avg loss 1943.12, throughput 2.66667K wps\n",
      "[Epoch 18 Batch 240/244] avg loss 1717.35, throughput 2.66667K wps\n",
      "[Epoch 18] train avg loss 1552.98, train avg r2 -0.058553,throughput 2.88757K wps\n",
      "learning rate: 0.0005\n",
      "[Epoch 19 Batch 10/244] avg loss 1875.15, throughput 2.38095K wps\n",
      "[Epoch 19 Batch 20/244] avg loss 1941.57, throughput 2.79329K wps\n",
      "[Epoch 19 Batch 30/244] avg loss 910.245, throughput 2.93254K wps\n",
      "[Epoch 19 Batch 40/244] avg loss 1598.75, throughput 3.86101K wps\n",
      "[Epoch 19 Batch 50/244] avg loss 2066.19, throughput 3.96826K wps\n",
      "[Epoch 19 Batch 60/244] avg loss 1404.38, throughput 2.57732K wps\n",
      "[Epoch 19 Batch 70/244] avg loss 1014.11, throughput 3.22581K wps\n",
      "[Epoch 19 Batch 80/244] avg loss 1085.51, throughput 3.69003K wps\n",
      "[Epoch 19 Batch 90/244] avg loss 636.998, throughput 2.68817K wps\n",
      "[Epoch 19 Batch 100/244] avg loss 272.761, throughput 3.66302K wps\n",
      "[Epoch 19 Batch 110/244] avg loss 1312.7, throughput 2.78551K wps\n",
      "[Epoch 19 Batch 120/244] avg loss 501.691, throughput 3.05809K wps\n",
      "[Epoch 19 Batch 130/244] avg loss 777.064, throughput 3.27871K wps\n",
      "[Epoch 19 Batch 140/244] avg loss 1495.09, throughput 2.90698K wps\n",
      "[Epoch 19 Batch 150/244] avg loss 2230.84, throughput 2.45098K wps\n",
      "[Epoch 19 Batch 160/244] avg loss 841.769, throughput 3.44825K wps\n",
      "[Epoch 19 Batch 170/244] avg loss 873.143, throughput 2.80899K wps\n",
      "[Epoch 19 Batch 180/244] avg loss 1145.99, throughput 2.35849K wps\n",
      "[Epoch 19 Batch 190/244] avg loss 910.327, throughput 2.43903K wps\n",
      "[Epoch 19 Batch 200/244] avg loss 3093.6, throughput 2.48756K wps\n",
      "[Epoch 19 Batch 210/244] avg loss 2925.26, throughput 2.90698K wps\n",
      "[Epoch 19 Batch 220/244] avg loss 2924.95, throughput 3.12501K wps\n",
      "[Epoch 19 Batch 230/244] avg loss 7444.73, throughput 2.67379K wps\n",
      "[Epoch 19 Batch 240/244] avg loss 6663.16, throughput 2.67379K wps\n",
      "[Epoch 19] train avg loss 1936.06, train avg r2 -0.526205,throughput 2.88553K wps\n",
      "learning rate: 0.0005\n",
      "[Epoch 20 Batch 10/244] avg loss 2627.15, throughput 2.38095K wps\n",
      "[Epoch 20 Batch 20/244] avg loss 3052.37, throughput 2.77779K wps\n",
      "[Epoch 20 Batch 30/244] avg loss 2853.8, throughput 2.94116K wps\n",
      "[Epoch 20 Batch 40/244] avg loss 4256.54, throughput 3.87597K wps\n",
      "[Epoch 20 Batch 50/244] avg loss 3646.2, throughput 3.95254K wps\n",
      "[Epoch 20 Batch 60/244] avg loss 3394.4, throughput 2.57071K wps\n",
      "[Epoch 20 Batch 70/244] avg loss 1297.05, throughput 3.2258K wps\n",
      "[Epoch 20 Batch 80/244] avg loss 1351.89, throughput 3.67647K wps\n",
      "[Epoch 20 Batch 90/244] avg loss 1152.22, throughput 2.69542K wps\n",
      "[Epoch 20 Batch 100/244] avg loss 724.985, throughput 3.64964K wps\n",
      "[Epoch 20 Batch 110/244] avg loss 1560.36, throughput 2.78551K wps\n",
      "[Epoch 20 Batch 120/244] avg loss 1278.99, throughput 3.06748K wps\n",
      "[Epoch 20 Batch 130/244] avg loss 1535.66, throughput 3.28946K wps\n",
      "[Epoch 20 Batch 140/244] avg loss 2386.43, throughput 2.89018K wps\n",
      "[Epoch 20 Batch 150/244] avg loss 3776.36, throughput 2.45097K wps\n",
      "[Epoch 20 Batch 160/244] avg loss 4183.59, throughput 3.44827K wps\n",
      "[Epoch 20 Batch 170/244] avg loss 5840.95, throughput 2.809K wps\n",
      "[Epoch 20 Batch 180/244] avg loss 5034.71, throughput 2.35849K wps\n",
      "[Epoch 20 Batch 190/244] avg loss 3330.84, throughput 2.44498K wps\n",
      "[Epoch 20 Batch 200/244] avg loss 6088.64, throughput 2.48756K wps\n",
      "[Epoch 20 Batch 210/244] avg loss 1996.01, throughput 2.91547K wps\n",
      "[Epoch 20 Batch 220/244] avg loss 1915.92, throughput 3.1348K wps\n",
      "[Epoch 20 Batch 230/244] avg loss 6103.77, throughput 2.6738K wps\n",
      "[Epoch 20 Batch 240/244] avg loss 4566.61, throughput 2.66665K wps\n",
      "[Epoch 20] train avg loss 3172.58, train avg r2 -1.91535,throughput 2.88518K wps\n",
      "learning rate: 0.00025\n",
      "[Epoch 21 Batch 10/244] avg loss 3617.5, throughput 2.38663K wps\n",
      "[Epoch 21 Batch 20/244] avg loss 1855.45, throughput 2.79329K wps\n",
      "[Epoch 21 Batch 30/244] avg loss 995.307, throughput 2.94118K wps\n",
      "[Epoch 21 Batch 40/244] avg loss 3049.9, throughput 3.861K wps\n",
      "[Epoch 21 Batch 50/244] avg loss 1112.66, throughput 3.95259K wps\n",
      "[Epoch 21 Batch 60/244] avg loss 1899.66, throughput 2.57732K wps\n",
      "[Epoch 21 Batch 70/244] avg loss 1403.43, throughput 3.23623K wps\n",
      "[Epoch 21 Batch 80/244] avg loss 1628.22, throughput 3.67648K wps\n",
      "[Epoch 21 Batch 90/244] avg loss 659.369, throughput 2.68818K wps\n",
      "[Epoch 21 Batch 100/244] avg loss 373.093, throughput 3.663K wps\n",
      "[Epoch 21 Batch 110/244] avg loss 1106.72, throughput 2.77777K wps\n",
      "[Epoch 21 Batch 120/244] avg loss 496.016, throughput 3.06749K wps\n",
      "[Epoch 21 Batch 130/244] avg loss 595.82, throughput 3.2787K wps\n",
      "[Epoch 21 Batch 140/244] avg loss 2180.07, throughput 2.89855K wps\n",
      "[Epoch 21 Batch 150/244] avg loss 3406.83, throughput 2.45099K wps\n",
      "[Epoch 21 Batch 160/244] avg loss 2327.98, throughput 3.43641K wps\n",
      "[Epoch 21 Batch 170/244] avg loss 5139.45, throughput 2.80899K wps\n",
      "[Epoch 21 Batch 180/244] avg loss 1772.72, throughput 2.35849K wps\n",
      "[Epoch 21 Batch 190/244] avg loss 2766.97, throughput 2.43902K wps\n",
      "[Epoch 21 Batch 200/244] avg loss 1839.91, throughput 2.48755K wps\n",
      "[Epoch 21 Batch 210/244] avg loss 565.84, throughput 2.91546K wps\n",
      "[Epoch 21 Batch 220/244] avg loss 3489.45, throughput 3.12501K wps\n",
      "[Epoch 21 Batch 230/244] avg loss 4580.58, throughput 2.67379K wps\n",
      "[Epoch 21 Batch 240/244] avg loss 4148.93, throughput 2.66667K wps\n",
      "[Epoch 21] train avg loss 2197.74, train avg r2 -1.02372,throughput 2.88621K wps\n",
      "learning rate: 0.00025\n",
      "[Epoch 22 Batch 10/244] avg loss 3092.65, throughput 2.38662K wps\n",
      "[Epoch 22 Batch 20/244] avg loss 1382.15, throughput 2.78553K wps\n",
      "[Epoch 22 Batch 30/244] avg loss 1140.2, throughput 2.94117K wps\n",
      "[Epoch 22 Batch 40/244] avg loss 589.422, throughput 3.84614K wps\n",
      "[Epoch 22 Batch 50/244] avg loss 554.747, throughput 3.95258K wps\n",
      "[Epoch 22 Batch 60/244] avg loss 1959.04, throughput 2.57069K wps\n",
      "[Epoch 22 Batch 70/244] avg loss 771.476, throughput 3.23625K wps\n",
      "[Epoch 22 Batch 80/244] avg loss 529.605, throughput 3.69003K wps\n",
      "[Epoch 22 Batch 90/244] avg loss 489.206, throughput 2.69542K wps\n",
      "[Epoch 22 Batch 100/244] avg loss 406.717, throughput 3.63636K wps\n",
      "[Epoch 22 Batch 110/244] avg loss 1070.38, throughput 2.79329K wps\n",
      "[Epoch 22 Batch 120/244] avg loss 1203.82, throughput 3.05811K wps\n",
      "[Epoch 22 Batch 130/244] avg loss 600.865, throughput 3.28947K wps\n",
      "[Epoch 22 Batch 140/244] avg loss 1440.86, throughput 2.89018K wps\n",
      "[Epoch 22 Batch 150/244] avg loss 2570.28, throughput 2.457K wps\n",
      "[Epoch 22 Batch 160/244] avg loss 1310.39, throughput 3.42464K wps\n",
      "[Epoch 22 Batch 170/244] avg loss 2563.94, throughput 2.809K wps\n",
      "[Epoch 22 Batch 180/244] avg loss 3820.23, throughput 2.36406K wps\n",
      "[Epoch 22 Batch 190/244] avg loss 4631.51, throughput 2.38663K wps\n",
      "[Epoch 22 Batch 200/244] avg loss 2118.33, throughput 2.46913K wps\n",
      "[Epoch 22 Batch 210/244] avg loss 1553.81, throughput 2.91545K wps\n",
      "[Epoch 22 Batch 220/244] avg loss 1489.58, throughput 3.1348K wps\n",
      "[Epoch 22 Batch 230/244] avg loss 2754.25, throughput 2.66666K wps\n",
      "[Epoch 22 Batch 240/244] avg loss 1900.54, throughput 2.66667K wps\n",
      "[Epoch 22] train avg loss 1670.58, train avg r2 -0.240891,throughput 2.87973K wps\n",
      "learning rate: 0.00025\n",
      "[Epoch 23 Batch 10/244] avg loss 2272.57, throughput 2.3753K wps\n",
      "[Epoch 23 Batch 20/244] avg loss 1573.85, throughput 2.79329K wps\n",
      "[Epoch 23 Batch 30/244] avg loss 957.172, throughput 2.91545K wps\n",
      "[Epoch 23 Batch 40/244] avg loss 716.281, throughput 3.86099K wps\n",
      "[Epoch 23 Batch 50/244] avg loss 498.113, throughput 3.96825K wps\n",
      "[Epoch 23 Batch 60/244] avg loss 1461.03, throughput 2.58398K wps\n",
      "[Epoch 23 Batch 70/244] avg loss 822.741, throughput 3.23623K wps\n",
      "[Epoch 23 Batch 80/244] avg loss 366.046, throughput 3.69003K wps\n",
      "[Epoch 23 Batch 90/244] avg loss 722.488, throughput 2.68818K wps\n",
      "[Epoch 23 Batch 100/244] avg loss 366.457, throughput 3.64961K wps\n",
      "[Epoch 23 Batch 110/244] avg loss 1068.74, throughput 2.79331K wps\n",
      "[Epoch 23 Batch 120/244] avg loss 612.757, throughput 3.0675K wps\n",
      "[Epoch 23 Batch 130/244] avg loss 436.849, throughput 3.27867K wps\n",
      "[Epoch 23 Batch 140/244] avg loss 889.778, throughput 2.89017K wps\n",
      "[Epoch 23 Batch 150/244] avg loss 2048.41, throughput 2.45099K wps\n",
      "[Epoch 23 Batch 160/244] avg loss 1151.55, throughput 3.43642K wps\n",
      "[Epoch 23 Batch 170/244] avg loss 2000.52, throughput 2.80112K wps\n",
      "[Epoch 23 Batch 180/244] avg loss 4568.96, throughput 2.35849K wps\n",
      "[Epoch 23 Batch 190/244] avg loss 4090.63, throughput 2.44499K wps\n",
      "[Epoch 23 Batch 200/244] avg loss 2958.04, throughput 2.49377K wps\n",
      "[Epoch 23 Batch 210/244] avg loss 2533.11, throughput 2.92397K wps\n",
      "[Epoch 23 Batch 220/244] avg loss 948.725, throughput 3.12501K wps\n",
      "[Epoch 23 Batch 230/244] avg loss 1731.12, throughput 2.67379K wps\n",
      "[Epoch 23 Batch 240/244] avg loss 713.409, throughput 2.6738K wps\n",
      "[Epoch 23] train avg loss 1476.5, train avg r2 0.0402792,throughput 2.88518K wps\n",
      "learning rate: 0.00025\n",
      "[Epoch 24 Batch 10/244] avg loss 2085.86, throughput 2.37532K wps\n",
      "[Epoch 24 Batch 20/244] avg loss 1597.04, throughput 2.78551K wps\n",
      "[Epoch 24 Batch 30/244] avg loss 1172.77, throughput 2.94117K wps\n",
      "[Epoch 24 Batch 40/244] avg loss 1061.68, throughput 3.86099K wps\n",
      "[Epoch 24 Batch 50/244] avg loss 790.932, throughput 3.95258K wps\n",
      "[Epoch 24 Batch 60/244] avg loss 1712.8, throughput 2.57731K wps\n",
      "[Epoch 24 Batch 70/244] avg loss 936.89, throughput 3.22581K wps\n",
      "[Epoch 24 Batch 80/244] avg loss 487.248, throughput 3.67649K wps\n",
      "[Epoch 24 Batch 90/244] avg loss 544.522, throughput 2.69541K wps\n",
      "[Epoch 24 Batch 100/244] avg loss 385.716, throughput 3.64964K wps\n",
      "[Epoch 24 Batch 110/244] avg loss 1312.98, throughput 2.78551K wps\n",
      "[Epoch 24 Batch 120/244] avg loss 1029.81, throughput 3.06749K wps\n",
      "[Epoch 24 Batch 130/244] avg loss 738.174, throughput 3.26795K wps\n",
      "[Epoch 24 Batch 140/244] avg loss 968.484, throughput 2.89855K wps\n",
      "[Epoch 24 Batch 150/244] avg loss 2051.93, throughput 2.45098K wps\n",
      "[Epoch 24 Batch 160/244] avg loss 837.21, throughput 3.42466K wps\n",
      "[Epoch 24 Batch 170/244] avg loss 1362.73, throughput 2.80899K wps\n",
      "[Epoch 24 Batch 180/244] avg loss 2161.98, throughput 2.35849K wps\n",
      "[Epoch 24 Batch 190/244] avg loss 1713.97, throughput 2.45097K wps\n",
      "[Epoch 24 Batch 200/244] avg loss 3774.5, throughput 2.48757K wps\n",
      "[Epoch 24 Batch 210/244] avg loss 3256.94, throughput 2.91544K wps\n",
      "[Epoch 24 Batch 220/244] avg loss 1013.25, throughput 3.14466K wps\n",
      "[Epoch 24 Batch 230/244] avg loss 1255.71, throughput 2.66667K wps\n",
      "[Epoch 24 Batch 240/244] avg loss 808.156, throughput 2.66666K wps\n",
      "[Epoch 24] train avg loss 1378.56, train avg r2 0.0472618,throughput 2.88553K wps\n",
      "learning rate: 0.00025\n",
      "[Epoch 25 Batch 10/244] avg loss 1795.87, throughput 2.38096K wps\n",
      "[Epoch 25 Batch 20/244] avg loss 1177.6, throughput 2.65252K wps\n",
      "[Epoch 25 Batch 30/244] avg loss 1147.76, throughput 2.81689K wps\n",
      "[Epoch 25 Batch 40/244] avg loss 1259.61, throughput 3.32227K wps\n",
      "[Epoch 25 Batch 50/244] avg loss 869.777, throughput 3.5842K wps\n",
      "[Epoch 25 Batch 60/244] avg loss 1864.1, throughput 2.43903K wps\n",
      "[Epoch 25 Batch 70/244] avg loss 595.902, throughput 3.03952K wps\n",
      "[Epoch 25 Batch 80/244] avg loss 301.22, throughput 3.47222K wps\n",
      "[Epoch 25 Batch 90/244] avg loss 449.37, throughput 2.57069K wps\n",
      "[Epoch 25 Batch 100/244] avg loss 387.443, throughput 3.46021K wps\n",
      "[Epoch 25 Batch 110/244] avg loss 2003.11, throughput 2.77776K wps\n",
      "[Epoch 25 Batch 120/244] avg loss 1640.85, throughput 3.04879K wps\n",
      "[Epoch 25 Batch 130/244] avg loss 793.59, throughput 3.2573K wps\n",
      "[Epoch 25 Batch 140/244] avg loss 1096.8, throughput 2.88186K wps\n",
      "[Epoch 25 Batch 150/244] avg loss 2086.98, throughput 2.43902K wps\n",
      "[Epoch 25 Batch 160/244] avg loss 734.194, throughput 3.42466K wps\n",
      "[Epoch 25 Batch 170/244] avg loss 1082.53, throughput 2.80111K wps\n",
      "[Epoch 25 Batch 180/244] avg loss 774.838, throughput 2.34742K wps\n",
      "[Epoch 25 Batch 190/244] avg loss 1262.58, throughput 2.43902K wps\n",
      "[Epoch 25 Batch 200/244] avg loss 5668.65, throughput 2.48139K wps\n",
      "[Epoch 25 Batch 210/244] avg loss 4180.52, throughput 2.90696K wps\n",
      "[Epoch 25 Batch 220/244] avg loss 2649.96, throughput 3.12501K wps\n",
      "[Epoch 25 Batch 230/244] avg loss 2584.41, throughput 2.66666K wps\n",
      "[Epoch 25 Batch 240/244] avg loss 2399.89, throughput 2.65957K wps\n",
      "[Epoch 25] train avg loss 1619.06, train avg r2 -0.251305,throughput 2.8143K wps\n",
      "learning rate: 0.00025\n",
      "[Epoch 26 Batch 10/244] avg loss 2201.01, throughput 2.37529K wps\n",
      "[Epoch 26 Batch 20/244] avg loss 870.907, throughput 2.77009K wps\n",
      "[Epoch 26 Batch 30/244] avg loss 810.219, throughput 2.91546K wps\n",
      "[Epoch 26 Batch 40/244] avg loss 1203.73, throughput 3.84615K wps\n",
      "[Epoch 26 Batch 50/244] avg loss 756.349, throughput 3.93701K wps\n",
      "[Epoch 26 Batch 60/244] avg loss 1552.26, throughput 2.55755K wps\n",
      "[Epoch 26 Batch 70/244] avg loss 478.702, throughput 3.20511K wps\n",
      "[Epoch 26 Batch 80/244] avg loss 292.615, throughput 3.66302K wps\n",
      "[Epoch 26 Batch 90/244] avg loss 439.874, throughput 2.66665K wps\n",
      "[Epoch 26 Batch 100/244] avg loss 455.58, throughput 3.64964K wps\n",
      "[Epoch 26 Batch 110/244] avg loss 2422.86, throughput 2.75482K wps\n",
      "[Epoch 26 Batch 120/244] avg loss 2360.39, throughput 3.04878K wps\n",
      "[Epoch 26 Batch 130/244] avg loss 867.039, throughput 3.23627K wps\n",
      "[Epoch 26 Batch 140/244] avg loss 1162.96, throughput 2.84089K wps\n",
      "[Epoch 26 Batch 150/244] avg loss 1729.75, throughput 2.43903K wps\n",
      "[Epoch 26 Batch 160/244] avg loss 562.389, throughput 3.42464K wps\n",
      "[Epoch 26 Batch 170/244] avg loss 884.539, throughput 2.7933K wps\n",
      "[Epoch 26 Batch 180/244] avg loss 515.222, throughput 2.35293K wps\n",
      "[Epoch 26 Batch 190/244] avg loss 1724.47, throughput 2.4331K wps\n",
      "[Epoch 26 Batch 200/244] avg loss 5671.94, throughput 2.48138K wps\n",
      "[Epoch 26 Batch 210/244] avg loss 4550.29, throughput 2.90697K wps\n",
      "[Epoch 26 Batch 220/244] avg loss 2648.4, throughput 3.11527K wps\n",
      "[Epoch 26 Batch 230/244] avg loss 4342.25, throughput 2.65957K wps\n",
      "[Epoch 26 Batch 240/244] avg loss 2875.49, throughput 2.65956K wps\n",
      "[Epoch 26] train avg loss 1733.87, train avg r2 -0.383384,throughput 2.86688K wps\n",
      "learning rate: 0.00025\n",
      "[Epoch 27 Batch 10/244] avg loss 2098.58, throughput 2.36967K wps\n",
      "[Epoch 27 Batch 20/244] avg loss 790.236, throughput 2.77009K wps\n",
      "[Epoch 27 Batch 30/244] avg loss 444.896, throughput 2.91544K wps\n",
      "[Epoch 27 Batch 40/244] avg loss 838.897, throughput 3.83143K wps\n",
      "[Epoch 27 Batch 50/244] avg loss 1025.12, throughput 3.92159K wps\n",
      "[Epoch 27 Batch 60/244] avg loss 1935.04, throughput 2.56409K wps\n",
      "[Epoch 27 Batch 70/244] avg loss 742.887, throughput 3.21542K wps\n",
      "[Epoch 27 Batch 80/244] avg loss 329.252, throughput 3.66301K wps\n",
      "[Epoch 27 Batch 90/244] avg loss 344.849, throughput 2.68097K wps\n",
      "[Epoch 27 Batch 100/244] avg loss 416.088, throughput 3.64964K wps\n",
      "[Epoch 27 Batch 110/244] avg loss 1580.69, throughput 2.77007K wps\n",
      "[Epoch 27 Batch 120/244] avg loss 1020.34, throughput 3.0581K wps\n",
      "[Epoch 27 Batch 130/244] avg loss 729.848, throughput 3.26797K wps\n",
      "[Epoch 27 Batch 140/244] avg loss 1051.87, throughput 2.87356K wps\n",
      "[Epoch 27 Batch 150/244] avg loss 1388.47, throughput 2.44498K wps\n",
      "[Epoch 27 Batch 160/244] avg loss 468.756, throughput 3.41297K wps\n",
      "[Epoch 27 Batch 170/244] avg loss 679.477, throughput 2.80112K wps\n",
      "[Epoch 27 Batch 180/244] avg loss 592.059, throughput 2.34192K wps\n",
      "[Epoch 27 Batch 190/244] avg loss 1409.78, throughput 2.43309K wps\n",
      "[Epoch 27 Batch 200/244] avg loss 3613.22, throughput 2.47524K wps\n",
      "[Epoch 27 Batch 210/244] avg loss 2686.95, throughput 2.89856K wps\n",
      "[Epoch 27 Batch 220/244] avg loss 1086.67, throughput 3.1056K wps\n",
      "[Epoch 27 Batch 230/244] avg loss 3252.62, throughput 2.66666K wps\n",
      "[Epoch 27 Batch 240/244] avg loss 1809.55, throughput 2.65956K wps\n",
      "[Epoch 27] train avg loss 1302.14, train avg r2 0.211532,throughput 2.8716K wps\n",
      "learning rate: 0.00025\n",
      "[Epoch 28 Batch 10/244] avg loss 1789.43, throughput 2.3753K wps\n",
      "[Epoch 28 Batch 20/244] avg loss 1078.63, throughput 2.77008K wps\n",
      "[Epoch 28 Batch 30/244] avg loss 628.8, throughput 2.91544K wps\n",
      "[Epoch 28 Batch 40/244] avg loss 1492.17, throughput 3.84615K wps\n",
      "[Epoch 28 Batch 50/244] avg loss 1670.93, throughput 3.95256K wps\n",
      "[Epoch 28 Batch 60/244] avg loss 2000.34, throughput 2.55103K wps\n",
      "[Epoch 28 Batch 70/244] avg loss 787.769, throughput 3.20513K wps\n",
      "[Epoch 28 Batch 80/244] avg loss 284.358, throughput 3.66302K wps\n",
      "[Epoch 28 Batch 90/244] avg loss 545.818, throughput 2.68096K wps\n",
      "[Epoch 28 Batch 100/244] avg loss 314.943, throughput 3.6496K wps\n",
      "[Epoch 28 Batch 110/244] avg loss 1221.57, throughput 2.77009K wps\n",
      "[Epoch 28 Batch 120/244] avg loss 1176.08, throughput 3.04878K wps\n",
      "[Epoch 28 Batch 130/244] avg loss 1478.98, throughput 3.26798K wps\n",
      "[Epoch 28 Batch 140/244] avg loss 822.074, throughput 2.88184K wps\n",
      "[Epoch 28 Batch 150/244] avg loss 1516.07, throughput 2.43903K wps\n",
      "[Epoch 28 Batch 160/244] avg loss 488.18, throughput 3.43642K wps\n",
      "[Epoch 28 Batch 170/244] avg loss 505.704, throughput 2.79329K wps\n",
      "[Epoch 28 Batch 180/244] avg loss 693.711, throughput 2.35293K wps\n",
      "[Epoch 28 Batch 190/244] avg loss 1001.6, throughput 2.43903K wps\n",
      "[Epoch 28 Batch 200/244] avg loss 2098.45, throughput 2.47525K wps\n",
      "[Epoch 28 Batch 210/244] avg loss 1490.16, throughput 2.90697K wps\n",
      "[Epoch 28 Batch 220/244] avg loss 2066.5, throughput 3.1056K wps\n",
      "[Epoch 28 Batch 230/244] avg loss 3190.1, throughput 2.65957K wps\n",
      "[Epoch 28 Batch 240/244] avg loss 2080.84, throughput 2.65957K wps\n",
      "[Epoch 28] train avg loss 1310.01, train avg r2 0.111892,throughput 2.87194K wps\n",
      "learning rate: 0.00025\n",
      "[Epoch 29 Batch 10/244] avg loss 1897.18, throughput 2.36967K wps\n",
      "[Epoch 29 Batch 20/244] avg loss 1555.18, throughput 2.76243K wps\n",
      "[Epoch 29 Batch 30/244] avg loss 457.306, throughput 2.92397K wps\n",
      "[Epoch 29 Batch 40/244] avg loss 1929.73, throughput 3.84614K wps\n",
      "[Epoch 29 Batch 50/244] avg loss 1733.71, throughput 3.93702K wps\n",
      "[Epoch 29 Batch 60/244] avg loss 1793.94, throughput 2.5641K wps\n",
      "[Epoch 29 Batch 70/244] avg loss 565.481, throughput 3.21544K wps\n",
      "[Epoch 29 Batch 80/244] avg loss 328.518, throughput 3.663K wps\n",
      "[Epoch 29 Batch 90/244] avg loss 596.268, throughput 2.68097K wps\n",
      "[Epoch 29 Batch 100/244] avg loss 344.576, throughput 3.6232K wps\n",
      "[Epoch 29 Batch 110/244] avg loss 1045.43, throughput 2.77008K wps\n",
      "[Epoch 29 Batch 120/244] avg loss 801.085, throughput 3.04878K wps\n",
      "[Epoch 29 Batch 130/244] avg loss 1323.37, throughput 3.24675K wps\n",
      "[Epoch 29 Batch 140/244] avg loss 1594.84, throughput 2.87355K wps\n",
      "[Epoch 29 Batch 150/244] avg loss 1906.16, throughput 2.43309K wps\n",
      "[Epoch 29 Batch 160/244] avg loss 756.521, throughput 3.41297K wps\n",
      "[Epoch 29 Batch 170/244] avg loss 650.734, throughput 2.7933K wps\n",
      "[Epoch 29 Batch 180/244] avg loss 677.679, throughput 2.34741K wps\n",
      "[Epoch 29 Batch 190/244] avg loss 574.69, throughput 2.42719K wps\n",
      "[Epoch 29 Batch 200/244] avg loss 1429.25, throughput 2.47525K wps\n",
      "[Epoch 29 Batch 210/244] avg loss 1039.45, throughput 2.89855K wps\n",
      "[Epoch 29 Batch 220/244] avg loss 2597.6, throughput 3.10559K wps\n",
      "[Epoch 29 Batch 230/244] avg loss 3738.38, throughput 2.65957K wps\n",
      "[Epoch 29 Batch 240/244] avg loss 2489.83, throughput 2.65956K wps\n",
      "[Epoch 29] train avg loss 1363.91, train avg r2 0.0580367,throughput 2.87025K wps\n",
      "learning rate: 0.00025\n",
      "[Epoch 30 Batch 10/244] avg loss 2385.18, throughput 2.36967K wps\n",
      "[Epoch 30 Batch 20/244] avg loss 2023.4, throughput 2.77009K wps\n",
      "[Epoch 30 Batch 30/244] avg loss 1251.96, throughput 2.91545K wps\n",
      "[Epoch 30 Batch 40/244] avg loss 702.709, throughput 3.84615K wps\n",
      "[Epoch 30 Batch 50/244] avg loss 717.295, throughput 3.93702K wps\n",
      "[Epoch 30 Batch 60/244] avg loss 2710.28, throughput 2.57069K wps\n",
      "[Epoch 30 Batch 70/244] avg loss 3997.79, throughput 3.20512K wps\n",
      "[Epoch 30 Batch 80/244] avg loss 1797.8, throughput 3.67645K wps\n",
      "[Epoch 30 Batch 90/244] avg loss 958.245, throughput 2.67382K wps\n",
      "[Epoch 30 Batch 100/244] avg loss 422.735, throughput 3.63634K wps\n",
      "[Epoch 30 Batch 110/244] avg loss 1089.8, throughput 2.77008K wps\n",
      "[Epoch 30 Batch 120/244] avg loss 538.59, throughput 3.04879K wps\n",
      "[Epoch 30 Batch 130/244] avg loss 1156.35, throughput 3.25732K wps\n",
      "[Epoch 30 Batch 140/244] avg loss 1919.72, throughput 2.87356K wps\n",
      "[Epoch 30 Batch 150/244] avg loss 2494.48, throughput 2.44499K wps\n",
      "[Epoch 30 Batch 160/244] avg loss 1342.13, throughput 3.42467K wps\n",
      "[Epoch 30 Batch 170/244] avg loss 1341.84, throughput 2.7933K wps\n",
      "[Epoch 30 Batch 180/244] avg loss 1487.22, throughput 2.3474K wps\n",
      "[Epoch 30 Batch 190/244] avg loss 1651.72, throughput 2.43904K wps\n",
      "[Epoch 30 Batch 200/244] avg loss 1733.22, throughput 2.48139K wps\n",
      "[Epoch 30 Batch 210/244] avg loss 690.772, throughput 2.89017K wps\n",
      "[Epoch 30 Batch 220/244] avg loss 1106.01, throughput 3.11528K wps\n",
      "[Epoch 30 Batch 230/244] avg loss 4854.19, throughput 2.65957K wps\n",
      "[Epoch 30 Batch 240/244] avg loss 3268.76, throughput 2.65958K wps\n",
      "[Epoch 30] train avg loss 1745.84, train avg r2 -0.418416,throughput 2.87194K wps\n",
      "learning rate: 0.000125\n",
      "[Epoch 31 Batch 10/244] avg loss 1932.67, throughput 2.36967K wps\n",
      "[Epoch 31 Batch 20/244] avg loss 908.286, throughput 2.77009K wps\n",
      "[Epoch 31 Batch 30/244] avg loss 1069.64, throughput 2.91545K wps\n",
      "[Epoch 31 Batch 40/244] avg loss 1020.4, throughput 3.8314K wps\n",
      "[Epoch 31 Batch 50/244] avg loss 625.029, throughput 3.93703K wps\n",
      "[Epoch 31 Batch 60/244] avg loss 2349, throughput 2.57069K wps\n",
      "[Epoch 31 Batch 70/244] avg loss 1363.23, throughput 3.21543K wps\n",
      "[Epoch 31 Batch 80/244] avg loss 381.94, throughput 3.67646K wps\n",
      "[Epoch 31 Batch 90/244] avg loss 451.215, throughput 2.68097K wps\n",
      "[Epoch 31 Batch 100/244] avg loss 280.111, throughput 3.61011K wps\n",
      "[Epoch 31 Batch 110/244] avg loss 1028.4, throughput 2.77007K wps\n",
      "[Epoch 31 Batch 120/244] avg loss 519.987, throughput 3.04879K wps\n",
      "[Epoch 31 Batch 130/244] avg loss 551.608, throughput 3.23624K wps\n",
      "[Epoch 31 Batch 140/244] avg loss 1163.22, throughput 2.89017K wps\n",
      "[Epoch 31 Batch 150/244] avg loss 1715.79, throughput 2.44498K wps\n",
      "[Epoch 31 Batch 160/244] avg loss 462.887, throughput 3.43643K wps\n",
      "[Epoch 31 Batch 170/244] avg loss 943.526, throughput 2.7933K wps\n",
      "[Epoch 31 Batch 180/244] avg loss 888.181, throughput 2.34741K wps\n",
      "[Epoch 31 Batch 190/244] avg loss 647.886, throughput 2.43903K wps\n",
      "[Epoch 31 Batch 200/244] avg loss 1197.27, throughput 2.48138K wps\n",
      "[Epoch 31 Batch 210/244] avg loss 697.635, throughput 2.91544K wps\n",
      "[Epoch 31 Batch 220/244] avg loss 1168.76, throughput 3.125K wps\n",
      "[Epoch 31 Batch 230/244] avg loss 1662.54, throughput 2.65957K wps\n",
      "[Epoch 31 Batch 240/244] avg loss 2556.36, throughput 2.65252K wps\n",
      "[Epoch 31] train avg loss 1084.75, train avg r2 0.338795,throughput 2.87228K wps\n",
      "learning rate: 0.000125\n",
      "[Epoch 32 Batch 10/244] avg loss 1544.24, throughput 2.3753K wps\n",
      "[Epoch 32 Batch 20/244] avg loss 976.789, throughput 2.77009K wps\n",
      "[Epoch 32 Batch 30/244] avg loss 624.548, throughput 2.92397K wps\n",
      "[Epoch 32 Batch 40/244] avg loss 714.934, throughput 3.84613K wps\n",
      "[Epoch 32 Batch 50/244] avg loss 524.278, throughput 3.9216K wps\n",
      "[Epoch 32 Batch 60/244] avg loss 1773.01, throughput 2.5641K wps\n",
      "[Epoch 32 Batch 70/244] avg loss 408.198, throughput 3.20512K wps\n",
      "[Epoch 32 Batch 80/244] avg loss 683.261, throughput 3.66301K wps\n",
      "[Epoch 32 Batch 90/244] avg loss 480.748, throughput 2.68097K wps\n",
      "[Epoch 32 Batch 100/244] avg loss 429.997, throughput 3.62318K wps\n",
      "[Epoch 32 Batch 110/244] avg loss 1267.52, throughput 2.77008K wps\n",
      "[Epoch 32 Batch 120/244] avg loss 767.512, throughput 3.04877K wps\n",
      "[Epoch 32 Batch 130/244] avg loss 576.886, throughput 3.24674K wps\n",
      "[Epoch 32 Batch 140/244] avg loss 1089.51, throughput 2.87356K wps\n",
      "[Epoch 32 Batch 150/244] avg loss 1394.23, throughput 2.4331K wps\n",
      "[Epoch 32 Batch 160/244] avg loss 366.208, throughput 3.41294K wps\n",
      "[Epoch 32 Batch 170/244] avg loss 544.217, throughput 2.80113K wps\n",
      "[Epoch 32 Batch 180/244] avg loss 443.173, throughput 2.34741K wps\n",
      "[Epoch 32 Batch 190/244] avg loss 357.331, throughput 2.4331K wps\n",
      "[Epoch 32 Batch 200/244] avg loss 1299.51, throughput 2.47525K wps\n",
      "[Epoch 32 Batch 210/244] avg loss 1066.82, throughput 2.89855K wps\n",
      "[Epoch 32 Batch 220/244] avg loss 1151.12, throughput 3.11528K wps\n",
      "[Epoch 32 Batch 230/244] avg loss 1802.56, throughput 2.66666K wps\n",
      "[Epoch 32 Batch 240/244] avg loss 2309.27, throughput 2.65252K wps\n",
      "[Epoch 32] train avg loss 983.671, train avg r2 0.432029,throughput 2.87126K wps\n",
      "learning rate: 0.000125\n",
      "[Epoch 33 Batch 10/244] avg loss 1579.42, throughput 2.36966K wps\n",
      "[Epoch 33 Batch 20/244] avg loss 1176.61, throughput 2.76243K wps\n",
      "[Epoch 33 Batch 30/244] avg loss 675.274, throughput 2.91546K wps\n",
      "[Epoch 33 Batch 40/244] avg loss 546.037, throughput 3.83141K wps\n",
      "[Epoch 33 Batch 50/244] avg loss 449.21, throughput 3.93703K wps\n",
      "[Epoch 33 Batch 60/244] avg loss 1441.23, throughput 2.56409K wps\n",
      "[Epoch 33 Batch 70/244] avg loss 459.909, throughput 3.21542K wps\n",
      "[Epoch 33 Batch 80/244] avg loss 706.613, throughput 3.66301K wps\n",
      "[Epoch 33 Batch 90/244] avg loss 716.326, throughput 2.6738K wps\n",
      "[Epoch 33 Batch 100/244] avg loss 556.789, throughput 3.62319K wps\n",
      "[Epoch 33 Batch 110/244] avg loss 1267.83, throughput 2.76242K wps\n",
      "[Epoch 33 Batch 120/244] avg loss 694.15, throughput 3.03952K wps\n",
      "[Epoch 33 Batch 130/244] avg loss 775.018, throughput 3.24675K wps\n",
      "[Epoch 33 Batch 140/244] avg loss 1021.35, throughput 2.88184K wps\n",
      "[Epoch 33 Batch 150/244] avg loss 1141.74, throughput 2.43903K wps\n",
      "[Epoch 33 Batch 160/244] avg loss 329.113, throughput 3.42466K wps\n",
      "[Epoch 33 Batch 170/244] avg loss 442.105, throughput 2.79331K wps\n",
      "[Epoch 33 Batch 180/244] avg loss 397.344, throughput 2.34741K wps\n",
      "[Epoch 33 Batch 190/244] avg loss 352.105, throughput 2.43309K wps\n",
      "[Epoch 33 Batch 200/244] avg loss 1350.11, throughput 2.46913K wps\n",
      "[Epoch 33 Batch 210/244] avg loss 1195.89, throughput 2.90698K wps\n",
      "[Epoch 33 Batch 220/244] avg loss 1002.36, throughput 3.12501K wps\n",
      "[Epoch 33 Batch 230/244] avg loss 2060.55, throughput 2.67379K wps\n",
      "[Epoch 33 Batch 240/244] avg loss 2140.1, throughput 2.65252K wps\n",
      "[Epoch 33] train avg loss 994.184, train avg r2 0.44528,throughput 2.87059K wps\n",
      "learning rate: 0.000125\n",
      "[Epoch 34 Batch 10/244] avg loss 1329.04, throughput 2.36968K wps\n",
      "[Epoch 34 Batch 20/244] avg loss 1423.38, throughput 2.77008K wps\n",
      "[Epoch 34 Batch 30/244] avg loss 765.495, throughput 2.92397K wps\n",
      "[Epoch 34 Batch 40/244] avg loss 592.139, throughput 3.8314K wps\n",
      "[Epoch 34 Batch 50/244] avg loss 539.46, throughput 3.93703K wps\n",
      "[Epoch 34 Batch 60/244] avg loss 1416.81, throughput 2.57069K wps\n",
      "[Epoch 34 Batch 70/244] avg loss 480.211, throughput 3.20512K wps\n",
      "[Epoch 34 Batch 80/244] avg loss 431.663, throughput 3.64965K wps\n",
      "[Epoch 34 Batch 90/244] avg loss 578.856, throughput 2.68096K wps\n",
      "[Epoch 34 Batch 100/244] avg loss 438.994, throughput 3.63633K wps\n",
      "[Epoch 34 Batch 110/244] avg loss 925.687, throughput 2.76245K wps\n",
      "[Epoch 34 Batch 120/244] avg loss 554.085, throughput 3.04877K wps\n",
      "[Epoch 34 Batch 130/244] avg loss 761.372, throughput 3.25733K wps\n",
      "[Epoch 34 Batch 140/244] avg loss 842.621, throughput 2.87356K wps\n",
      "[Epoch 34 Batch 150/244] avg loss 1127.85, throughput 2.43903K wps\n",
      "[Epoch 34 Batch 160/244] avg loss 343.683, throughput 3.42463K wps\n",
      "[Epoch 34 Batch 170/244] avg loss 587.035, throughput 2.79331K wps\n",
      "[Epoch 34 Batch 180/244] avg loss 367.651, throughput 2.35294K wps\n",
      "[Epoch 34 Batch 190/244] avg loss 289.31, throughput 2.43309K wps\n",
      "[Epoch 34 Batch 200/244] avg loss 1280.25, throughput 2.48139K wps\n",
      "[Epoch 34 Batch 210/244] avg loss 1163.89, throughput 2.91545K wps\n",
      "[Epoch 34 Batch 220/244] avg loss 753.153, throughput 3.11527K wps\n",
      "[Epoch 34 Batch 230/244] avg loss 2135.82, throughput 2.65958K wps\n",
      "[Epoch 34 Batch 240/244] avg loss 1871.42, throughput 2.65956K wps\n",
      "[Epoch 34] train avg loss 941.55, train avg r2 0.499314,throughput 2.87126K wps\n",
      "learning rate: 0.000125\n",
      "[Epoch 35 Batch 10/244] avg loss 1266.86, throughput 2.32558K wps\n",
      "[Epoch 35 Batch 20/244] avg loss 1438.77, throughput 2.77776K wps\n",
      "[Epoch 35 Batch 30/244] avg loss 673.533, throughput 2.85714K wps\n",
      "[Epoch 35 Batch 40/244] avg loss 809.936, throughput 3.8168K wps\n",
      "[Epoch 35 Batch 50/244] avg loss 675.768, throughput 3.937K wps\n",
      "[Epoch 35 Batch 60/244] avg loss 1314.12, throughput 2.53164K wps\n",
      "[Epoch 35 Batch 70/244] avg loss 418.64, throughput 3.16455K wps\n",
      "[Epoch 35 Batch 80/244] avg loss 319.155, throughput 3.64966K wps\n",
      "[Epoch 35 Batch 90/244] avg loss 474.14, throughput 2.67379K wps\n",
      "[Epoch 35 Batch 100/244] avg loss 296.909, throughput 3.62318K wps\n",
      "[Epoch 35 Batch 110/244] avg loss 790.306, throughput 2.77009K wps\n",
      "[Epoch 35 Batch 120/244] avg loss 416.14, throughput 3.04877K wps\n",
      "[Epoch 35 Batch 130/244] avg loss 496.548, throughput 3.25733K wps\n",
      "[Epoch 35 Batch 140/244] avg loss 656.519, throughput 2.88184K wps\n",
      "[Epoch 35 Batch 150/244] avg loss 1103.2, throughput 2.43903K wps\n",
      "[Epoch 35 Batch 160/244] avg loss 321.959, throughput 3.42466K wps\n",
      "[Epoch 35 Batch 170/244] avg loss 630.991, throughput 2.79329K wps\n",
      "[Epoch 35 Batch 180/244] avg loss 373.783, throughput 2.34192K wps\n",
      "[Epoch 35 Batch 190/244] avg loss 352.366, throughput 2.43309K wps\n",
      "[Epoch 35 Batch 200/244] avg loss 1158.27, throughput 2.46914K wps\n",
      "[Epoch 35 Batch 210/244] avg loss 909.739, throughput 2.89855K wps\n",
      "[Epoch 35 Batch 220/244] avg loss 508.446, throughput 3.125K wps\n",
      "[Epoch 35 Batch 230/244] avg loss 1872.11, throughput 2.66667K wps\n",
      "[Epoch 35 Batch 240/244] avg loss 1397.08, throughput 2.65957K wps\n",
      "[Epoch 35] train avg loss 840.854, train avg r2 0.568903,throughput 2.86049K wps\n",
      "learning rate: 0.000125\n",
      "[Epoch 36 Batch 10/244] avg loss 1180.45, throughput 2.36966K wps\n",
      "[Epoch 36 Batch 20/244] avg loss 1366.33, throughput 2.77779K wps\n",
      "[Epoch 36 Batch 30/244] avg loss 617.964, throughput 2.90697K wps\n",
      "[Epoch 36 Batch 40/244] avg loss 1015.19, throughput 3.84615K wps\n",
      "[Epoch 36 Batch 50/244] avg loss 761.643, throughput 3.92158K wps\n",
      "[Epoch 36 Batch 60/244] avg loss 1335.64, throughput 2.55754K wps\n",
      "[Epoch 36 Batch 70/244] avg loss 363.429, throughput 3.22581K wps\n",
      "[Epoch 36 Batch 80/244] avg loss 262.919, throughput 3.663K wps\n",
      "[Epoch 36 Batch 90/244] avg loss 416.151, throughput 2.68097K wps\n",
      "[Epoch 36 Batch 100/244] avg loss 236.185, throughput 3.63636K wps\n",
      "[Epoch 36 Batch 110/244] avg loss 703.022, throughput 2.77777K wps\n",
      "[Epoch 36 Batch 120/244] avg loss 310.253, throughput 3.06748K wps\n",
      "[Epoch 36 Batch 130/244] avg loss 329.142, throughput 3.26798K wps\n",
      "[Epoch 36 Batch 140/244] avg loss 543.106, throughput 2.88183K wps\n",
      "[Epoch 36 Batch 150/244] avg loss 1106.34, throughput 2.44499K wps\n",
      "[Epoch 36 Batch 160/244] avg loss 338.025, throughput 3.42465K wps\n",
      "[Epoch 36 Batch 170/244] avg loss 654.283, throughput 2.7933K wps\n",
      "[Epoch 36 Batch 180/244] avg loss 377.823, throughput 2.3474K wps\n",
      "[Epoch 36 Batch 190/244] avg loss 501.533, throughput 2.43311K wps\n",
      "[Epoch 36 Batch 200/244] avg loss 1056.31, throughput 2.48139K wps\n",
      "[Epoch 36 Batch 210/244] avg loss 616.676, throughput 2.91544K wps\n",
      "[Epoch 36 Batch 220/244] avg loss 418.448, throughput 3.11528K wps\n",
      "[Epoch 36 Batch 230/244] avg loss 1430, throughput 2.65252K wps\n",
      "[Epoch 36 Batch 240/244] avg loss 1096.52, throughput 2.66667K wps\n",
      "[Epoch 36] train avg loss 765.487, train avg r2 0.587669,throughput 2.87363K wps\n",
      "learning rate: 0.000125\n",
      "[Epoch 37 Batch 10/244] avg loss 1136, throughput 2.36967K wps\n",
      "[Epoch 37 Batch 20/244] avg loss 1473.55, throughput 2.77778K wps\n",
      "[Epoch 37 Batch 30/244] avg loss 499.298, throughput 2.91545K wps\n",
      "[Epoch 37 Batch 40/244] avg loss 1058.24, throughput 3.8314K wps\n",
      "[Epoch 37 Batch 50/244] avg loss 681.521, throughput 3.93702K wps\n",
      "[Epoch 37 Batch 60/244] avg loss 1288.83, throughput 2.57068K wps\n",
      "[Epoch 37 Batch 70/244] avg loss 349.052, throughput 3.21543K wps\n",
      "[Epoch 37 Batch 80/244] avg loss 240.831, throughput 3.66302K wps\n",
      "[Epoch 37 Batch 90/244] avg loss 390.532, throughput 2.68818K wps\n",
      "[Epoch 37 Batch 100/244] avg loss 227.645, throughput 3.62318K wps\n",
      "[Epoch 37 Batch 110/244] avg loss 669.906, throughput 2.77009K wps\n",
      "[Epoch 37 Batch 120/244] avg loss 288.26, throughput 3.04877K wps\n",
      "[Epoch 37 Batch 130/244] avg loss 413.407, throughput 3.25734K wps\n",
      "[Epoch 37 Batch 140/244] avg loss 566.322, throughput 2.88183K wps\n",
      "[Epoch 37 Batch 150/244] avg loss 1173.35, throughput 2.42719K wps\n",
      "[Epoch 37 Batch 160/244] avg loss 335.723, throughput 3.41299K wps\n",
      "[Epoch 37 Batch 170/244] avg loss 526.709, throughput 2.7933K wps\n",
      "[Epoch 37 Batch 180/244] avg loss 441.817, throughput 2.34741K wps\n",
      "[Epoch 37 Batch 190/244] avg loss 408.131, throughput 2.43901K wps\n",
      "[Epoch 37 Batch 200/244] avg loss 945.073, throughput 2.47525K wps\n",
      "[Epoch 37 Batch 210/244] avg loss 429.984, throughput 2.89855K wps\n",
      "[Epoch 37 Batch 220/244] avg loss 330.443, throughput 3.10558K wps\n",
      "[Epoch 37 Batch 230/244] avg loss 804.102, throughput 2.65958K wps\n",
      "[Epoch 37 Batch 240/244] avg loss 871.417, throughput 2.65957K wps\n",
      "[Epoch 37] train avg loss 693.635, train avg r2 0.60841,throughput 2.86991K wps\n",
      "learning rate: 0.000125\n",
      "[Epoch 38 Batch 10/244] avg loss 1143.31, throughput 2.37529K wps\n",
      "[Epoch 38 Batch 20/244] avg loss 1380.18, throughput 2.77008K wps\n",
      "[Epoch 38 Batch 30/244] avg loss 552.111, throughput 2.92397K wps\n",
      "[Epoch 38 Batch 40/244] avg loss 895.65, throughput 3.83142K wps\n",
      "[Epoch 38 Batch 50/244] avg loss 568.897, throughput 3.90626K wps\n",
      "[Epoch 38 Batch 60/244] avg loss 1286.19, throughput 2.5707K wps\n",
      "[Epoch 38 Batch 70/244] avg loss 324.614, throughput 3.21542K wps\n",
      "[Epoch 38 Batch 80/244] avg loss 227.658, throughput 3.663K wps\n",
      "[Epoch 38 Batch 90/244] avg loss 428.601, throughput 2.68817K wps\n",
      "[Epoch 38 Batch 100/244] avg loss 235.446, throughput 3.63637K wps\n",
      "[Epoch 38 Batch 110/244] avg loss 859.906, throughput 2.77008K wps\n",
      "[Epoch 38 Batch 120/244] avg loss 289.052, throughput 3.0581K wps\n",
      "[Epoch 38 Batch 130/244] avg loss 529.995, throughput 3.25731K wps\n",
      "[Epoch 38 Batch 140/244] avg loss 595.189, throughput 2.88185K wps\n",
      "[Epoch 38 Batch 150/244] avg loss 1123.01, throughput 2.44498K wps\n",
      "[Epoch 38 Batch 160/244] avg loss 347.83, throughput 3.42464K wps\n",
      "[Epoch 38 Batch 170/244] avg loss 499.892, throughput 2.7933K wps\n",
      "[Epoch 38 Batch 180/244] avg loss 492.715, throughput 2.35294K wps\n",
      "[Epoch 38 Batch 190/244] avg loss 278.104, throughput 2.43309K wps\n",
      "[Epoch 38 Batch 200/244] avg loss 989.091, throughput 2.47525K wps\n",
      "[Epoch 38 Batch 210/244] avg loss 364.718, throughput 2.89855K wps\n",
      "[Epoch 38 Batch 220/244] avg loss 298.46, throughput 3.11528K wps\n",
      "[Epoch 38 Batch 230/244] avg loss 475.435, throughput 2.65956K wps\n",
      "[Epoch 38 Batch 240/244] avg loss 713.081, throughput 2.65251K wps\n",
      "[Epoch 38] train avg loss 650.72, train avg r2 0.632212,throughput 2.8716K wps\n",
      "learning rate: 0.000125\n",
      "[Epoch 39 Batch 10/244] avg loss 1294.38, throughput 2.37529K wps\n",
      "[Epoch 39 Batch 20/244] avg loss 1320.35, throughput 2.74725K wps\n",
      "[Epoch 39 Batch 30/244] avg loss 559.114, throughput 2.92397K wps\n",
      "[Epoch 39 Batch 40/244] avg loss 948.85, throughput 3.84616K wps\n",
      "[Epoch 39 Batch 50/244] avg loss 533.105, throughput 3.95257K wps\n",
      "[Epoch 39 Batch 60/244] avg loss 1206.67, throughput 2.5641K wps\n",
      "[Epoch 39 Batch 70/244] avg loss 303.246, throughput 3.20513K wps\n",
      "[Epoch 39 Batch 80/244] avg loss 226.585, throughput 3.64965K wps\n",
      "[Epoch 39 Batch 90/244] avg loss 472.06, throughput 2.67379K wps\n",
      "[Epoch 39 Batch 100/244] avg loss 273.068, throughput 3.63637K wps\n",
      "[Epoch 39 Batch 110/244] avg loss 643.945, throughput 2.77778K wps\n",
      "[Epoch 39 Batch 120/244] avg loss 295.825, throughput 3.04877K wps\n",
      "[Epoch 39 Batch 130/244] avg loss 566.473, throughput 3.26798K wps\n",
      "[Epoch 39 Batch 140/244] avg loss 555.508, throughput 2.89017K wps\n",
      "[Epoch 39 Batch 150/244] avg loss 1111.38, throughput 2.43902K wps\n",
      "[Epoch 39 Batch 160/244] avg loss 355.398, throughput 3.41297K wps\n",
      "[Epoch 39 Batch 170/244] avg loss 505.734, throughput 2.7933K wps\n",
      "[Epoch 39 Batch 180/244] avg loss 546.671, throughput 2.34742K wps\n",
      "[Epoch 39 Batch 190/244] avg loss 296.291, throughput 2.42719K wps\n",
      "[Epoch 39 Batch 200/244] avg loss 1205.08, throughput 2.47525K wps\n",
      "[Epoch 39 Batch 210/244] avg loss 363.542, throughput 2.89854K wps\n",
      "[Epoch 39 Batch 220/244] avg loss 283.218, throughput 3.1348K wps\n",
      "[Epoch 39 Batch 230/244] avg loss 358.462, throughput 2.65956K wps\n",
      "[Epoch 39 Batch 240/244] avg loss 532.435, throughput 2.64551K wps\n",
      "[Epoch 39] train avg loss 635.505, train avg r2 0.635838,throughput 2.86958K wps\n",
      "learning rate: 0.000125\n",
      "[Epoch 40 Batch 10/244] avg loss 1922.26, throughput 2.36967K wps\n",
      "[Epoch 40 Batch 20/244] avg loss 997.882, throughput 2.76245K wps\n",
      "[Epoch 40 Batch 30/244] avg loss 2008.73, throughput 2.91545K wps\n",
      "[Epoch 40 Batch 40/244] avg loss 2350.18, throughput 3.8314K wps\n",
      "[Epoch 40 Batch 50/244] avg loss 704.758, throughput 3.95258K wps\n",
      "[Epoch 40 Batch 60/244] avg loss 1757.54, throughput 2.57069K wps\n",
      "[Epoch 40 Batch 70/244] avg loss 666.063, throughput 3.21543K wps\n",
      "[Epoch 40 Batch 80/244] avg loss 349.524, throughput 3.64966K wps\n",
      "[Epoch 40 Batch 90/244] avg loss 1264.26, throughput 2.68096K wps\n",
      "[Epoch 40 Batch 100/244] avg loss 1469.27, throughput 3.63635K wps\n",
      "[Epoch 40 Batch 110/244] avg loss 770.656, throughput 2.77008K wps\n",
      "[Epoch 40 Batch 120/244] avg loss 302.793, throughput 3.03951K wps\n",
      "[Epoch 40 Batch 130/244] avg loss 250.072, throughput 3.24675K wps\n",
      "[Epoch 40 Batch 140/244] avg loss 715.498, throughput 2.88185K wps\n",
      "[Epoch 40 Batch 150/244] avg loss 1285.62, throughput 2.44498K wps\n",
      "[Epoch 40 Batch 160/244] avg loss 803.557, throughput 3.40136K wps\n",
      "[Epoch 40 Batch 170/244] avg loss 844.541, throughput 2.7933K wps\n",
      "[Epoch 40 Batch 180/244] avg loss 473.124, throughput 2.35294K wps\n",
      "[Epoch 40 Batch 190/244] avg loss 843.594, throughput 2.42719K wps\n",
      "[Epoch 40 Batch 200/244] avg loss 1412.37, throughput 2.46913K wps\n",
      "[Epoch 40 Batch 210/244] avg loss 867.605, throughput 2.89855K wps\n",
      "[Epoch 40 Batch 220/244] avg loss 684.545, throughput 3.11527K wps\n",
      "[Epoch 40 Batch 230/244] avg loss 504.717, throughput 2.65251K wps\n",
      "[Epoch 40 Batch 240/244] avg loss 545.937, throughput 2.65253K wps\n",
      "[Epoch 40] train avg loss 999.771, train avg r2 0.1589,throughput 2.86991K wps\n",
      "learning rate: 6.25e-05\n",
      "[Epoch 41 Batch 10/244] avg loss 1986.67, throughput 2.3753K wps\n",
      "[Epoch 41 Batch 20/244] avg loss 862.728, throughput 2.77008K wps\n",
      "[Epoch 41 Batch 30/244] avg loss 2035.95, throughput 2.92398K wps\n",
      "[Epoch 41 Batch 40/244] avg loss 833.929, throughput 3.83142K wps\n",
      "[Epoch 41 Batch 50/244] avg loss 1624.72, throughput 3.93703K wps\n",
      "[Epoch 41 Batch 60/244] avg loss 1470.08, throughput 2.55754K wps\n",
      "[Epoch 41 Batch 70/244] avg loss 1386.27, throughput 3.20513K wps\n",
      "[Epoch 41 Batch 80/244] avg loss 309.652, throughput 3.63638K wps\n",
      "[Epoch 41 Batch 90/244] avg loss 1408.17, throughput 2.68097K wps\n",
      "[Epoch 41 Batch 100/244] avg loss 1069.18, throughput 3.62318K wps\n",
      "[Epoch 41 Batch 110/244] avg loss 1444.39, throughput 2.77008K wps\n",
      "[Epoch 41 Batch 120/244] avg loss 346.862, throughput 3.04876K wps\n",
      "[Epoch 41 Batch 130/244] avg loss 324.447, throughput 3.24676K wps\n",
      "[Epoch 41 Batch 140/244] avg loss 488.191, throughput 2.88185K wps\n",
      "[Epoch 41 Batch 150/244] avg loss 1052.3, throughput 2.43903K wps\n",
      "[Epoch 41 Batch 160/244] avg loss 414.199, throughput 3.41297K wps\n",
      "[Epoch 41 Batch 170/244] avg loss 341.842, throughput 2.79329K wps\n",
      "[Epoch 41 Batch 180/244] avg loss 402.12, throughput 2.23214K wps\n",
      "[Epoch 41 Batch 190/244] avg loss 362.613, throughput 2.43309K wps\n",
      "[Epoch 41 Batch 200/244] avg loss 942.057, throughput 2.48138K wps\n",
      "[Epoch 41 Batch 210/244] avg loss 889.404, throughput 2.89017K wps\n",
      "[Epoch 41 Batch 220/244] avg loss 436.095, throughput 3.11527K wps\n",
      "[Epoch 41 Batch 230/244] avg loss 914.497, throughput 2.65957K wps\n",
      "[Epoch 41 Batch 240/244] avg loss 438.987, throughput 2.65252K wps\n",
      "[Epoch 41] train avg loss 915.656, train avg r2 0.375705,throughput 2.8615K wps\n",
      "learning rate: 6.25e-05\n",
      "[Epoch 42 Batch 10/244] avg loss 1575.07, throughput 2.36967K wps\n",
      "[Epoch 42 Batch 20/244] avg loss 888.628, throughput 2.77008K wps\n",
      "[Epoch 42 Batch 30/244] avg loss 1365.45, throughput 2.91543K wps\n",
      "[Epoch 42 Batch 40/244] avg loss 724.747, throughput 3.8168K wps\n",
      "[Epoch 42 Batch 50/244] avg loss 1964.53, throughput 3.937K wps\n",
      "[Epoch 42 Batch 60/244] avg loss 1525.9, throughput 2.5641K wps\n",
      "[Epoch 42 Batch 70/244] avg loss 1024.59, throughput 3.19487K wps\n",
      "[Epoch 42 Batch 80/244] avg loss 279.914, throughput 3.66301K wps\n",
      "[Epoch 42 Batch 90/244] avg loss 840.43, throughput 2.66667K wps\n",
      "[Epoch 42 Batch 100/244] avg loss 526.009, throughput 3.63635K wps\n",
      "[Epoch 42 Batch 110/244] avg loss 1878.54, throughput 2.77777K wps\n",
      "[Epoch 42 Batch 120/244] avg loss 400.819, throughput 3.04878K wps\n",
      "[Epoch 42 Batch 130/244] avg loss 559.813, throughput 3.26797K wps\n",
      "[Epoch 42 Batch 140/244] avg loss 502.613, throughput 2.89855K wps\n",
      "[Epoch 42 Batch 150/244] avg loss 923.97, throughput 2.445K wps\n",
      "[Epoch 42 Batch 160/244] avg loss 332.502, throughput 3.41296K wps\n",
      "[Epoch 42 Batch 170/244] avg loss 400.417, throughput 2.78551K wps\n",
      "[Epoch 42 Batch 180/244] avg loss 350.189, throughput 2.35294K wps\n",
      "[Epoch 42 Batch 190/244] avg loss 238.731, throughput 2.42719K wps\n",
      "[Epoch 42 Batch 200/244] avg loss 793.453, throughput 2.47525K wps\n",
      "[Epoch 42 Batch 210/244] avg loss 730.069, throughput 2.90699K wps\n",
      "[Epoch 42 Batch 220/244] avg loss 358.834, throughput 3.11527K wps\n",
      "[Epoch 42 Batch 230/244] avg loss 915.229, throughput 2.65252K wps\n",
      "[Epoch 42 Batch 240/244] avg loss 408.302, throughput 2.65251K wps\n",
      "[Epoch 42] train avg loss 823.721, train avg r2 0.507793,throughput 2.8689K wps\n",
      "learning rate: 6.25e-05\n",
      "[Epoch 43 Batch 10/244] avg loss 1498.32, throughput 2.36968K wps\n",
      "[Epoch 43 Batch 20/244] avg loss 837.529, throughput 2.77008K wps\n",
      "[Epoch 43 Batch 30/244] avg loss 912.374, throughput 2.91546K wps\n",
      "[Epoch 43 Batch 40/244] avg loss 820.53, throughput 3.84615K wps\n",
      "[Epoch 43 Batch 50/244] avg loss 1744.44, throughput 3.95254K wps\n",
      "[Epoch 43 Batch 60/244] avg loss 1353.46, throughput 2.57068K wps\n",
      "[Epoch 43 Batch 70/244] avg loss 663.341, throughput 3.20514K wps\n",
      "[Epoch 43 Batch 80/244] avg loss 283.381, throughput 3.66301K wps\n",
      "[Epoch 43 Batch 90/244] avg loss 500.966, throughput 2.67379K wps\n",
      "[Epoch 43 Batch 100/244] avg loss 415.547, throughput 3.63635K wps\n",
      "[Epoch 43 Batch 110/244] avg loss 1480.5, throughput 2.78551K wps\n",
      "[Epoch 43 Batch 120/244] avg loss 532.521, throughput 3.04878K wps\n",
      "[Epoch 43 Batch 130/244] avg loss 573.768, throughput 3.26794K wps\n",
      "[Epoch 43 Batch 140/244] avg loss 616.945, throughput 2.87358K wps\n",
      "[Epoch 43 Batch 150/244] avg loss 958.145, throughput 2.43903K wps\n",
      "[Epoch 43 Batch 160/244] avg loss 311.889, throughput 3.42465K wps\n",
      "[Epoch 43 Batch 170/244] avg loss 409.444, throughput 2.80113K wps\n",
      "[Epoch 43 Batch 180/244] avg loss 376.625, throughput 2.34192K wps\n",
      "[Epoch 43 Batch 190/244] avg loss 208.032, throughput 2.4331K wps\n",
      "[Epoch 43 Batch 200/244] avg loss 745.193, throughput 2.47523K wps\n",
      "[Epoch 43 Batch 210/244] avg loss 644.07, throughput 2.89856K wps\n",
      "[Epoch 43 Batch 220/244] avg loss 330.747, throughput 3.09599K wps\n",
      "[Epoch 43 Batch 230/244] avg loss 707.676, throughput 2.65957K wps\n",
      "[Epoch 43 Batch 240/244] avg loss 390.63, throughput 2.65252K wps\n",
      "[Epoch 43] train avg loss 731.388, train avg r2 0.569025,throughput 2.87059K wps\n",
      "learning rate: 6.25e-05\n",
      "[Epoch 44 Batch 10/244] avg loss 1470.72, throughput 2.37529K wps\n",
      "[Epoch 44 Batch 20/244] avg loss 744.071, throughput 2.77008K wps\n",
      "[Epoch 44 Batch 30/244] avg loss 646.881, throughput 2.91546K wps\n",
      "[Epoch 44 Batch 40/244] avg loss 938.332, throughput 3.84615K wps\n",
      "[Epoch 44 Batch 50/244] avg loss 1438.8, throughput 3.92159K wps\n",
      "[Epoch 44 Batch 60/244] avg loss 1317.6, throughput 2.5641K wps\n",
      "[Epoch 44 Batch 70/244] avg loss 565.133, throughput 3.20512K wps\n",
      "[Epoch 44 Batch 80/244] avg loss 281.873, throughput 3.66302K wps\n",
      "[Epoch 44 Batch 90/244] avg loss 341.525, throughput 2.68096K wps\n",
      "[Epoch 44 Batch 100/244] avg loss 384.466, throughput 3.62317K wps\n",
      "[Epoch 44 Batch 110/244] avg loss 978.335, throughput 2.77779K wps\n",
      "[Epoch 44 Batch 120/244] avg loss 518.911, throughput 3.04878K wps\n",
      "[Epoch 44 Batch 130/244] avg loss 451.103, throughput 3.25732K wps\n",
      "[Epoch 44 Batch 140/244] avg loss 757.602, throughput 2.87357K wps\n",
      "[Epoch 44 Batch 150/244] avg loss 1006.15, throughput 2.43308K wps\n",
      "[Epoch 44 Batch 160/244] avg loss 326.938, throughput 3.40136K wps\n",
      "[Epoch 44 Batch 170/244] avg loss 413.736, throughput 2.77778K wps\n",
      "[Epoch 44 Batch 180/244] avg loss 384.171, throughput 2.34741K wps\n",
      "[Epoch 44 Batch 190/244] avg loss 190.36, throughput 2.42719K wps\n",
      "[Epoch 44 Batch 200/244] avg loss 706.262, throughput 2.47525K wps\n",
      "[Epoch 44 Batch 210/244] avg loss 519.776, throughput 2.89854K wps\n",
      "[Epoch 44 Batch 220/244] avg loss 306.939, throughput 3.1056K wps\n",
      "[Epoch 44 Batch 230/244] avg loss 654.866, throughput 2.65957K wps\n",
      "[Epoch 44 Batch 240/244] avg loss 380.936, throughput 2.65252K wps\n",
      "[Epoch 44] train avg loss 663.834, train avg r2 0.615295,throughput 2.86856K wps\n",
      "learning rate: 6.25e-05\n",
      "[Epoch 45 Batch 10/244] avg loss 1384.38, throughput 2.36966K wps\n",
      "[Epoch 45 Batch 20/244] avg loss 765.756, throughput 2.77007K wps\n",
      "[Epoch 45 Batch 30/244] avg loss 521.799, throughput 2.91547K wps\n",
      "[Epoch 45 Batch 40/244] avg loss 1068.87, throughput 3.83142K wps\n",
      "[Epoch 45 Batch 50/244] avg loss 1115.09, throughput 3.92159K wps\n",
      "[Epoch 45 Batch 60/244] avg loss 1154.75, throughput 2.5641K wps\n",
      "[Epoch 45 Batch 70/244] avg loss 456.103, throughput 3.21542K wps\n",
      "[Epoch 45 Batch 80/244] avg loss 247.572, throughput 3.663K wps\n",
      "[Epoch 45 Batch 90/244] avg loss 321.716, throughput 2.68097K wps\n",
      "[Epoch 45 Batch 100/244] avg loss 431.04, throughput 3.6101K wps\n",
      "[Epoch 45 Batch 110/244] avg loss 772.233, throughput 2.77007K wps\n",
      "[Epoch 45 Batch 120/244] avg loss 387.146, throughput 3.04879K wps\n",
      "[Epoch 45 Batch 130/244] avg loss 378.993, throughput 3.25732K wps\n",
      "[Epoch 45 Batch 140/244] avg loss 785.734, throughput 2.89855K wps\n",
      "[Epoch 45 Batch 150/244] avg loss 1189.72, throughput 2.43903K wps\n",
      "[Epoch 45 Batch 160/244] avg loss 355.122, throughput 3.42464K wps\n",
      "[Epoch 45 Batch 170/244] avg loss 526.132, throughput 2.78552K wps\n",
      "[Epoch 45 Batch 180/244] avg loss 353.031, throughput 2.34192K wps\n",
      "[Epoch 45 Batch 190/244] avg loss 215.88, throughput 2.43309K wps\n",
      "[Epoch 45 Batch 200/244] avg loss 713.68, throughput 2.47524K wps\n",
      "[Epoch 45 Batch 210/244] avg loss 409.263, throughput 2.89855K wps\n",
      "[Epoch 45 Batch 220/244] avg loss 286.233, throughput 3.11527K wps\n",
      "[Epoch 45 Batch 230/244] avg loss 544.976, throughput 2.66665K wps\n",
      "[Epoch 45 Batch 240/244] avg loss 424.704, throughput 2.65252K wps\n",
      "[Epoch 45] train avg loss 625.299, train avg r2 0.629246,throughput 2.86958K wps\n",
      "learning rate: 6.25e-05\n",
      "[Epoch 46 Batch 10/244] avg loss 1321.79, throughput 2.36968K wps\n",
      "[Epoch 46 Batch 20/244] avg loss 796.499, throughput 2.77009K wps\n",
      "[Epoch 46 Batch 30/244] avg loss 422.619, throughput 2.92397K wps\n",
      "[Epoch 46 Batch 40/244] avg loss 922.623, throughput 3.83142K wps\n",
      "[Epoch 46 Batch 50/244] avg loss 748.321, throughput 3.93701K wps\n",
      "[Epoch 46 Batch 60/244] avg loss 1017.03, throughput 2.56411K wps\n",
      "[Epoch 46 Batch 70/244] avg loss 407.167, throughput 3.20512K wps\n",
      "[Epoch 46 Batch 80/244] avg loss 243.237, throughput 3.64964K wps\n",
      "[Epoch 46 Batch 90/244] avg loss 335.609, throughput 2.68816K wps\n",
      "[Epoch 46 Batch 100/244] avg loss 404.849, throughput 3.6364K wps\n",
      "[Epoch 46 Batch 110/244] avg loss 737.105, throughput 2.77777K wps\n",
      "[Epoch 46 Batch 120/244] avg loss 343.455, throughput 3.04878K wps\n",
      "[Epoch 46 Batch 130/244] avg loss 396.156, throughput 3.26797K wps\n",
      "[Epoch 46 Batch 140/244] avg loss 705.881, throughput 2.88184K wps\n",
      "[Epoch 46 Batch 150/244] avg loss 1299.01, throughput 2.44499K wps\n",
      "[Epoch 46 Batch 160/244] avg loss 375.366, throughput 3.42465K wps\n",
      "[Epoch 46 Batch 170/244] avg loss 577.483, throughput 2.79329K wps\n",
      "[Epoch 46 Batch 180/244] avg loss 408.068, throughput 2.35294K wps\n",
      "[Epoch 46 Batch 190/244] avg loss 227.032, throughput 2.42719K wps\n",
      "[Epoch 46 Batch 200/244] avg loss 727.018, throughput 2.46914K wps\n",
      "[Epoch 46 Batch 210/244] avg loss 338.351, throughput 2.90697K wps\n",
      "[Epoch 46 Batch 220/244] avg loss 300.528, throughput 3.10559K wps\n",
      "[Epoch 46 Batch 230/244] avg loss 516.544, throughput 2.65957K wps\n",
      "[Epoch 46 Batch 240/244] avg loss 406.296, throughput 2.65251K wps\n",
      "[Epoch 46] train avg loss 589.93, train avg r2 0.645392,throughput 2.87126K wps\n",
      "learning rate: 6.25e-05\n",
      "[Epoch 47 Batch 10/244] avg loss 1214.31, throughput 2.36966K wps\n",
      "[Epoch 47 Batch 20/244] avg loss 767.77, throughput 2.76244K wps\n",
      "[Epoch 47 Batch 30/244] avg loss 417.115, throughput 2.91544K wps\n",
      "[Epoch 47 Batch 40/244] avg loss 795.104, throughput 3.8314K wps\n",
      "[Epoch 47 Batch 50/244] avg loss 543.108, throughput 3.90626K wps\n",
      "[Epoch 47 Batch 60/244] avg loss 971.618, throughput 2.5707K wps\n",
      "[Epoch 47 Batch 70/244] avg loss 341.541, throughput 3.21544K wps\n",
      "[Epoch 47 Batch 80/244] avg loss 207.142, throughput 3.66301K wps\n",
      "[Epoch 47 Batch 90/244] avg loss 322.691, throughput 2.68097K wps\n",
      "[Epoch 47 Batch 100/244] avg loss 315.099, throughput 3.62318K wps\n",
      "[Epoch 47 Batch 110/244] avg loss 647.257, throughput 2.77008K wps\n",
      "[Epoch 47 Batch 120/244] avg loss 321.65, throughput 3.03028K wps\n",
      "[Epoch 47 Batch 130/244] avg loss 449.035, throughput 3.25731K wps\n",
      "[Epoch 47 Batch 140/244] avg loss 510.905, throughput 2.89018K wps\n",
      "[Epoch 47 Batch 150/244] avg loss 1343.27, throughput 2.43903K wps\n",
      "[Epoch 47 Batch 160/244] avg loss 355.85, throughput 3.42465K wps\n",
      "[Epoch 47 Batch 170/244] avg loss 614.669, throughput 2.7933K wps\n",
      "[Epoch 47 Batch 180/244] avg loss 455.647, throughput 2.34742K wps\n",
      "[Epoch 47 Batch 190/244] avg loss 225.289, throughput 2.42717K wps\n",
      "[Epoch 47 Batch 200/244] avg loss 780.953, throughput 2.48139K wps\n",
      "[Epoch 47 Batch 210/244] avg loss 334.593, throughput 2.90697K wps\n",
      "[Epoch 47 Batch 220/244] avg loss 297.222, throughput 3.11527K wps\n",
      "[Epoch 47 Batch 230/244] avg loss 474.292, throughput 2.65957K wps\n",
      "[Epoch 47 Batch 240/244] avg loss 407.219, throughput 2.65958K wps\n",
      "[Epoch 47] train avg loss 555.075, train avg r2 0.679244,throughput 2.86958K wps\n",
      "learning rate: 6.25e-05\n",
      "[Epoch 48 Batch 10/244] avg loss 1191.12, throughput 2.36967K wps\n",
      "[Epoch 48 Batch 20/244] avg loss 701.473, throughput 2.76243K wps\n",
      "[Epoch 48 Batch 30/244] avg loss 375.988, throughput 2.90697K wps\n",
      "[Epoch 48 Batch 40/244] avg loss 694.932, throughput 3.84616K wps\n",
      "[Epoch 48 Batch 50/244] avg loss 439.925, throughput 3.92157K wps\n",
      "[Epoch 48 Batch 60/244] avg loss 983.556, throughput 2.5641K wps\n",
      "[Epoch 48 Batch 70/244] avg loss 338.3, throughput 3.20513K wps\n",
      "[Epoch 48 Batch 80/244] avg loss 223.106, throughput 3.663K wps\n",
      "[Epoch 48 Batch 90/244] avg loss 298.514, throughput 2.68095K wps\n",
      "[Epoch 48 Batch 100/244] avg loss 286.167, throughput 3.62319K wps\n",
      "[Epoch 48 Batch 110/244] avg loss 586.001, throughput 2.77778K wps\n",
      "[Epoch 48 Batch 120/244] avg loss 296.608, throughput 3.03951K wps\n",
      "[Epoch 48 Batch 130/244] avg loss 476.708, throughput 3.26799K wps\n",
      "[Epoch 48 Batch 140/244] avg loss 426.206, throughput 2.88184K wps\n",
      "[Epoch 48 Batch 150/244] avg loss 1364.36, throughput 2.445K wps\n",
      "[Epoch 48 Batch 160/244] avg loss 342.851, throughput 3.41297K wps\n",
      "[Epoch 48 Batch 170/244] avg loss 625.388, throughput 2.7933K wps\n",
      "[Epoch 48 Batch 180/244] avg loss 501.006, throughput 2.34742K wps\n",
      "[Epoch 48 Batch 190/244] avg loss 216.051, throughput 2.43309K wps\n",
      "[Epoch 48 Batch 200/244] avg loss 849.633, throughput 2.47525K wps\n",
      "[Epoch 48 Batch 210/244] avg loss 350.539, throughput 2.89017K wps\n",
      "[Epoch 48 Batch 220/244] avg loss 268.506, throughput 3.11528K wps\n",
      "[Epoch 48 Batch 230/244] avg loss 489.332, throughput 2.65957K wps\n",
      "[Epoch 48 Batch 240/244] avg loss 411.934, throughput 2.66666K wps\n",
      "[Epoch 48] train avg loss 539.294, train avg r2 0.687372,throughput 2.87025K wps\n",
      "learning rate: 6.25e-05\n",
      "[Epoch 49 Batch 10/244] avg loss 1168.64, throughput 2.30415K wps\n",
      "[Epoch 49 Batch 20/244] avg loss 621.934, throughput 2.77009K wps\n",
      "[Epoch 49 Batch 30/244] avg loss 315.966, throughput 2.86533K wps\n",
      "[Epoch 49 Batch 40/244] avg loss 670.796, throughput 3.80229K wps\n",
      "[Epoch 49 Batch 50/244] avg loss 373.59, throughput 3.90626K wps\n",
      "[Epoch 49 Batch 60/244] avg loss 879.264, throughput 2.56411K wps\n",
      "[Epoch 49 Batch 70/244] avg loss 344.511, throughput 3.09596K wps\n",
      "[Epoch 49 Batch 80/244] avg loss 199.569, throughput 3.63636K wps\n",
      "[Epoch 49 Batch 90/244] avg loss 280.975, throughput 2.6455K wps\n",
      "[Epoch 49 Batch 100/244] avg loss 262.099, throughput 3.59712K wps\n",
      "[Epoch 49 Batch 110/244] avg loss 624.945, throughput 2.77009K wps\n",
      "[Epoch 49 Batch 120/244] avg loss 249.22, throughput 3.04878K wps\n",
      "[Epoch 49 Batch 130/244] avg loss 440.634, throughput 3.25733K wps\n",
      "[Epoch 49 Batch 140/244] avg loss 397.786, throughput 2.87356K wps\n",
      "[Epoch 49 Batch 150/244] avg loss 1306.98, throughput 2.43902K wps\n",
      "[Epoch 49 Batch 160/244] avg loss 286.496, throughput 3.42467K wps\n",
      "[Epoch 49 Batch 170/244] avg loss 537.517, throughput 2.80112K wps\n",
      "[Epoch 49 Batch 180/244] avg loss 538.818, throughput 2.33645K wps\n",
      "[Epoch 49 Batch 190/244] avg loss 222.915, throughput 2.42718K wps\n",
      "[Epoch 49 Batch 200/244] avg loss 761.69, throughput 2.46915K wps\n",
      "[Epoch 49 Batch 210/244] avg loss 323.94, throughput 2.89016K wps\n",
      "[Epoch 49 Batch 220/244] avg loss 250.268, throughput 3.11527K wps\n",
      "[Epoch 49 Batch 230/244] avg loss 441.603, throughput 2.65958K wps\n",
      "[Epoch 49 Batch 240/244] avg loss 405.615, throughput 2.65251K wps\n",
      "[Epoch 49] train avg loss 504.76, train avg r2 0.702207,throughput 2.8548K wps\n",
      "learning rate: 6.25e-05\n",
      "[Epoch 50 Batch 10/244] avg loss 1040.39, throughput 2.3753K wps\n",
      "[Epoch 50 Batch 20/244] avg loss 829.872, throughput 2.77009K wps\n",
      "[Epoch 50 Batch 30/244] avg loss 501.244, throughput 2.91544K wps\n",
      "[Epoch 50 Batch 40/244] avg loss 853.639, throughput 3.83142K wps\n",
      "[Epoch 50 Batch 50/244] avg loss 349.94, throughput 3.93703K wps\n",
      "[Epoch 50 Batch 60/244] avg loss 898.424, throughput 2.56409K wps\n",
      "[Epoch 50 Batch 70/244] avg loss 339.125, throughput 3.21542K wps\n",
      "[Epoch 50 Batch 80/244] avg loss 190.297, throughput 3.64964K wps\n",
      "[Epoch 50 Batch 90/244] avg loss 348.086, throughput 2.68097K wps\n",
      "[Epoch 50 Batch 100/244] avg loss 335.215, throughput 3.63636K wps\n",
      "[Epoch 50 Batch 110/244] avg loss 785.005, throughput 2.77007K wps\n",
      "[Epoch 50 Batch 120/244] avg loss 312.153, throughput 3.0488K wps\n",
      "[Epoch 50 Batch 130/244] avg loss 629.324, throughput 3.25733K wps\n",
      "[Epoch 50 Batch 140/244] avg loss 579.069, throughput 2.87356K wps\n",
      "[Epoch 50 Batch 150/244] avg loss 1350.86, throughput 2.43308K wps\n",
      "[Epoch 50 Batch 160/244] avg loss 722.09, throughput 3.42467K wps\n",
      "[Epoch 50 Batch 170/244] avg loss 431.668, throughput 2.7855K wps\n",
      "[Epoch 50 Batch 180/244] avg loss 1126.11, throughput 2.34192K wps\n",
      "[Epoch 50 Batch 190/244] avg loss 461.604, throughput 2.4331K wps\n",
      "[Epoch 50 Batch 200/244] avg loss 736.072, throughput 2.47525K wps\n",
      "[Epoch 50 Batch 210/244] avg loss 594.335, throughput 2.89855K wps\n",
      "[Epoch 50 Batch 220/244] avg loss 391.927, throughput 3.125K wps\n",
      "[Epoch 50 Batch 230/244] avg loss 364.513, throughput 2.65956K wps\n",
      "[Epoch 50 Batch 240/244] avg loss 437.047, throughput 2.65252K wps\n",
      "[Epoch 50] train avg loss 620.463, train avg r2 0.526205,throughput 2.86924K wps\n",
      "learning rate: 3.125e-05\n",
      "[Epoch 51 Batch 10/244] avg loss 954.526, throughput 2.36406K wps\n",
      "[Epoch 51 Batch 20/244] avg loss 613.251, throughput 2.7701K wps\n",
      "[Epoch 51 Batch 30/244] avg loss 506.891, throughput 2.92398K wps\n",
      "[Epoch 51 Batch 40/244] avg loss 474.084, throughput 3.84614K wps\n",
      "[Epoch 51 Batch 50/244] avg loss 433.298, throughput 3.93704K wps\n",
      "[Epoch 51 Batch 60/244] avg loss 1186.55, throughput 2.5641K wps\n",
      "[Epoch 51 Batch 70/244] avg loss 356.649, throughput 3.20511K wps\n",
      "[Epoch 51 Batch 80/244] avg loss 189.025, throughput 3.64962K wps\n",
      "[Epoch 51 Batch 90/244] avg loss 303.302, throughput 2.6738K wps\n",
      "[Epoch 51 Batch 100/244] avg loss 222.991, throughput 3.63636K wps\n",
      "[Epoch 51 Batch 110/244] avg loss 724.214, throughput 2.77009K wps\n",
      "[Epoch 51 Batch 120/244] avg loss 319.515, throughput 3.0395K wps\n",
      "[Epoch 51 Batch 130/244] avg loss 385.017, throughput 3.25732K wps\n",
      "[Epoch 51 Batch 140/244] avg loss 679.619, throughput 2.89018K wps\n",
      "[Epoch 51 Batch 150/244] avg loss 975.135, throughput 2.43308K wps\n",
      "[Epoch 51 Batch 160/244] avg loss 389.286, throughput 3.41297K wps\n",
      "[Epoch 51 Batch 170/244] avg loss 499.249, throughput 2.77778K wps\n",
      "[Epoch 51 Batch 180/244] avg loss 479.855, throughput 2.34192K wps\n",
      "[Epoch 51 Batch 190/244] avg loss 804.294, throughput 2.43309K wps\n",
      "[Epoch 51 Batch 200/244] avg loss 595.255, throughput 2.46914K wps\n",
      "[Epoch 51 Batch 210/244] avg loss 604.741, throughput 2.89853K wps\n",
      "[Epoch 51 Batch 220/244] avg loss 283.565, throughput 3.11527K wps\n",
      "[Epoch 51 Batch 230/244] avg loss 353.793, throughput 2.65957K wps\n",
      "[Epoch 51 Batch 240/244] avg loss 422.243, throughput 2.65957K wps\n",
      "[Epoch 51] train avg loss 542.401, train avg r2 0.658687,throughput 2.86823K wps\n",
      "learning rate: 3.125e-05\n",
      "[Epoch 52 Batch 10/244] avg loss 1083.13, throughput 2.36966K wps\n",
      "[Epoch 52 Batch 20/244] avg loss 594.555, throughput 2.77009K wps\n",
      "[Epoch 52 Batch 30/244] avg loss 506.173, throughput 2.91545K wps\n",
      "[Epoch 52 Batch 40/244] avg loss 432.101, throughput 3.80227K wps\n",
      "[Epoch 52 Batch 50/244] avg loss 428.416, throughput 3.92157K wps\n",
      "[Epoch 52 Batch 60/244] avg loss 1158.05, throughput 2.56411K wps\n",
      "[Epoch 52 Batch 70/244] avg loss 295.098, throughput 3.20512K wps\n",
      "[Epoch 52 Batch 80/244] avg loss 176.742, throughput 3.64965K wps\n",
      "[Epoch 52 Batch 90/244] avg loss 276.258, throughput 2.68817K wps\n",
      "[Epoch 52 Batch 100/244] avg loss 197.005, throughput 3.63634K wps\n",
      "[Epoch 52 Batch 110/244] avg loss 622.387, throughput 2.77008K wps\n",
      "[Epoch 52 Batch 120/244] avg loss 295.204, throughput 3.04878K wps\n",
      "[Epoch 52 Batch 130/244] avg loss 289.334, throughput 3.26798K wps\n",
      "[Epoch 52 Batch 140/244] avg loss 672.634, throughput 2.88183K wps\n",
      "[Epoch 52 Batch 150/244] avg loss 888.85, throughput 2.44499K wps\n",
      "[Epoch 52 Batch 160/244] avg loss 272.107, throughput 3.41295K wps\n",
      "[Epoch 52 Batch 170/244] avg loss 600.518, throughput 2.80112K wps\n",
      "[Epoch 52 Batch 180/244] avg loss 386.901, throughput 2.34742K wps\n",
      "[Epoch 52 Batch 190/244] avg loss 746.334, throughput 2.42718K wps\n",
      "[Epoch 52 Batch 200/244] avg loss 683.01, throughput 2.46913K wps\n",
      "[Epoch 52 Batch 210/244] avg loss 495.079, throughput 2.89856K wps\n",
      "[Epoch 52 Batch 220/244] avg loss 344.379, throughput 3.1056K wps\n",
      "[Epoch 52 Batch 230/244] avg loss 354.783, throughput 2.65253K wps\n",
      "[Epoch 52 Batch 240/244] avg loss 468.709, throughput 2.65956K wps\n",
      "[Epoch 52] train avg loss 526.28, train avg r2 0.705753,throughput 2.86958K wps\n",
      "learning rate: 3.125e-05\n",
      "[Epoch 53 Batch 10/244] avg loss 939.16, throughput 2.36406K wps\n",
      "[Epoch 53 Batch 20/244] avg loss 527.913, throughput 2.7701K wps\n",
      "[Epoch 53 Batch 30/244] avg loss 426.707, throughput 2.92397K wps\n",
      "[Epoch 53 Batch 40/244] avg loss 429.679, throughput 3.84615K wps\n",
      "[Epoch 53 Batch 50/244] avg loss 432.221, throughput 3.93702K wps\n",
      "[Epoch 53 Batch 60/244] avg loss 1149.73, throughput 2.5641K wps\n",
      "[Epoch 53 Batch 70/244] avg loss 313.495, throughput 3.21543K wps\n",
      "[Epoch 53 Batch 80/244] avg loss 164.778, throughput 3.64965K wps\n",
      "[Epoch 53 Batch 90/244] avg loss 290.639, throughput 2.66667K wps\n",
      "[Epoch 53 Batch 100/244] avg loss 186.742, throughput 3.61011K wps\n",
      "[Epoch 53 Batch 110/244] avg loss 620.503, throughput 2.73973K wps\n",
      "[Epoch 53 Batch 120/244] avg loss 230.745, throughput 2.96736K wps\n",
      "[Epoch 53 Batch 130/244] avg loss 239.95, throughput 3.15456K wps\n",
      "[Epoch 53 Batch 140/244] avg loss 592.812, throughput 2.84901K wps\n",
      "[Epoch 53 Batch 150/244] avg loss 862.425, throughput 2.43309K wps\n",
      "[Epoch 53 Batch 160/244] avg loss 268.919, throughput 3.41297K wps\n",
      "[Epoch 53 Batch 170/244] avg loss 605.224, throughput 2.7933K wps\n",
      "[Epoch 53 Batch 180/244] avg loss 337.463, throughput 2.34192K wps\n",
      "[Epoch 53 Batch 190/244] avg loss 561.166, throughput 2.40964K wps\n",
      "[Epoch 53 Batch 200/244] avg loss 734.776, throughput 2.46913K wps\n",
      "[Epoch 53 Batch 210/244] avg loss 435.496, throughput 2.89015K wps\n",
      "[Epoch 53 Batch 220/244] avg loss 338.842, throughput 3.11527K wps\n",
      "[Epoch 53 Batch 230/244] avg loss 489.005, throughput 2.62467K wps\n",
      "[Epoch 53 Batch 240/244] avg loss 480.819, throughput 2.60416K wps\n",
      "[Epoch 53] train avg loss 507.458, train avg r2 0.718216,throughput 2.8528K wps\n",
      "learning rate: 3.125e-05\n",
      "[Epoch 54 Batch 10/244] avg loss 937.058, throughput 2.36406K wps\n",
      "[Epoch 54 Batch 20/244] avg loss 546.077, throughput 2.74726K wps\n",
      "[Epoch 54 Batch 30/244] avg loss 345.535, throughput 2.89854K wps\n",
      "[Epoch 54 Batch 40/244] avg loss 447.887, throughput 3.81679K wps\n",
      "[Epoch 54 Batch 50/244] avg loss 378.401, throughput 3.93702K wps\n",
      "[Epoch 54 Batch 60/244] avg loss 1111.91, throughput 2.55102K wps\n",
      "[Epoch 54 Batch 70/244] avg loss 328.197, throughput 3.18471K wps\n",
      "[Epoch 54 Batch 80/244] avg loss 168.315, throughput 3.64965K wps\n",
      "[Epoch 54 Batch 90/244] avg loss 295.331, throughput 2.68096K wps\n",
      "[Epoch 54 Batch 100/244] avg loss 183.212, throughput 3.61012K wps\n",
      "[Epoch 54 Batch 110/244] avg loss 611.173, throughput 2.75481K wps\n",
      "[Epoch 54 Batch 120/244] avg loss 218.422, throughput 3.0303K wps\n",
      "[Epoch 54 Batch 130/244] avg loss 214.436, throughput 3.24676K wps\n",
      "[Epoch 54 Batch 140/244] avg loss 435.293, throughput 2.88184K wps\n",
      "[Epoch 54 Batch 150/244] avg loss 811.361, throughput 2.4331K wps\n",
      "[Epoch 54 Batch 160/244] avg loss 261.866, throughput 3.40136K wps\n",
      "[Epoch 54 Batch 170/244] avg loss 487.363, throughput 2.78552K wps\n",
      "[Epoch 54 Batch 180/244] avg loss 321.396, throughput 2.33645K wps\n",
      "[Epoch 54 Batch 190/244] avg loss 416.723, throughput 2.42131K wps\n",
      "[Epoch 54 Batch 200/244] avg loss 696.346, throughput 2.45701K wps\n",
      "[Epoch 54 Batch 210/244] avg loss 362.819, throughput 2.88183K wps\n",
      "[Epoch 54 Batch 220/244] avg loss 308.929, throughput 3.10559K wps\n",
      "[Epoch 54 Batch 230/244] avg loss 576.95, throughput 2.6455K wps\n",
      "[Epoch 54 Batch 240/244] avg loss 432.846, throughput 2.6455K wps\n",
      "[Epoch 54] train avg loss 475.839, train avg r2 0.742031,throughput 2.85949K wps\n",
      "learning rate: 3.125e-05\n",
      "[Epoch 55 Batch 10/244] avg loss 898.589, throughput 2.35849K wps\n",
      "[Epoch 55 Batch 20/244] avg loss 514.387, throughput 2.75483K wps\n",
      "[Epoch 55 Batch 30/244] avg loss 345.113, throughput 2.90697K wps\n",
      "[Epoch 55 Batch 40/244] avg loss 392.49, throughput 3.80227K wps\n",
      "[Epoch 55 Batch 50/244] avg loss 324.92, throughput 3.90626K wps\n",
      "[Epoch 55 Batch 60/244] avg loss 985.243, throughput 2.55102K wps\n",
      "[Epoch 55 Batch 70/244] avg loss 317.65, throughput 3.18471K wps\n",
      "[Epoch 55 Batch 80/244] avg loss 159.405, throughput 3.61012K wps\n",
      "[Epoch 55 Batch 90/244] avg loss 286.987, throughput 2.63157K wps\n",
      "[Epoch 55 Batch 100/244] avg loss 178.694, throughput 3.54609K wps\n",
      "[Epoch 55 Batch 110/244] avg loss 571.931, throughput 2.73973K wps\n",
      "[Epoch 55 Batch 120/244] avg loss 219.942, throughput 3.03952K wps\n",
      "[Epoch 55 Batch 130/244] avg loss 230.728, throughput 3.24675K wps\n",
      "[Epoch 55 Batch 140/244] avg loss 391.056, throughput 2.86532K wps\n",
      "[Epoch 55 Batch 150/244] avg loss 766.647, throughput 2.43903K wps\n",
      "[Epoch 55 Batch 160/244] avg loss 243.276, throughput 3.41295K wps\n",
      "[Epoch 55 Batch 170/244] avg loss 376.498, throughput 2.78551K wps\n",
      "[Epoch 55 Batch 180/244] avg loss 313.547, throughput 2.33644K wps\n",
      "[Epoch 55 Batch 190/244] avg loss 321.258, throughput 2.43309K wps\n",
      "[Epoch 55 Batch 200/244] avg loss 580.908, throughput 2.47525K wps\n",
      "[Epoch 55 Batch 210/244] avg loss 313.174, throughput 2.89016K wps\n",
      "[Epoch 55 Batch 220/244] avg loss 295.794, throughput 3.11528K wps\n",
      "[Epoch 55 Batch 230/244] avg loss 565.145, throughput 2.65956K wps\n",
      "[Epoch 55 Batch 240/244] avg loss 432.381, throughput 2.65956K wps\n",
      "[Epoch 55] train avg loss 438.34, train avg r2 0.764709,throughput 2.85614K wps\n",
      "learning rate: 3.125e-05\n",
      "[Epoch 56 Batch 10/244] avg loss 833.509, throughput 2.36966K wps\n",
      "[Epoch 56 Batch 20/244] avg loss 479.368, throughput 2.77008K wps\n",
      "[Epoch 56 Batch 30/244] avg loss 290.432, throughput 2.91546K wps\n",
      "[Epoch 56 Batch 40/244] avg loss 442.045, throughput 3.81679K wps\n",
      "[Epoch 56 Batch 50/244] avg loss 272.203, throughput 3.92156K wps\n",
      "[Epoch 56 Batch 60/244] avg loss 944.322, throughput 2.55103K wps\n",
      "[Epoch 56 Batch 70/244] avg loss 320.068, throughput 3.20512K wps\n",
      "[Epoch 56 Batch 80/244] avg loss 172.607, throughput 3.63637K wps\n",
      "[Epoch 56 Batch 90/244] avg loss 250.571, throughput 2.67379K wps\n",
      "[Epoch 56 Batch 100/244] avg loss 187.727, throughput 3.63634K wps\n",
      "[Epoch 56 Batch 110/244] avg loss 601.365, throughput 2.76243K wps\n",
      "[Epoch 56 Batch 120/244] avg loss 222.366, throughput 3.05811K wps\n",
      "[Epoch 56 Batch 130/244] avg loss 208.245, throughput 3.24674K wps\n",
      "[Epoch 56 Batch 140/244] avg loss 355.893, throughput 2.87356K wps\n",
      "[Epoch 56 Batch 150/244] avg loss 805.969, throughput 2.43902K wps\n",
      "[Epoch 56 Batch 160/244] avg loss 229.671, throughput 3.41298K wps\n",
      "[Epoch 56 Batch 170/244] avg loss 348.658, throughput 2.79329K wps\n",
      "[Epoch 56 Batch 180/244] avg loss 284.723, throughput 2.34742K wps\n",
      "[Epoch 56 Batch 190/244] avg loss 273.129, throughput 2.42718K wps\n",
      "[Epoch 56 Batch 200/244] avg loss 519.359, throughput 2.46914K wps\n",
      "[Epoch 56 Batch 210/244] avg loss 298.765, throughput 2.89854K wps\n",
      "[Epoch 56 Batch 220/244] avg loss 265.274, throughput 3.10559K wps\n",
      "[Epoch 56 Batch 230/244] avg loss 528.426, throughput 2.65958K wps\n",
      "[Epoch 56 Batch 240/244] avg loss 388.591, throughput 2.65956K wps\n",
      "[Epoch 56] train avg loss 415.366, train avg r2 0.774623,throughput 2.86654K wps\n",
      "learning rate: 3.125e-05\n",
      "[Epoch 57 Batch 10/244] avg loss 833.853, throughput 2.36966K wps\n",
      "[Epoch 57 Batch 20/244] avg loss 464.636, throughput 2.76244K wps\n",
      "[Epoch 57 Batch 30/244] avg loss 268.206, throughput 2.91544K wps\n",
      "[Epoch 57 Batch 40/244] avg loss 406.532, throughput 3.81676K wps\n",
      "[Epoch 57 Batch 50/244] avg loss 210.565, throughput 3.9216K wps\n",
      "[Epoch 57 Batch 60/244] avg loss 900.099, throughput 2.5641K wps\n",
      "[Epoch 57 Batch 70/244] avg loss 355.177, throughput 3.22581K wps\n",
      "[Epoch 57 Batch 80/244] avg loss 179.646, throughput 3.64964K wps\n",
      "[Epoch 57 Batch 90/244] avg loss 256.905, throughput 2.68097K wps\n",
      "[Epoch 57 Batch 100/244] avg loss 189.867, throughput 3.63634K wps\n",
      "[Epoch 57 Batch 110/244] avg loss 587.433, throughput 2.7701K wps\n",
      "[Epoch 57 Batch 120/244] avg loss 213.495, throughput 3.0581K wps\n",
      "[Epoch 57 Batch 130/244] avg loss 198.118, throughput 3.24675K wps\n",
      "[Epoch 57 Batch 140/244] avg loss 299.9, throughput 2.88184K wps\n",
      "[Epoch 57 Batch 150/244] avg loss 779.685, throughput 2.43903K wps\n",
      "[Epoch 57 Batch 160/244] avg loss 222.543, throughput 3.42462K wps\n",
      "[Epoch 57 Batch 170/244] avg loss 311.815, throughput 2.78553K wps\n",
      "[Epoch 57 Batch 180/244] avg loss 306.945, throughput 2.34192K wps\n",
      "[Epoch 57 Batch 190/244] avg loss 224.129, throughput 2.43309K wps\n",
      "[Epoch 57 Batch 200/244] avg loss 512.474, throughput 2.46914K wps\n",
      "[Epoch 57 Batch 210/244] avg loss 295.433, throughput 2.89854K wps\n",
      "[Epoch 57 Batch 220/244] avg loss 271.322, throughput 3.09597K wps\n",
      "[Epoch 57 Batch 230/244] avg loss 445.216, throughput 2.66667K wps\n",
      "[Epoch 57 Batch 240/244] avg loss 349.856, throughput 2.65956K wps\n",
      "[Epoch 57] train avg loss 394.082, train avg r2 0.786802,throughput 2.86856K wps\n",
      "learning rate: 3.125e-05\n",
      "[Epoch 58 Batch 10/244] avg loss 774.129, throughput 2.36966K wps\n",
      "[Epoch 58 Batch 20/244] avg loss 501.119, throughput 2.77009K wps\n",
      "[Epoch 58 Batch 30/244] avg loss 262.307, throughput 2.89855K wps\n",
      "[Epoch 58 Batch 40/244] avg loss 383.908, throughput 3.83141K wps\n",
      "[Epoch 58 Batch 50/244] avg loss 208.23, throughput 3.92155K wps\n",
      "[Epoch 58 Batch 60/244] avg loss 866.129, throughput 2.56412K wps\n",
      "[Epoch 58 Batch 70/244] avg loss 329.427, throughput 3.20511K wps\n",
      "[Epoch 58 Batch 80/244] avg loss 186.054, throughput 3.64964K wps\n",
      "[Epoch 58 Batch 90/244] avg loss 248.669, throughput 2.68097K wps\n",
      "[Epoch 58 Batch 100/244] avg loss 195.149, throughput 3.62319K wps\n",
      "[Epoch 58 Batch 110/244] avg loss 590.514, throughput 2.77007K wps\n",
      "[Epoch 58 Batch 120/244] avg loss 234.284, throughput 3.04879K wps\n",
      "[Epoch 58 Batch 130/244] avg loss 202.995, throughput 3.25733K wps\n",
      "[Epoch 58 Batch 140/244] avg loss 282.888, throughput 2.88185K wps\n",
      "[Epoch 58 Batch 150/244] avg loss 787.137, throughput 2.43309K wps\n",
      "[Epoch 58 Batch 160/244] avg loss 216.078, throughput 3.41296K wps\n",
      "[Epoch 58 Batch 170/244] avg loss 285.148, throughput 2.78552K wps\n",
      "[Epoch 58 Batch 180/244] avg loss 279.699, throughput 2.34741K wps\n",
      "[Epoch 58 Batch 190/244] avg loss 218.634, throughput 2.43308K wps\n",
      "[Epoch 58 Batch 200/244] avg loss 512.116, throughput 2.46914K wps\n",
      "[Epoch 58 Batch 210/244] avg loss 279.24, throughput 2.89854K wps\n",
      "[Epoch 58 Batch 220/244] avg loss 223.97, throughput 3.10561K wps\n",
      "[Epoch 58 Batch 230/244] avg loss 416.026, throughput 2.65957K wps\n",
      "[Epoch 58 Batch 240/244] avg loss 336.031, throughput 2.65252K wps\n",
      "[Epoch 58] train avg loss 382.062, train avg r2 0.789923,throughput 2.86688K wps\n",
      "learning rate: 3.125e-05\n",
      "[Epoch 59 Batch 10/244] avg loss 749.269, throughput 2.36406K wps\n",
      "[Epoch 59 Batch 20/244] avg loss 436.964, throughput 2.76244K wps\n",
      "[Epoch 59 Batch 30/244] avg loss 261.407, throughput 2.91544K wps\n",
      "[Epoch 59 Batch 40/244] avg loss 340.183, throughput 3.83139K wps\n",
      "[Epoch 59 Batch 50/244] avg loss 188.639, throughput 3.93702K wps\n",
      "[Epoch 59 Batch 60/244] avg loss 868.358, throughput 2.5641K wps\n",
      "[Epoch 59 Batch 70/244] avg loss 315.672, throughput 3.20513K wps\n",
      "[Epoch 59 Batch 80/244] avg loss 197.275, throughput 3.66301K wps\n",
      "[Epoch 59 Batch 90/244] avg loss 263.884, throughput 2.68096K wps\n",
      "[Epoch 59 Batch 100/244] avg loss 182.854, throughput 3.63632K wps\n",
      "[Epoch 59 Batch 110/244] avg loss 585.972, throughput 2.7778K wps\n",
      "[Epoch 59 Batch 120/244] avg loss 215.815, throughput 3.04878K wps\n",
      "[Epoch 59 Batch 130/244] avg loss 213.272, throughput 3.25734K wps\n",
      "[Epoch 59 Batch 140/244] avg loss 296.587, throughput 2.87356K wps\n",
      "[Epoch 59 Batch 150/244] avg loss 800.287, throughput 2.43903K wps\n",
      "[Epoch 59 Batch 160/244] avg loss 205.761, throughput 3.42467K wps\n",
      "[Epoch 59 Batch 170/244] avg loss 282.191, throughput 2.7933K wps\n",
      "[Epoch 59 Batch 180/244] avg loss 277.668, throughput 2.34192K wps\n",
      "[Epoch 59 Batch 190/244] avg loss 212.103, throughput 2.43902K wps\n",
      "[Epoch 59 Batch 200/244] avg loss 477.442, throughput 2.47525K wps\n",
      "[Epoch 59 Batch 210/244] avg loss 266.23, throughput 2.89855K wps\n",
      "[Epoch 59 Batch 220/244] avg loss 229.58, throughput 3.11528K wps\n",
      "[Epoch 59 Batch 230/244] avg loss 353.01, throughput 2.65252K wps\n",
      "[Epoch 59 Batch 240/244] avg loss 307.693, throughput 2.65251K wps\n",
      "[Epoch 59] train avg loss 368.676, train avg r2 0.796462,throughput 2.86924K wps\n",
      "learning rate: 3.125e-05\n",
      "[Epoch 60 Batch 10/244] avg loss 769.603, throughput 2.36967K wps\n",
      "[Epoch 60 Batch 20/244] avg loss 460.375, throughput 2.76243K wps\n",
      "[Epoch 60 Batch 30/244] avg loss 268.139, throughput 2.91545K wps\n",
      "[Epoch 60 Batch 40/244] avg loss 371.094, throughput 3.83141K wps\n",
      "[Epoch 60 Batch 50/244] avg loss 203.196, throughput 3.93701K wps\n",
      "[Epoch 60 Batch 60/244] avg loss 823.691, throughput 2.55754K wps\n",
      "[Epoch 60 Batch 70/244] avg loss 397.635, throughput 3.21544K wps\n",
      "[Epoch 60 Batch 80/244] avg loss 256.615, throughput 3.64964K wps\n",
      "[Epoch 60 Batch 90/244] avg loss 283.651, throughput 2.67381K wps\n",
      "[Epoch 60 Batch 100/244] avg loss 201.707, throughput 3.61011K wps\n",
      "[Epoch 60 Batch 110/244] avg loss 647.455, throughput 2.77007K wps\n",
      "[Epoch 60 Batch 120/244] avg loss 220.497, throughput 3.03952K wps\n",
      "[Epoch 60 Batch 130/244] avg loss 214.145, throughput 3.25732K wps\n",
      "[Epoch 60 Batch 140/244] avg loss 298.365, throughput 2.88184K wps\n",
      "[Epoch 60 Batch 150/244] avg loss 733.492, throughput 2.43902K wps\n",
      "[Epoch 60 Batch 160/244] avg loss 220.608, throughput 3.41296K wps\n",
      "[Epoch 60 Batch 170/244] avg loss 317.457, throughput 2.7855K wps\n",
      "[Epoch 60 Batch 180/244] avg loss 265.477, throughput 2.34743K wps\n",
      "[Epoch 60 Batch 190/244] avg loss 207.789, throughput 2.4331K wps\n",
      "[Epoch 60 Batch 200/244] avg loss 584.138, throughput 2.46913K wps\n",
      "[Epoch 60 Batch 210/244] avg loss 280.759, throughput 2.89855K wps\n",
      "[Epoch 60 Batch 220/244] avg loss 233.782, throughput 3.11528K wps\n",
      "[Epoch 60 Batch 230/244] avg loss 466.56, throughput 2.65957K wps\n",
      "[Epoch 60 Batch 240/244] avg loss 313.089, throughput 2.65957K wps\n",
      "[Epoch 60] train avg loss 388.134, train avg r2 0.760771,throughput 2.86823K wps\n",
      "learning rate: 1.5625e-05\n",
      "[Epoch 61 Batch 10/244] avg loss 758.383, throughput 2.36966K wps\n",
      "[Epoch 61 Batch 20/244] avg loss 472.573, throughput 2.7701K wps\n",
      "[Epoch 61 Batch 30/244] avg loss 269.447, throughput 2.91545K wps\n",
      "[Epoch 61 Batch 40/244] avg loss 349.755, throughput 3.81678K wps\n",
      "[Epoch 61 Batch 50/244] avg loss 214.858, throughput 3.95258K wps\n",
      "[Epoch 61 Batch 60/244] avg loss 823.798, throughput 2.5641K wps\n",
      "[Epoch 61 Batch 70/244] avg loss 327.524, throughput 3.20513K wps\n",
      "[Epoch 61 Batch 80/244] avg loss 279.667, throughput 3.663K wps\n",
      "[Epoch 61 Batch 90/244] avg loss 340.948, throughput 2.68097K wps\n",
      "[Epoch 61 Batch 100/244] avg loss 207.344, throughput 3.62319K wps\n",
      "[Epoch 61 Batch 110/244] avg loss 664.585, throughput 2.77008K wps\n",
      "[Epoch 61 Batch 120/244] avg loss 201.444, throughput 3.05812K wps\n",
      "[Epoch 61 Batch 130/244] avg loss 194.785, throughput 3.25731K wps\n",
      "[Epoch 61 Batch 140/244] avg loss 259.299, throughput 2.89017K wps\n",
      "[Epoch 61 Batch 150/244] avg loss 669.043, throughput 2.43903K wps\n",
      "[Epoch 61 Batch 160/244] avg loss 209.023, throughput 3.42464K wps\n",
      "[Epoch 61 Batch 170/244] avg loss 320.036, throughput 2.7933K wps\n",
      "[Epoch 61 Batch 180/244] avg loss 254.291, throughput 2.34741K wps\n",
      "[Epoch 61 Batch 190/244] avg loss 220.595, throughput 2.4331K wps\n",
      "[Epoch 61 Batch 200/244] avg loss 566.22, throughput 2.47524K wps\n",
      "[Epoch 61 Batch 210/244] avg loss 273.759, throughput 2.89854K wps\n",
      "[Epoch 61 Batch 220/244] avg loss 236.284, throughput 3.10559K wps\n",
      "[Epoch 61 Batch 230/244] avg loss 446.856, throughput 2.65251K wps\n",
      "[Epoch 61 Batch 240/244] avg loss 309.221, throughput 2.65251K wps\n",
      "[Epoch 61] train avg loss 379.524, train avg r2 0.772549,throughput 2.86991K wps\n",
      "learning rate: 1.5625e-05\n",
      "[Epoch 62 Batch 10/244] avg loss 716.005, throughput 2.36966K wps\n",
      "[Epoch 62 Batch 20/244] avg loss 426.828, throughput 2.77008K wps\n",
      "[Epoch 62 Batch 30/244] avg loss 258.464, throughput 2.91545K wps\n",
      "[Epoch 62 Batch 40/244] avg loss 331.591, throughput 3.83142K wps\n",
      "[Epoch 62 Batch 50/244] avg loss 209.465, throughput 3.93702K wps\n",
      "[Epoch 62 Batch 60/244] avg loss 834.839, throughput 2.56409K wps\n",
      "[Epoch 62 Batch 70/244] avg loss 297.459, throughput 3.20514K wps\n",
      "[Epoch 62 Batch 80/244] avg loss 257.865, throughput 3.64966K wps\n",
      "[Epoch 62 Batch 90/244] avg loss 380.912, throughput 2.67379K wps\n",
      "[Epoch 62 Batch 100/244] avg loss 204.547, throughput 3.61012K wps\n",
      "[Epoch 62 Batch 110/244] avg loss 623.879, throughput 2.76242K wps\n",
      "[Epoch 62 Batch 120/244] avg loss 209.773, throughput 3.03952K wps\n",
      "[Epoch 62 Batch 130/244] avg loss 197.785, throughput 3.25734K wps\n",
      "[Epoch 62 Batch 140/244] avg loss 261.705, throughput 2.88184K wps\n",
      "[Epoch 62 Batch 150/244] avg loss 700.764, throughput 2.43309K wps\n",
      "[Epoch 62 Batch 160/244] avg loss 224.957, throughput 3.41297K wps\n",
      "[Epoch 62 Batch 170/244] avg loss 305.494, throughput 2.7933K wps\n",
      "[Epoch 62 Batch 180/244] avg loss 270.221, throughput 2.34742K wps\n",
      "[Epoch 62 Batch 190/244] avg loss 188.688, throughput 2.43309K wps\n",
      "[Epoch 62 Batch 200/244] avg loss 522.279, throughput 2.47525K wps\n",
      "[Epoch 62 Batch 210/244] avg loss 269.204, throughput 2.89854K wps\n",
      "[Epoch 62 Batch 220/244] avg loss 210.505, throughput 3.12499K wps\n",
      "[Epoch 62 Batch 230/244] avg loss 443.754, throughput 2.65958K wps\n",
      "[Epoch 62 Batch 240/244] avg loss 317.667, throughput 2.65252K wps\n",
      "[Epoch 62] train avg loss 369.995, train avg r2 0.775835,throughput 2.86823K wps\n",
      "learning rate: 1.5625e-05\n",
      "[Epoch 63 Batch 10/244] avg loss 714.86, throughput 2.28834K wps\n",
      "[Epoch 63 Batch 20/244] avg loss 473.274, throughput 2.77777K wps\n",
      "[Epoch 63 Batch 30/244] avg loss 265.844, throughput 2.84899K wps\n",
      "[Epoch 63 Batch 40/244] avg loss 322.11, throughput 3.81681K wps\n",
      "[Epoch 63 Batch 50/244] avg loss 214.286, throughput 3.92157K wps\n",
      "[Epoch 63 Batch 60/244] avg loss 862.423, throughput 2.55755K wps\n",
      "[Epoch 63 Batch 70/244] avg loss 266.946, throughput 3.0768K wps\n",
      "[Epoch 63 Batch 80/244] avg loss 245.216, throughput 3.64965K wps\n",
      "[Epoch 63 Batch 90/244] avg loss 375.077, throughput 2.66665K wps\n",
      "[Epoch 63 Batch 100/244] avg loss 199.364, throughput 3.6232K wps\n",
      "[Epoch 63 Batch 110/244] avg loss 660.929, throughput 2.76243K wps\n",
      "[Epoch 63 Batch 120/244] avg loss 191.237, throughput 3.03031K wps\n",
      "[Epoch 63 Batch 130/244] avg loss 199.248, throughput 3.25731K wps\n",
      "[Epoch 63 Batch 140/244] avg loss 255.712, throughput 2.88185K wps\n",
      "[Epoch 63 Batch 150/244] avg loss 681.909, throughput 2.43308K wps\n",
      "[Epoch 63 Batch 160/244] avg loss 208.326, throughput 3.41297K wps\n",
      "[Epoch 63 Batch 170/244] avg loss 279.286, throughput 2.79329K wps\n",
      "[Epoch 63 Batch 180/244] avg loss 278.883, throughput 2.34191K wps\n",
      "[Epoch 63 Batch 190/244] avg loss 175.051, throughput 2.42719K wps\n",
      "[Epoch 63 Batch 200/244] avg loss 506.491, throughput 2.46913K wps\n",
      "[Epoch 63 Batch 210/244] avg loss 246.556, throughput 2.89017K wps\n",
      "[Epoch 63 Batch 220/244] avg loss 210.632, throughput 3.11527K wps\n",
      "[Epoch 63 Batch 230/244] avg loss 378.803, throughput 2.65957K wps\n",
      "[Epoch 63 Batch 240/244] avg loss 301.143, throughput 2.65252K wps\n",
      "[Epoch 63] train avg loss 363.271, train avg r2 0.784833,throughput 2.85313K wps\n",
      "learning rate: 1.5625e-05\n",
      "[Epoch 64 Batch 10/244] avg loss 677.563, throughput 2.36967K wps\n",
      "[Epoch 64 Batch 20/244] avg loss 469.608, throughput 2.76242K wps\n",
      "[Epoch 64 Batch 30/244] avg loss 232.396, throughput 2.91545K wps\n",
      "[Epoch 64 Batch 40/244] avg loss 299.891, throughput 3.81679K wps\n",
      "[Epoch 64 Batch 50/244] avg loss 212.774, throughput 3.92157K wps\n",
      "[Epoch 64 Batch 60/244] avg loss 853.386, throughput 2.56409K wps\n",
      "[Epoch 64 Batch 70/244] avg loss 276.416, throughput 3.20514K wps\n",
      "[Epoch 64 Batch 80/244] avg loss 218.594, throughput 3.64964K wps\n",
      "[Epoch 64 Batch 90/244] avg loss 398.454, throughput 2.68817K wps\n",
      "[Epoch 64 Batch 100/244] avg loss 187.44, throughput 3.64962K wps\n",
      "[Epoch 64 Batch 110/244] avg loss 632.912, throughput 2.76242K wps\n",
      "[Epoch 64 Batch 120/244] avg loss 184.122, throughput 3.04878K wps\n",
      "[Epoch 64 Batch 130/244] avg loss 183.908, throughput 3.25732K wps\n",
      "[Epoch 64 Batch 140/244] avg loss 257.013, throughput 2.87357K wps\n",
      "[Epoch 64 Batch 150/244] avg loss 650.266, throughput 2.43309K wps\n",
      "[Epoch 64 Batch 160/244] avg loss 215.256, throughput 3.42466K wps\n",
      "[Epoch 64 Batch 170/244] avg loss 295.193, throughput 2.80899K wps\n",
      "[Epoch 64 Batch 180/244] avg loss 241.286, throughput 2.34742K wps\n",
      "[Epoch 64 Batch 190/244] avg loss 209.581, throughput 2.43309K wps\n",
      "[Epoch 64 Batch 200/244] avg loss 501.301, throughput 2.47525K wps\n",
      "[Epoch 64 Batch 210/244] avg loss 269.986, throughput 2.90698K wps\n",
      "[Epoch 64 Batch 220/244] avg loss 206.04, throughput 3.11526K wps\n",
      "[Epoch 64 Batch 230/244] avg loss 360.277, throughput 2.65956K wps\n",
      "[Epoch 64 Batch 240/244] avg loss 279.727, throughput 2.65252K wps\n",
      "[Epoch 64] train avg loss 354.941, train avg r2 0.791447,throughput 2.86856K wps\n",
      "learning rate: 1.5625e-05\n",
      "[Epoch 65 Batch 10/244] avg loss 670.601, throughput 2.36966K wps\n",
      "[Epoch 65 Batch 20/244] avg loss 468.29, throughput 2.76244K wps\n",
      "[Epoch 65 Batch 30/244] avg loss 231.658, throughput 2.92397K wps\n",
      "[Epoch 65 Batch 40/244] avg loss 310.2, throughput 3.83141K wps\n",
      "[Epoch 65 Batch 50/244] avg loss 202.086, throughput 3.95256K wps\n",
      "[Epoch 65 Batch 60/244] avg loss 812.037, throughput 2.57069K wps\n",
      "[Epoch 65 Batch 70/244] avg loss 281.094, throughput 3.21543K wps\n",
      "[Epoch 65 Batch 80/244] avg loss 183.649, throughput 3.64964K wps\n",
      "[Epoch 65 Batch 90/244] avg loss 332.868, throughput 2.68097K wps\n",
      "[Epoch 65 Batch 100/244] avg loss 199.256, throughput 3.64959K wps\n",
      "[Epoch 65 Batch 110/244] avg loss 552.185, throughput 2.77008K wps\n",
      "[Epoch 65 Batch 120/244] avg loss 198.524, throughput 3.04876K wps\n",
      "[Epoch 65 Batch 130/244] avg loss 187.578, throughput 3.26799K wps\n",
      "[Epoch 65 Batch 140/244] avg loss 244.512, throughput 2.88184K wps\n",
      "[Epoch 65 Batch 150/244] avg loss 680.383, throughput 2.43903K wps\n",
      "[Epoch 65 Batch 160/244] avg loss 218.412, throughput 3.42462K wps\n",
      "[Epoch 65 Batch 170/244] avg loss 248.839, throughput 2.78553K wps\n",
      "[Epoch 65 Batch 180/244] avg loss 248.356, throughput 2.34742K wps\n",
      "[Epoch 65 Batch 190/244] avg loss 181.577, throughput 2.42718K wps\n",
      "[Epoch 65 Batch 200/244] avg loss 463.602, throughput 2.47525K wps\n",
      "[Epoch 65 Batch 210/244] avg loss 249.56, throughput 2.89016K wps\n",
      "[Epoch 65 Batch 220/244] avg loss 204.905, throughput 3.11527K wps\n",
      "[Epoch 65 Batch 230/244] avg loss 327.064, throughput 2.65958K wps\n",
      "[Epoch 65 Batch 240/244] avg loss 264.303, throughput 2.65252K wps\n",
      "[Epoch 65] train avg loss 339.97, train avg r2 0.795813,throughput 2.86924K wps\n",
      "learning rate: 1.5625e-05\n",
      "[Epoch 66 Batch 10/244] avg loss 651.939, throughput 2.36967K wps\n",
      "[Epoch 66 Batch 20/244] avg loss 403.651, throughput 2.77777K wps\n",
      "[Epoch 66 Batch 30/244] avg loss 248.457, throughput 2.92399K wps\n",
      "[Epoch 66 Batch 40/244] avg loss 297.761, throughput 3.84614K wps\n",
      "[Epoch 66 Batch 50/244] avg loss 194.049, throughput 3.93703K wps\n",
      "[Epoch 66 Batch 60/244] avg loss 812.637, throughput 2.55754K wps\n",
      "[Epoch 66 Batch 70/244] avg loss 275.174, throughput 3.20513K wps\n",
      "[Epoch 66 Batch 80/244] avg loss 185.951, throughput 3.66299K wps\n",
      "[Epoch 66 Batch 90/244] avg loss 301.519, throughput 2.67381K wps\n",
      "[Epoch 66 Batch 100/244] avg loss 193.877, throughput 3.62318K wps\n",
      "[Epoch 66 Batch 110/244] avg loss 523.229, throughput 2.77009K wps\n",
      "[Epoch 66 Batch 120/244] avg loss 207.702, throughput 3.05809K wps\n",
      "[Epoch 66 Batch 130/244] avg loss 188.038, throughput 3.26796K wps\n",
      "[Epoch 66 Batch 140/244] avg loss 274.756, throughput 2.88185K wps\n",
      "[Epoch 66 Batch 150/244] avg loss 651.077, throughput 2.43902K wps\n",
      "[Epoch 66 Batch 160/244] avg loss 209.743, throughput 3.40136K wps\n",
      "[Epoch 66 Batch 170/244] avg loss 255.443, throughput 2.80113K wps\n",
      "[Epoch 66 Batch 180/244] avg loss 248.134, throughput 2.35293K wps\n",
      "[Epoch 66 Batch 190/244] avg loss 169.424, throughput 2.43309K wps\n",
      "[Epoch 66 Batch 200/244] avg loss 479.724, throughput 2.47524K wps\n",
      "[Epoch 66 Batch 210/244] avg loss 252.626, throughput 2.89855K wps\n",
      "[Epoch 66 Batch 220/244] avg loss 208.073, throughput 3.11528K wps\n",
      "[Epoch 66 Batch 230/244] avg loss 284.359, throughput 2.65252K wps\n",
      "[Epoch 66 Batch 240/244] avg loss 287.167, throughput 2.65251K wps\n",
      "[Epoch 66] train avg loss 334.848, train avg r2 0.801322,throughput 2.86991K wps\n",
      "learning rate: 1.5625e-05\n",
      "[Epoch 67 Batch 10/244] avg loss 679.642, throughput 2.36966K wps\n",
      "[Epoch 67 Batch 20/244] avg loss 440.871, throughput 2.76243K wps\n",
      "[Epoch 67 Batch 30/244] avg loss 219.701, throughput 2.92398K wps\n",
      "[Epoch 67 Batch 40/244] avg loss 287.492, throughput 3.83142K wps\n",
      "[Epoch 67 Batch 50/244] avg loss 177.513, throughput 3.93701K wps\n",
      "[Epoch 67 Batch 60/244] avg loss 795.863, throughput 2.5641K wps\n",
      "[Epoch 67 Batch 70/244] avg loss 276.14, throughput 3.21542K wps\n",
      "[Epoch 67 Batch 80/244] avg loss 180.62, throughput 3.21543K wps\n",
      "[Epoch 67 Batch 90/244] avg loss 288.047, throughput 2.68097K wps\n",
      "[Epoch 67 Batch 100/244] avg loss 181.057, throughput 3.61012K wps\n",
      "[Epoch 67 Batch 110/244] avg loss 544.381, throughput 2.77007K wps\n",
      "[Epoch 67 Batch 120/244] avg loss 189.686, throughput 3.03952K wps\n",
      "[Epoch 67 Batch 130/244] avg loss 186.315, throughput 3.26797K wps\n",
      "[Epoch 67 Batch 140/244] avg loss 242.854, throughput 2.88185K wps\n",
      "[Epoch 67 Batch 150/244] avg loss 649.54, throughput 2.43902K wps\n",
      "[Epoch 67 Batch 160/244] avg loss 207.15, throughput 3.41296K wps\n",
      "[Epoch 67 Batch 170/244] avg loss 259.828, throughput 2.80112K wps\n",
      "[Epoch 67 Batch 180/244] avg loss 250.343, throughput 2.34192K wps\n",
      "[Epoch 67 Batch 190/244] avg loss 183.858, throughput 2.42719K wps\n",
      "[Epoch 67 Batch 200/244] avg loss 450.535, throughput 2.46914K wps\n",
      "[Epoch 67 Batch 210/244] avg loss 246.895, throughput 2.89852K wps\n",
      "[Epoch 67 Batch 220/244] avg loss 188.757, throughput 3.125K wps\n",
      "[Epoch 67 Batch 230/244] avg loss 265.759, throughput 2.65957K wps\n",
      "[Epoch 67 Batch 240/244] avg loss 288.588, throughput 2.65251K wps\n",
      "[Epoch 67] train avg loss 328.436, train avg r2 0.808131,throughput 2.8558K wps\n",
      "learning rate: 1.5625e-05\n",
      "[Epoch 68 Batch 10/244] avg loss 673.719, throughput 2.36406K wps\n",
      "[Epoch 68 Batch 20/244] avg loss 441.866, throughput 2.77779K wps\n",
      "[Epoch 68 Batch 30/244] avg loss 237.997, throughput 2.89854K wps\n",
      "[Epoch 68 Batch 40/244] avg loss 294.846, throughput 3.83142K wps\n",
      "[Epoch 68 Batch 50/244] avg loss 163.232, throughput 3.92158K wps\n",
      "[Epoch 68 Batch 60/244] avg loss 772.665, throughput 2.5641K wps\n",
      "[Epoch 68 Batch 70/244] avg loss 270.935, throughput 3.20511K wps\n",
      "[Epoch 68 Batch 80/244] avg loss 166.261, throughput 3.66302K wps\n",
      "[Epoch 68 Batch 90/244] avg loss 283.782, throughput 2.66668K wps\n",
      "[Epoch 68 Batch 100/244] avg loss 193.432, throughput 3.6496K wps\n",
      "[Epoch 68 Batch 110/244] avg loss 506.437, throughput 2.76244K wps\n",
      "[Epoch 68 Batch 120/244] avg loss 192.347, throughput 3.03951K wps\n",
      "[Epoch 68 Batch 130/244] avg loss 195.348, throughput 3.25732K wps\n",
      "[Epoch 68 Batch 140/244] avg loss 277.283, throughput 2.88185K wps\n",
      "[Epoch 68 Batch 150/244] avg loss 654.644, throughput 2.43902K wps\n",
      "[Epoch 68 Batch 160/244] avg loss 220.783, throughput 3.41297K wps\n",
      "[Epoch 68 Batch 170/244] avg loss 250.003, throughput 2.7933K wps\n",
      "[Epoch 68 Batch 180/244] avg loss 243.979, throughput 2.34192K wps\n",
      "[Epoch 68 Batch 190/244] avg loss 165.741, throughput 2.42718K wps\n",
      "[Epoch 68 Batch 200/244] avg loss 428.422, throughput 2.46913K wps\n",
      "[Epoch 68 Batch 210/244] avg loss 240.616, throughput 2.89019K wps\n",
      "[Epoch 68 Batch 220/244] avg loss 195.954, throughput 3.12501K wps\n",
      "[Epoch 68 Batch 230/244] avg loss 236.897, throughput 2.65957K wps\n",
      "[Epoch 68 Batch 240/244] avg loss 262.801, throughput 2.65252K wps\n",
      "[Epoch 68] train avg loss 324.237, train avg r2 0.810613,throughput 2.86755K wps\n",
      "learning rate: 1.5625e-05\n",
      "[Epoch 69 Batch 10/244] avg loss 648.526, throughput 2.36967K wps\n",
      "[Epoch 69 Batch 20/244] avg loss 430.954, throughput 2.76242K wps\n",
      "[Epoch 69 Batch 30/244] avg loss 244.094, throughput 2.91545K wps\n",
      "[Epoch 69 Batch 40/244] avg loss 301.204, throughput 3.83142K wps\n",
      "[Epoch 69 Batch 50/244] avg loss 178.603, throughput 3.90627K wps\n",
      "[Epoch 69 Batch 60/244] avg loss 769.72, throughput 2.5641K wps\n",
      "[Epoch 69 Batch 70/244] avg loss 253.915, throughput 3.20512K wps\n",
      "[Epoch 69 Batch 80/244] avg loss 157.118, throughput 3.663K wps\n",
      "[Epoch 69 Batch 90/244] avg loss 250.471, throughput 2.68817K wps\n",
      "[Epoch 69 Batch 100/244] avg loss 194.156, throughput 3.63634K wps\n",
      "[Epoch 69 Batch 110/244] avg loss 468.878, throughput 2.76245K wps\n",
      "[Epoch 69 Batch 120/244] avg loss 174.475, throughput 3.04877K wps\n",
      "[Epoch 69 Batch 130/244] avg loss 185.383, throughput 3.25735K wps\n",
      "[Epoch 69 Batch 140/244] avg loss 254.341, throughput 2.88183K wps\n",
      "[Epoch 69 Batch 150/244] avg loss 648.095, throughput 2.43902K wps\n",
      "[Epoch 69 Batch 160/244] avg loss 214.297, throughput 3.41298K wps\n",
      "[Epoch 69 Batch 170/244] avg loss 264.634, throughput 2.7933K wps\n",
      "[Epoch 69 Batch 180/244] avg loss 238.114, throughput 2.34192K wps\n",
      "[Epoch 69 Batch 190/244] avg loss 180.665, throughput 2.42718K wps\n",
      "[Epoch 69 Batch 200/244] avg loss 456.166, throughput 2.46914K wps\n",
      "[Epoch 69 Batch 210/244] avg loss 258.979, throughput 2.89017K wps\n",
      "[Epoch 69 Batch 220/244] avg loss 190.817, throughput 3.1056K wps\n",
      "[Epoch 69 Batch 230/244] avg loss 259.29, throughput 2.65251K wps\n",
      "[Epoch 69 Batch 240/244] avg loss 275.199, throughput 2.65252K wps\n",
      "[Epoch 69] train avg loss 321.323, train avg r2 0.809787,throughput 2.86721K wps\n",
      "learning rate: 1.5625e-05\n",
      "[Epoch 70 Batch 10/244] avg loss 685.412, throughput 2.35849K wps\n",
      "[Epoch 70 Batch 20/244] avg loss 399.186, throughput 2.77009K wps\n",
      "[Epoch 70 Batch 30/244] avg loss 222.672, throughput 2.90697K wps\n",
      "[Epoch 70 Batch 40/244] avg loss 292.794, throughput 3.83142K wps\n",
      "[Epoch 70 Batch 50/244] avg loss 171.583, throughput 3.93701K wps\n",
      "[Epoch 70 Batch 60/244] avg loss 776.158, throughput 2.57069K wps\n",
      "[Epoch 70 Batch 70/244] avg loss 258.403, throughput 3.21542K wps\n",
      "[Epoch 70 Batch 80/244] avg loss 138.936, throughput 3.63636K wps\n",
      "[Epoch 70 Batch 90/244] avg loss 233.737, throughput 2.6738K wps\n",
      "[Epoch 70 Batch 100/244] avg loss 190.731, throughput 3.61012K wps\n",
      "[Epoch 70 Batch 110/244] avg loss 494.689, throughput 2.77007K wps\n",
      "[Epoch 70 Batch 120/244] avg loss 182.153, throughput 3.04878K wps\n",
      "[Epoch 70 Batch 130/244] avg loss 184.532, throughput 3.25731K wps\n",
      "[Epoch 70 Batch 140/244] avg loss 235.467, throughput 2.87358K wps\n",
      "[Epoch 70 Batch 150/244] avg loss 628.512, throughput 2.43902K wps\n",
      "[Epoch 70 Batch 160/244] avg loss 197.601, throughput 3.42466K wps\n",
      "[Epoch 70 Batch 170/244] avg loss 244.53, throughput 2.7933K wps\n",
      "[Epoch 70 Batch 180/244] avg loss 226.606, throughput 2.34741K wps\n",
      "[Epoch 70 Batch 190/244] avg loss 176.885, throughput 2.43311K wps\n",
      "[Epoch 70 Batch 200/244] avg loss 497.129, throughput 2.46913K wps\n",
      "[Epoch 70 Batch 210/244] avg loss 252.339, throughput 2.89854K wps\n",
      "[Epoch 70 Batch 220/244] avg loss 193.374, throughput 3.08643K wps\n",
      "[Epoch 70 Batch 230/244] avg loss 253.745, throughput 2.65956K wps\n",
      "[Epoch 70 Batch 240/244] avg loss 272.465, throughput 2.65958K wps\n",
      "[Epoch 70] train avg loss 317.505, train avg r2 0.81447,throughput 2.86654K wps\n",
      "learning rate: 7.8125e-06\n",
      "[Epoch 71 Batch 10/244] avg loss 640.267, throughput 2.36967K wps\n",
      "[Epoch 71 Batch 20/244] avg loss 414.032, throughput 2.77008K wps\n",
      "[Epoch 71 Batch 30/244] avg loss 229.868, throughput 2.92397K wps\n",
      "[Epoch 71 Batch 40/244] avg loss 303.599, throughput 3.84616K wps\n",
      "[Epoch 71 Batch 50/244] avg loss 193.455, throughput 3.937K wps\n",
      "[Epoch 71 Batch 60/244] avg loss 746.389, throughput 2.55755K wps\n",
      "[Epoch 71 Batch 70/244] avg loss 261.325, throughput 3.19488K wps\n",
      "[Epoch 71 Batch 80/244] avg loss 148.045, throughput 3.64965K wps\n",
      "[Epoch 71 Batch 90/244] avg loss 250.466, throughput 2.68097K wps\n",
      "[Epoch 71 Batch 100/244] avg loss 204.262, throughput 3.62319K wps\n",
      "[Epoch 71 Batch 110/244] avg loss 499.127, throughput 2.77008K wps\n",
      "[Epoch 71 Batch 120/244] avg loss 174.101, throughput 3.0581K wps\n",
      "[Epoch 71 Batch 130/244] avg loss 178.637, throughput 3.25733K wps\n",
      "[Epoch 71 Batch 140/244] avg loss 255.582, throughput 2.89017K wps\n",
      "[Epoch 71 Batch 150/244] avg loss 663.301, throughput 2.43902K wps\n",
      "[Epoch 71 Batch 160/244] avg loss 232.298, throughput 3.42465K wps\n",
      "[Epoch 71 Batch 170/244] avg loss 263.889, throughput 2.7933K wps\n",
      "[Epoch 71 Batch 180/244] avg loss 254.42, throughput 2.34742K wps\n",
      "[Epoch 71 Batch 190/244] avg loss 167.716, throughput 2.43309K wps\n",
      "[Epoch 71 Batch 200/244] avg loss 443.519, throughput 2.47525K wps\n",
      "[Epoch 71 Batch 210/244] avg loss 223.254, throughput 2.88185K wps\n",
      "[Epoch 71 Batch 220/244] avg loss 187.089, throughput 3.09598K wps\n",
      "[Epoch 71 Batch 230/244] avg loss 247.175, throughput 2.65252K wps\n",
      "[Epoch 71 Batch 240/244] avg loss 283.313, throughput 2.65251K wps\n",
      "[Epoch 71] train avg loss 319.672, train avg r2 0.810779,throughput 2.86924K wps\n",
      "learning rate: 7.8125e-06\n",
      "[Epoch 72 Batch 10/244] avg loss 654.994, throughput 2.36966K wps\n",
      "[Epoch 72 Batch 20/244] avg loss 427.944, throughput 2.76244K wps\n",
      "[Epoch 72 Batch 30/244] avg loss 219.143, throughput 2.91544K wps\n",
      "[Epoch 72 Batch 40/244] avg loss 281.119, throughput 3.84615K wps\n",
      "[Epoch 72 Batch 50/244] avg loss 178.041, throughput 3.93702K wps\n",
      "[Epoch 72 Batch 60/244] avg loss 773.994, throughput 2.57069K wps\n",
      "[Epoch 72 Batch 70/244] avg loss 224.988, throughput 3.20512K wps\n",
      "[Epoch 72 Batch 80/244] avg loss 151.6, throughput 3.663K wps\n",
      "[Epoch 72 Batch 90/244] avg loss 228.763, throughput 2.66665K wps\n",
      "[Epoch 72 Batch 100/244] avg loss 190.962, throughput 3.62321K wps\n",
      "[Epoch 72 Batch 110/244] avg loss 505.183, throughput 2.77777K wps\n",
      "[Epoch 72 Batch 120/244] avg loss 195.899, throughput 3.03952K wps\n",
      "[Epoch 72 Batch 130/244] avg loss 173.958, throughput 3.23623K wps\n",
      "[Epoch 72 Batch 140/244] avg loss 269.144, throughput 2.89017K wps\n",
      "[Epoch 72 Batch 150/244] avg loss 639.248, throughput 2.43308K wps\n",
      "[Epoch 72 Batch 160/244] avg loss 209.102, throughput 3.41296K wps\n",
      "[Epoch 72 Batch 170/244] avg loss 251.955, throughput 2.78551K wps\n",
      "[Epoch 72 Batch 180/244] avg loss 239.54, throughput 2.34741K wps\n",
      "[Epoch 72 Batch 190/244] avg loss 172.673, throughput 2.43309K wps\n",
      "[Epoch 72 Batch 200/244] avg loss 433.102, throughput 2.47524K wps\n",
      "[Epoch 72 Batch 210/244] avg loss 222.476, throughput 2.90699K wps\n",
      "[Epoch 72 Batch 220/244] avg loss 174.31, throughput 3.10559K wps\n",
      "[Epoch 72 Batch 230/244] avg loss 263.941, throughput 2.65956K wps\n",
      "[Epoch 72 Batch 240/244] avg loss 286.523, throughput 2.65957K wps\n",
      "[Epoch 72] train avg loss 315.397, train avg r2 0.813141,throughput 2.86654K wps\n",
      "learning rate: 7.8125e-06\n",
      "[Epoch 73 Batch 10/244] avg loss 648.285, throughput 2.37529K wps\n",
      "[Epoch 73 Batch 20/244] avg loss 389.901, throughput 2.76242K wps\n",
      "[Epoch 73 Batch 30/244] avg loss 235.107, throughput 2.91545K wps\n",
      "[Epoch 73 Batch 40/244] avg loss 305.594, throughput 3.81679K wps\n",
      "[Epoch 73 Batch 50/244] avg loss 173.617, throughput 3.90627K wps\n",
      "[Epoch 73 Batch 60/244] avg loss 773.445, throughput 2.5641K wps\n",
      "[Epoch 73 Batch 70/244] avg loss 259.767, throughput 3.21543K wps\n",
      "[Epoch 73 Batch 80/244] avg loss 145.277, throughput 3.67646K wps\n",
      "[Epoch 73 Batch 90/244] avg loss 225.244, throughput 2.68817K wps\n",
      "[Epoch 73 Batch 100/244] avg loss 183.796, throughput 3.63635K wps\n",
      "[Epoch 73 Batch 110/244] avg loss 536.863, throughput 2.77006K wps\n",
      "[Epoch 73 Batch 120/244] avg loss 202.925, throughput 3.03954K wps\n",
      "[Epoch 73 Batch 130/244] avg loss 180.593, throughput 3.24675K wps\n",
      "[Epoch 73 Batch 140/244] avg loss 255.109, throughput 2.88184K wps\n",
      "[Epoch 73 Batch 150/244] avg loss 642.147, throughput 2.44498K wps\n",
      "[Epoch 73 Batch 160/244] avg loss 204.799, throughput 3.41298K wps\n",
      "[Epoch 73 Batch 170/244] avg loss 236.457, throughput 2.80112K wps\n",
      "[Epoch 73 Batch 180/244] avg loss 253.533, throughput 2.34741K wps\n",
      "[Epoch 73 Batch 190/244] avg loss 184.505, throughput 2.43309K wps\n",
      "[Epoch 73 Batch 200/244] avg loss 453.967, throughput 2.46914K wps\n",
      "[Epoch 73 Batch 210/244] avg loss 238.192, throughput 2.89855K wps\n",
      "[Epoch 73 Batch 220/244] avg loss 182.928, throughput 3.1056K wps\n",
      "[Epoch 73 Batch 230/244] avg loss 236.589, throughput 2.65957K wps\n",
      "[Epoch 73 Batch 240/244] avg loss 270.538, throughput 2.65252K wps\n",
      "[Epoch 73] train avg loss 317.786, train avg r2 0.807888,throughput 2.86924K wps\n",
      "learning rate: 7.8125e-06\n",
      "[Epoch 74 Batch 10/244] avg loss 653.008, throughput 2.36967K wps\n",
      "[Epoch 74 Batch 20/244] avg loss 433.56, throughput 2.77008K wps\n",
      "[Epoch 74 Batch 30/244] avg loss 230.626, throughput 2.92398K wps\n",
      "[Epoch 74 Batch 40/244] avg loss 294.042, throughput 3.83141K wps\n",
      "[Epoch 74 Batch 50/244] avg loss 186.373, throughput 3.90627K wps\n",
      "[Epoch 74 Batch 60/244] avg loss 772.006, throughput 2.5641K wps\n",
      "[Epoch 74 Batch 70/244] avg loss 267.011, throughput 3.20511K wps\n",
      "[Epoch 74 Batch 80/244] avg loss 141.837, throughput 3.64966K wps\n",
      "[Epoch 74 Batch 90/244] avg loss 226.562, throughput 2.68096K wps\n",
      "[Epoch 74 Batch 100/244] avg loss 191.119, throughput 3.63636K wps\n",
      "[Epoch 74 Batch 110/244] avg loss 485.197, throughput 2.76244K wps\n",
      "[Epoch 74 Batch 120/244] avg loss 176.024, throughput 3.03951K wps\n",
      "[Epoch 74 Batch 130/244] avg loss 182.967, throughput 3.25732K wps\n",
      "[Epoch 74 Batch 140/244] avg loss 241.376, throughput 2.88184K wps\n",
      "[Epoch 74 Batch 150/244] avg loss 660.335, throughput 2.43904K wps\n",
      "[Epoch 74 Batch 160/244] avg loss 217.716, throughput 3.42464K wps\n",
      "[Epoch 74 Batch 170/244] avg loss 264.638, throughput 2.80113K wps\n",
      "[Epoch 74 Batch 180/244] avg loss 231.451, throughput 2.34742K wps\n",
      "[Epoch 74 Batch 190/244] avg loss 188.208, throughput 2.43902K wps\n",
      "[Epoch 74 Batch 200/244] avg loss 419.603, throughput 2.46913K wps\n",
      "[Epoch 74 Batch 210/244] avg loss 230.325, throughput 2.89017K wps\n",
      "[Epoch 74 Batch 220/244] avg loss 187.071, throughput 3.12501K wps\n",
      "[Epoch 74 Batch 230/244] avg loss 227.995, throughput 2.65957K wps\n",
      "[Epoch 74 Batch 240/244] avg loss 269.39, throughput 2.65957K wps\n",
      "[Epoch 74] train avg loss 316.291, train avg r2 0.812756,throughput 2.86958K wps\n",
      "learning rate: 7.8125e-06\n",
      "[Epoch 75 Batch 10/244] avg loss 711.813, throughput 2.36967K wps\n",
      "[Epoch 75 Batch 20/244] avg loss 438.314, throughput 2.77007K wps\n",
      "[Epoch 75 Batch 30/244] avg loss 218.197, throughput 2.91545K wps\n",
      "[Epoch 75 Batch 40/244] avg loss 306.558, throughput 3.84615K wps\n",
      "[Epoch 75 Batch 50/244] avg loss 182.646, throughput 3.92157K wps\n",
      "[Epoch 75 Batch 60/244] avg loss 753.263, throughput 2.56411K wps\n",
      "[Epoch 75 Batch 70/244] avg loss 251.086, throughput 3.20511K wps\n",
      "[Epoch 75 Batch 80/244] avg loss 144.908, throughput 3.66302K wps\n",
      "[Epoch 75 Batch 90/244] avg loss 229.746, throughput 2.68096K wps\n",
      "[Epoch 75 Batch 100/244] avg loss 191.171, throughput 3.63637K wps\n",
      "[Epoch 75 Batch 110/244] avg loss 504.029, throughput 2.76244K wps\n",
      "[Epoch 75 Batch 120/244] avg loss 177.036, throughput 3.0581K wps\n",
      "[Epoch 75 Batch 130/244] avg loss 176.358, throughput 3.25732K wps\n",
      "[Epoch 75 Batch 140/244] avg loss 257.762, throughput 2.87356K wps\n",
      "[Epoch 75 Batch 150/244] avg loss 627.681, throughput 2.44498K wps\n",
      "[Epoch 75 Batch 160/244] avg loss 217.062, throughput 3.40137K wps\n",
      "[Epoch 75 Batch 170/244] avg loss 249.217, throughput 2.7933K wps\n",
      "[Epoch 75 Batch 180/244] avg loss 234.614, throughput 2.34741K wps\n",
      "[Epoch 75 Batch 190/244] avg loss 176.104, throughput 2.43903K wps\n",
      "[Epoch 75 Batch 200/244] avg loss 430.937, throughput 2.46913K wps\n",
      "[Epoch 75 Batch 210/244] avg loss 239.718, throughput 2.89018K wps\n",
      "[Epoch 75 Batch 220/244] avg loss 173.84, throughput 3.11528K wps\n",
      "[Epoch 75 Batch 230/244] avg loss 250.154, throughput 2.65956K wps\n",
      "[Epoch 75 Batch 240/244] avg loss 268.975, throughput 2.65253K wps\n",
      "[Epoch 75] train avg loss 318.339, train avg r2 0.812927,throughput 2.86991K wps\n",
      "learning rate: 7.8125e-06\n",
      "[Epoch 76 Batch 10/244] avg loss 666.658, throughput 2.37529K wps\n",
      "[Epoch 76 Batch 20/244] avg loss 420.954, throughput 2.77779K wps\n",
      "[Epoch 76 Batch 30/244] avg loss 217.366, throughput 2.90698K wps\n",
      "[Epoch 76 Batch 40/244] avg loss 305.47, throughput 3.8314K wps\n",
      "[Epoch 76 Batch 50/244] avg loss 178.381, throughput 3.93703K wps\n",
      "[Epoch 76 Batch 60/244] avg loss 747.115, throughput 2.56409K wps\n",
      "[Epoch 76 Batch 70/244] avg loss 256.201, throughput 3.19488K wps\n",
      "[Epoch 76 Batch 80/244] avg loss 144.072, throughput 3.64967K wps\n",
      "[Epoch 76 Batch 90/244] avg loss 226.69, throughput 2.68095K wps\n",
      "[Epoch 76 Batch 100/244] avg loss 190.036, throughput 3.63638K wps\n",
      "[Epoch 76 Batch 110/244] avg loss 434.866, throughput 2.76243K wps\n",
      "[Epoch 76 Batch 120/244] avg loss 181.657, throughput 3.0581K wps\n",
      "[Epoch 76 Batch 130/244] avg loss 194.607, throughput 3.24674K wps\n",
      "[Epoch 76 Batch 140/244] avg loss 227.923, throughput 2.88183K wps\n",
      "[Epoch 76 Batch 150/244] avg loss 647.681, throughput 2.43903K wps\n",
      "[Epoch 76 Batch 160/244] avg loss 203.921, throughput 3.40137K wps\n",
      "[Epoch 76 Batch 170/244] avg loss 239.43, throughput 2.7933K wps\n",
      "[Epoch 76 Batch 180/244] avg loss 237.717, throughput 2.35293K wps\n",
      "[Epoch 76 Batch 190/244] avg loss 175.147, throughput 2.43309K wps\n",
      "[Epoch 76 Batch 200/244] avg loss 405.719, throughput 2.46913K wps\n",
      "[Epoch 76 Batch 210/244] avg loss 223.944, throughput 2.90697K wps\n",
      "[Epoch 76 Batch 220/244] avg loss 178.607, throughput 3.10559K wps\n",
      "[Epoch 76 Batch 230/244] avg loss 226.569, throughput 2.65252K wps\n",
      "[Epoch 76 Batch 240/244] avg loss 263.319, throughput 2.66665K wps\n",
      "[Epoch 76] train avg loss 308.523, train avg r2 0.818822,throughput 2.86958K wps\n",
      "learning rate: 7.8125e-06\n",
      "[Epoch 77 Batch 10/244] avg loss 652.075, throughput 2.29358K wps\n",
      "[Epoch 77 Batch 20/244] avg loss 459.096, throughput 2.77007K wps\n",
      "[Epoch 77 Batch 30/244] avg loss 236.475, throughput 2.84092K wps\n",
      "[Epoch 77 Batch 40/244] avg loss 298.616, throughput 3.78788K wps\n",
      "[Epoch 77 Batch 50/244] avg loss 167.623, throughput 3.90627K wps\n",
      "[Epoch 77 Batch 60/244] avg loss 739.803, throughput 2.5641K wps\n",
      "[Epoch 77 Batch 70/244] avg loss 266.183, throughput 3.11525K wps\n",
      "[Epoch 77 Batch 80/244] avg loss 140.22, throughput 3.663K wps\n",
      "[Epoch 77 Batch 90/244] avg loss 216.093, throughput 2.68097K wps\n",
      "[Epoch 77 Batch 100/244] avg loss 183.839, throughput 3.61012K wps\n",
      "[Epoch 77 Batch 110/244] avg loss 519.486, throughput 2.77777K wps\n",
      "[Epoch 77 Batch 120/244] avg loss 176.469, throughput 3.05809K wps\n",
      "[Epoch 77 Batch 130/244] avg loss 190.956, throughput 3.21543K wps\n",
      "[Epoch 77 Batch 140/244] avg loss 256.049, throughput 2.83286K wps\n",
      "[Epoch 77 Batch 150/244] avg loss 611.768, throughput 2.42718K wps\n",
      "[Epoch 77 Batch 160/244] avg loss 206.461, throughput 3.40136K wps\n",
      "[Epoch 77 Batch 170/244] avg loss 243.224, throughput 2.80113K wps\n",
      "[Epoch 77 Batch 180/244] avg loss 225.267, throughput 2.34741K wps\n",
      "[Epoch 77 Batch 190/244] avg loss 176.648, throughput 2.42718K wps\n",
      "[Epoch 77 Batch 200/244] avg loss 403.154, throughput 2.48139K wps\n",
      "[Epoch 77 Batch 210/244] avg loss 224.486, throughput 2.89855K wps\n",
      "[Epoch 77 Batch 220/244] avg loss 175.757, throughput 3.10559K wps\n",
      "[Epoch 77 Batch 230/244] avg loss 229.329, throughput 2.65958K wps\n",
      "[Epoch 77 Batch 240/244] avg loss 250.213, throughput 2.65251K wps\n",
      "[Epoch 77] train avg loss 309.912, train avg r2 0.814063,throughput 2.85313K wps\n",
      "learning rate: 7.8125e-06\n",
      "[Epoch 78 Batch 10/244] avg loss 618.371, throughput 2.36407K wps\n",
      "[Epoch 78 Batch 20/244] avg loss 403.968, throughput 2.77778K wps\n",
      "[Epoch 78 Batch 30/244] avg loss 236.408, throughput 2.91545K wps\n",
      "[Epoch 78 Batch 40/244] avg loss 304.051, throughput 3.83143K wps\n",
      "[Epoch 78 Batch 50/244] avg loss 182.17, throughput 3.93701K wps\n",
      "[Epoch 78 Batch 60/244] avg loss 755.36, throughput 2.56411K wps\n",
      "[Epoch 78 Batch 70/244] avg loss 261.735, throughput 3.2051K wps\n",
      "[Epoch 78 Batch 80/244] avg loss 154.369, throughput 3.66305K wps\n",
      "[Epoch 78 Batch 90/244] avg loss 219.17, throughput 2.68096K wps\n",
      "[Epoch 78 Batch 100/244] avg loss 203.841, throughput 3.62316K wps\n",
      "[Epoch 78 Batch 110/244] avg loss 474.146, throughput 2.77009K wps\n",
      "[Epoch 78 Batch 120/244] avg loss 188.225, throughput 3.03951K wps\n",
      "[Epoch 78 Batch 130/244] avg loss 166.298, throughput 3.25733K wps\n",
      "[Epoch 78 Batch 140/244] avg loss 253.152, throughput 2.88184K wps\n",
      "[Epoch 78 Batch 150/244] avg loss 621.078, throughput 2.42719K wps\n",
      "[Epoch 78 Batch 160/244] avg loss 209.639, throughput 3.41295K wps\n",
      "[Epoch 78 Batch 170/244] avg loss 247.401, throughput 2.79329K wps\n",
      "[Epoch 78 Batch 180/244] avg loss 228.063, throughput 2.34192K wps\n",
      "[Epoch 78 Batch 190/244] avg loss 177.31, throughput 2.43309K wps\n",
      "[Epoch 78 Batch 200/244] avg loss 415.426, throughput 2.47525K wps\n",
      "[Epoch 78 Batch 210/244] avg loss 219.775, throughput 2.89017K wps\n",
      "[Epoch 78 Batch 220/244] avg loss 188.49, throughput 3.10558K wps\n",
      "[Epoch 78 Batch 230/244] avg loss 240.707, throughput 2.65253K wps\n",
      "[Epoch 78 Batch 240/244] avg loss 258.927, throughput 2.65252K wps\n",
      "[Epoch 78] train avg loss 309.043, train avg r2 0.815433,throughput 2.86789K wps\n",
      "learning rate: 7.8125e-06\n",
      "[Epoch 79 Batch 10/244] avg loss 659.76, throughput 2.36406K wps\n",
      "[Epoch 79 Batch 20/244] avg loss 399.658, throughput 2.77777K wps\n",
      "[Epoch 79 Batch 30/244] avg loss 228.868, throughput 2.91545K wps\n",
      "[Epoch 79 Batch 40/244] avg loss 285.126, throughput 3.80227K wps\n",
      "[Epoch 79 Batch 50/244] avg loss 173.998, throughput 3.90626K wps\n",
      "[Epoch 79 Batch 60/244] avg loss 740.751, throughput 2.5641K wps\n",
      "[Epoch 79 Batch 70/244] avg loss 254.921, throughput 3.20511K wps\n",
      "[Epoch 79 Batch 80/244] avg loss 157.882, throughput 3.66301K wps\n",
      "[Epoch 79 Batch 90/244] avg loss 232.919, throughput 2.6738K wps\n",
      "[Epoch 79 Batch 100/244] avg loss 189.54, throughput 3.63634K wps\n",
      "[Epoch 79 Batch 110/244] avg loss 492.444, throughput 2.77776K wps\n",
      "[Epoch 79 Batch 120/244] avg loss 161.17, throughput 3.04878K wps\n",
      "[Epoch 79 Batch 130/244] avg loss 171.451, throughput 3.26798K wps\n",
      "[Epoch 79 Batch 140/244] avg loss 236.65, throughput 2.88183K wps\n",
      "[Epoch 79 Batch 150/244] avg loss 652.206, throughput 2.42131K wps\n",
      "[Epoch 79 Batch 160/244] avg loss 203.803, throughput 3.40135K wps\n",
      "[Epoch 79 Batch 170/244] avg loss 228.005, throughput 2.78552K wps\n",
      "[Epoch 79 Batch 180/244] avg loss 218.43, throughput 2.34192K wps\n",
      "[Epoch 79 Batch 190/244] avg loss 186.888, throughput 2.42719K wps\n",
      "[Epoch 79 Batch 200/244] avg loss 385.133, throughput 2.46913K wps\n",
      "[Epoch 79 Batch 210/244] avg loss 220.117, throughput 2.89855K wps\n",
      "[Epoch 79 Batch 220/244] avg loss 171.79, throughput 3.11528K wps\n",
      "[Epoch 79 Batch 230/244] avg loss 225.675, throughput 2.65252K wps\n",
      "[Epoch 79 Batch 240/244] avg loss 237.881, throughput 2.65958K wps\n",
      "[Epoch 79] train avg loss 304.18, train avg r2 0.818634,throughput 2.86553K wps\n",
      "learning rate: 7.8125e-06\n",
      "[Epoch 80 Batch 10/244] avg loss 641.752, throughput 2.3753K wps\n",
      "[Epoch 80 Batch 20/244] avg loss 430.782, throughput 2.77008K wps\n",
      "[Epoch 80 Batch 30/244] avg loss 228.619, throughput 2.91544K wps\n",
      "[Epoch 80 Batch 40/244] avg loss 296.324, throughput 3.83144K wps\n",
      "[Epoch 80 Batch 50/244] avg loss 173.28, throughput 3.92157K wps\n",
      "[Epoch 80 Batch 60/244] avg loss 746.438, throughput 2.5641K wps\n",
      "[Epoch 80 Batch 70/244] avg loss 256.893, throughput 3.20512K wps\n",
      "[Epoch 80 Batch 80/244] avg loss 148.289, throughput 3.66301K wps\n",
      "[Epoch 80 Batch 90/244] avg loss 219.97, throughput 2.6738K wps\n",
      "[Epoch 80 Batch 100/244] avg loss 165.909, throughput 3.63637K wps\n",
      "[Epoch 80 Batch 110/244] avg loss 500.772, throughput 2.77008K wps\n",
      "[Epoch 80 Batch 120/244] avg loss 198.811, throughput 3.04878K wps\n",
      "[Epoch 80 Batch 130/244] avg loss 181.29, throughput 3.25733K wps\n",
      "[Epoch 80 Batch 140/244] avg loss 246.958, throughput 2.87357K wps\n",
      "[Epoch 80 Batch 150/244] avg loss 620.839, throughput 2.43902K wps\n",
      "[Epoch 80 Batch 160/244] avg loss 215.643, throughput 3.42464K wps\n",
      "[Epoch 80 Batch 170/244] avg loss 254.439, throughput 2.80112K wps\n",
      "[Epoch 80 Batch 180/244] avg loss 217.897, throughput 2.35294K wps\n",
      "[Epoch 80 Batch 190/244] avg loss 179.195, throughput 2.43309K wps\n",
      "[Epoch 80 Batch 200/244] avg loss 405.78, throughput 2.48139K wps\n",
      "[Epoch 80 Batch 210/244] avg loss 235.735, throughput 2.89016K wps\n",
      "[Epoch 80 Batch 220/244] avg loss 185.09, throughput 3.11526K wps\n",
      "[Epoch 80 Batch 230/244] avg loss 222.835, throughput 2.66666K wps\n",
      "[Epoch 80 Batch 240/244] avg loss 265.847, throughput 2.65252K wps\n",
      "[Epoch 80] train avg loss 309.647, train avg r2 0.816038,throughput 2.87025K wps\n",
      "learning rate: 3.90625e-06\n",
      "[Epoch 81 Batch 10/244] avg loss 644.407, throughput 2.36406K wps\n",
      "[Epoch 81 Batch 20/244] avg loss 395.096, throughput 2.76243K wps\n",
      "[Epoch 81 Batch 30/244] avg loss 236.15, throughput 2.91546K wps\n",
      "[Epoch 81 Batch 40/244] avg loss 275.655, throughput 3.84618K wps\n",
      "[Epoch 81 Batch 50/244] avg loss 175.022, throughput 3.937K wps\n",
      "[Epoch 81 Batch 60/244] avg loss 748.196, throughput 2.55755K wps\n",
      "[Epoch 81 Batch 70/244] avg loss 254.617, throughput 3.21543K wps\n",
      "[Epoch 81 Batch 80/244] avg loss 147.626, throughput 3.663K wps\n",
      "[Epoch 81 Batch 90/244] avg loss 226.532, throughput 2.68817K wps\n",
      "[Epoch 81 Batch 100/244] avg loss 185.966, throughput 3.62319K wps\n",
      "[Epoch 81 Batch 110/244] avg loss 522.892, throughput 2.78551K wps\n",
      "[Epoch 81 Batch 120/244] avg loss 193.602, throughput 3.0581K wps\n",
      "[Epoch 81 Batch 130/244] avg loss 193.41, throughput 3.24675K wps\n",
      "[Epoch 81 Batch 140/244] avg loss 225.82, throughput 2.89018K wps\n",
      "[Epoch 81 Batch 150/244] avg loss 581.919, throughput 2.44499K wps\n",
      "[Epoch 81 Batch 160/244] avg loss 220.575, throughput 3.42466K wps\n",
      "[Epoch 81 Batch 170/244] avg loss 239.369, throughput 2.80112K wps\n",
      "[Epoch 81 Batch 180/244] avg loss 229.893, throughput 2.35294K wps\n",
      "[Epoch 81 Batch 190/244] avg loss 167.102, throughput 2.43903K wps\n",
      "[Epoch 81 Batch 200/244] avg loss 399.001, throughput 2.48139K wps\n",
      "[Epoch 81 Batch 210/244] avg loss 237.426, throughput 2.90697K wps\n",
      "[Epoch 81 Batch 220/244] avg loss 173.996, throughput 3.125K wps\n",
      "[Epoch 81 Batch 230/244] avg loss 216.977, throughput 2.65253K wps\n",
      "[Epoch 81 Batch 240/244] avg loss 263.221, throughput 2.65957K wps\n",
      "[Epoch 81] train avg loss 306.607, train avg r2 0.817114,throughput 2.87194K wps\n",
      "learning rate: 3.90625e-06\n",
      "[Epoch 82 Batch 10/244] avg loss 649.213, throughput 2.36967K wps\n",
      "[Epoch 82 Batch 20/244] avg loss 404.063, throughput 2.77008K wps\n",
      "[Epoch 82 Batch 30/244] avg loss 240.665, throughput 2.91545K wps\n",
      "[Epoch 82 Batch 40/244] avg loss 284.271, throughput 3.84614K wps\n",
      "[Epoch 82 Batch 50/244] avg loss 166.68, throughput 3.937K wps\n",
      "[Epoch 82 Batch 60/244] avg loss 782.175, throughput 2.57069K wps\n",
      "[Epoch 82 Batch 70/244] avg loss 270.861, throughput 3.20512K wps\n",
      "[Epoch 82 Batch 80/244] avg loss 137.747, throughput 3.64964K wps\n",
      "[Epoch 82 Batch 90/244] avg loss 228.808, throughput 2.68097K wps\n",
      "[Epoch 82 Batch 100/244] avg loss 177.129, throughput 3.62318K wps\n",
      "[Epoch 82 Batch 110/244] avg loss 466.525, throughput 2.77009K wps\n",
      "[Epoch 82 Batch 120/244] avg loss 200.647, throughput 3.03952K wps\n",
      "[Epoch 82 Batch 130/244] avg loss 184.697, throughput 3.25732K wps\n",
      "[Epoch 82 Batch 140/244] avg loss 231.22, throughput 2.88185K wps\n",
      "[Epoch 82 Batch 150/244] avg loss 615.458, throughput 2.43309K wps\n",
      "[Epoch 82 Batch 160/244] avg loss 204.649, throughput 3.42465K wps\n",
      "[Epoch 82 Batch 170/244] avg loss 249.594, throughput 2.79329K wps\n",
      "[Epoch 82 Batch 180/244] avg loss 230.561, throughput 2.34741K wps\n",
      "[Epoch 82 Batch 190/244] avg loss 159.068, throughput 2.43309K wps\n",
      "[Epoch 82 Batch 200/244] avg loss 397.394, throughput 2.47525K wps\n",
      "[Epoch 82 Batch 210/244] avg loss 222.488, throughput 2.90696K wps\n",
      "[Epoch 82 Batch 220/244] avg loss 169.98, throughput 3.125K wps\n",
      "[Epoch 82 Batch 230/244] avg loss 219.591, throughput 2.66666K wps\n",
      "[Epoch 82 Batch 240/244] avg loss 258.7, throughput 2.65252K wps\n",
      "[Epoch 82] train avg loss 306.535, train avg r2 0.818949,throughput 2.87025K wps\n",
      "learning rate: 3.90625e-06\n",
      "[Epoch 83 Batch 10/244] avg loss 650.573, throughput 2.36967K wps\n",
      "[Epoch 83 Batch 20/244] avg loss 417.555, throughput 2.76242K wps\n",
      "[Epoch 83 Batch 30/244] avg loss 221.423, throughput 2.91547K wps\n",
      "[Epoch 83 Batch 40/244] avg loss 302.936, throughput 3.83142K wps\n",
      "[Epoch 83 Batch 50/244] avg loss 160.2, throughput 3.93703K wps\n",
      "[Epoch 83 Batch 60/244] avg loss 748.804, throughput 2.5641K wps\n",
      "[Epoch 83 Batch 70/244] avg loss 258.08, throughput 3.19488K wps\n",
      "[Epoch 83 Batch 80/244] avg loss 132.89, throughput 3.663K wps\n",
      "[Epoch 83 Batch 90/244] avg loss 230.768, throughput 2.68097K wps\n",
      "[Epoch 83 Batch 100/244] avg loss 198.596, throughput 3.63637K wps\n",
      "[Epoch 83 Batch 110/244] avg loss 481.59, throughput 2.76243K wps\n",
      "[Epoch 83 Batch 120/244] avg loss 186.013, throughput 3.04879K wps\n",
      "[Epoch 83 Batch 130/244] avg loss 195.321, throughput 3.24673K wps\n",
      "[Epoch 83 Batch 140/244] avg loss 252.52, throughput 2.88185K wps\n",
      "[Epoch 83 Batch 150/244] avg loss 585.515, throughput 2.43902K wps\n",
      "[Epoch 83 Batch 160/244] avg loss 195.332, throughput 3.41296K wps\n",
      "[Epoch 83 Batch 170/244] avg loss 261.862, throughput 2.79329K wps\n",
      "[Epoch 83 Batch 180/244] avg loss 250.248, throughput 2.34741K wps\n",
      "[Epoch 83 Batch 190/244] avg loss 170.369, throughput 2.43311K wps\n",
      "[Epoch 83 Batch 200/244] avg loss 383.452, throughput 2.47525K wps\n",
      "[Epoch 83 Batch 210/244] avg loss 220.679, throughput 2.90697K wps\n",
      "[Epoch 83 Batch 220/244] avg loss 193.469, throughput 3.125K wps\n",
      "[Epoch 83 Batch 230/244] avg loss 239.88, throughput 2.65253K wps\n",
      "[Epoch 83 Batch 240/244] avg loss 252.056, throughput 2.65251K wps\n",
      "[Epoch 83] train avg loss 307.826, train avg r2 0.816278,throughput 2.86823K wps\n",
      "learning rate: 3.90625e-06\n",
      "[Epoch 84 Batch 10/244] avg loss 669.172, throughput 2.36967K wps\n",
      "[Epoch 84 Batch 20/244] avg loss 417.159, throughput 2.76241K wps\n",
      "[Epoch 84 Batch 30/244] avg loss 221.048, throughput 2.90699K wps\n",
      "[Epoch 84 Batch 40/244] avg loss 299.087, throughput 3.83142K wps\n",
      "[Epoch 84 Batch 50/244] avg loss 168.175, throughput 3.90625K wps\n",
      "[Epoch 84 Batch 60/244] avg loss 732.588, throughput 2.56411K wps\n",
      "[Epoch 84 Batch 70/244] avg loss 250.604, throughput 3.20511K wps\n",
      "[Epoch 84 Batch 80/244] avg loss 146.169, throughput 3.64965K wps\n",
      "[Epoch 84 Batch 90/244] avg loss 231.043, throughput 2.66667K wps\n",
      "[Epoch 84 Batch 100/244] avg loss 186.42, throughput 3.63637K wps\n",
      "[Epoch 84 Batch 110/244] avg loss 473.069, throughput 2.77007K wps\n",
      "[Epoch 84 Batch 120/244] avg loss 192.376, throughput 3.04878K wps\n",
      "[Epoch 84 Batch 130/244] avg loss 184.18, throughput 3.25733K wps\n",
      "[Epoch 84 Batch 140/244] avg loss 227.198, throughput 2.88185K wps\n",
      "[Epoch 84 Batch 150/244] avg loss 572.328, throughput 2.43309K wps\n",
      "[Epoch 84 Batch 160/244] avg loss 216.434, throughput 3.41295K wps\n",
      "[Epoch 84 Batch 170/244] avg loss 252.399, throughput 2.79331K wps\n",
      "[Epoch 84 Batch 180/244] avg loss 219.95, throughput 2.34741K wps\n",
      "[Epoch 84 Batch 190/244] avg loss 164.002, throughput 2.43308K wps\n",
      "[Epoch 84 Batch 200/244] avg loss 385.519, throughput 2.46913K wps\n",
      "[Epoch 84 Batch 210/244] avg loss 210.753, throughput 2.89856K wps\n",
      "[Epoch 84 Batch 220/244] avg loss 177.592, throughput 3.11527K wps\n",
      "[Epoch 84 Batch 230/244] avg loss 226.137, throughput 2.65252K wps\n",
      "[Epoch 84 Batch 240/244] avg loss 246.388, throughput 2.65956K wps\n",
      "[Epoch 84] train avg loss 302.816, train avg r2 0.81742,throughput 2.86721K wps\n",
      "learning rate: 3.90625e-06\n",
      "[Epoch 85 Batch 10/244] avg loss 663.953, throughput 2.37529K wps\n",
      "[Epoch 85 Batch 20/244] avg loss 392.008, throughput 2.77008K wps\n",
      "[Epoch 85 Batch 30/244] avg loss 226.424, throughput 2.90696K wps\n",
      "[Epoch 85 Batch 40/244] avg loss 304.202, throughput 3.84615K wps\n",
      "[Epoch 85 Batch 50/244] avg loss 164.003, throughput 3.93701K wps\n",
      "[Epoch 85 Batch 60/244] avg loss 726.374, throughput 2.55755K wps\n",
      "[Epoch 85 Batch 70/244] avg loss 262.954, throughput 3.20512K wps\n",
      "[Epoch 85 Batch 80/244] avg loss 145.893, throughput 3.64964K wps\n",
      "[Epoch 85 Batch 90/244] avg loss 201.922, throughput 2.68818K wps\n",
      "[Epoch 85 Batch 100/244] avg loss 181.47, throughput 3.63637K wps\n",
      "[Epoch 85 Batch 110/244] avg loss 458.565, throughput 2.77008K wps\n",
      "[Epoch 85 Batch 120/244] avg loss 182.159, throughput 3.04877K wps\n",
      "[Epoch 85 Batch 130/244] avg loss 193.522, throughput 3.24675K wps\n",
      "[Epoch 85 Batch 140/244] avg loss 254.023, throughput 2.88186K wps\n",
      "[Epoch 85 Batch 150/244] avg loss 625.032, throughput 2.43901K wps\n",
      "[Epoch 85 Batch 160/244] avg loss 200.873, throughput 3.42465K wps\n",
      "[Epoch 85 Batch 170/244] avg loss 254.267, throughput 2.79329K wps\n",
      "[Epoch 85 Batch 180/244] avg loss 225.059, throughput 2.35295K wps\n",
      "[Epoch 85 Batch 190/244] avg loss 165.486, throughput 2.4331K wps\n",
      "[Epoch 85 Batch 200/244] avg loss 372.202, throughput 2.47524K wps\n",
      "[Epoch 85 Batch 210/244] avg loss 228.757, throughput 2.89854K wps\n",
      "[Epoch 85 Batch 220/244] avg loss 172.755, throughput 3.09599K wps\n",
      "[Epoch 85 Batch 230/244] avg loss 232.71, throughput 2.65956K wps\n",
      "[Epoch 85 Batch 240/244] avg loss 243.391, throughput 2.65252K wps\n",
      "[Epoch 85] train avg loss 303.942, train avg r2 0.817077,throughput 2.86991K wps\n",
      "learning rate: 3.90625e-06\n",
      "[Epoch 86 Batch 10/244] avg loss 633.623, throughput 2.37529K wps\n",
      "[Epoch 86 Batch 20/244] avg loss 410.085, throughput 2.76243K wps\n",
      "[Epoch 86 Batch 30/244] avg loss 262.2, throughput 2.92398K wps\n",
      "[Epoch 86 Batch 40/244] avg loss 295.714, throughput 3.81678K wps\n",
      "[Epoch 86 Batch 50/244] avg loss 171.135, throughput 3.93702K wps\n",
      "[Epoch 86 Batch 60/244] avg loss 739.817, throughput 2.55755K wps\n",
      "[Epoch 86 Batch 70/244] avg loss 241.631, throughput 3.2051K wps\n",
      "[Epoch 86 Batch 80/244] avg loss 144.927, throughput 3.64963K wps\n",
      "[Epoch 86 Batch 90/244] avg loss 220.637, throughput 2.67381K wps\n",
      "[Epoch 86 Batch 100/244] avg loss 173.37, throughput 3.62318K wps\n",
      "[Epoch 86 Batch 110/244] avg loss 468.17, throughput 2.77008K wps\n",
      "[Epoch 86 Batch 120/244] avg loss 190.555, throughput 3.03952K wps\n",
      "[Epoch 86 Batch 130/244] avg loss 180.326, throughput 3.25731K wps\n",
      "[Epoch 86 Batch 140/244] avg loss 230.775, throughput 2.87356K wps\n",
      "[Epoch 86 Batch 150/244] avg loss 597.108, throughput 2.43309K wps\n",
      "[Epoch 86 Batch 160/244] avg loss 207.108, throughput 3.42464K wps\n",
      "[Epoch 86 Batch 170/244] avg loss 246.527, throughput 2.78552K wps\n",
      "[Epoch 86 Batch 180/244] avg loss 217.396, throughput 2.34742K wps\n",
      "[Epoch 86 Batch 190/244] avg loss 151.467, throughput 2.42719K wps\n",
      "[Epoch 86 Batch 200/244] avg loss 371.58, throughput 2.47525K wps\n",
      "[Epoch 86 Batch 210/244] avg loss 225.241, throughput 2.89854K wps\n",
      "[Epoch 86 Batch 220/244] avg loss 172.585, throughput 3.11526K wps\n",
      "[Epoch 86 Batch 230/244] avg loss 221.821, throughput 2.65956K wps\n",
      "[Epoch 86 Batch 240/244] avg loss 242.556, throughput 2.65958K wps\n",
      "[Epoch 86] train avg loss 300.526, train avg r2 0.820667,throughput 2.86755K wps\n",
      "learning rate: 3.90625e-06\n",
      "[Epoch 87 Batch 10/244] avg loss 628.264, throughput 2.36407K wps\n",
      "[Epoch 87 Batch 20/244] avg loss 389.68, throughput 2.76243K wps\n",
      "[Epoch 87 Batch 30/244] avg loss 242.941, throughput 2.91544K wps\n",
      "[Epoch 87 Batch 40/244] avg loss 298.54, throughput 3.81678K wps\n",
      "[Epoch 87 Batch 50/244] avg loss 169.337, throughput 3.92158K wps\n",
      "[Epoch 87 Batch 60/244] avg loss 747.645, throughput 2.56411K wps\n",
      "[Epoch 87 Batch 70/244] avg loss 244.441, throughput 3.20511K wps\n",
      "[Epoch 87 Batch 80/244] avg loss 147.033, throughput 3.67647K wps\n",
      "[Epoch 87 Batch 90/244] avg loss 233.608, throughput 2.6738K wps\n",
      "[Epoch 87 Batch 100/244] avg loss 181.635, throughput 3.63635K wps\n",
      "[Epoch 87 Batch 110/244] avg loss 430.25, throughput 2.77778K wps\n",
      "[Epoch 87 Batch 120/244] avg loss 183.549, throughput 3.05807K wps\n",
      "[Epoch 87 Batch 130/244] avg loss 194.892, throughput 3.26798K wps\n",
      "[Epoch 87 Batch 140/244] avg loss 233.837, throughput 2.88184K wps\n",
      "[Epoch 87 Batch 150/244] avg loss 642.489, throughput 2.43902K wps\n",
      "[Epoch 87 Batch 160/244] avg loss 193.719, throughput 3.41297K wps\n",
      "[Epoch 87 Batch 170/244] avg loss 244.883, throughput 2.78552K wps\n",
      "[Epoch 87 Batch 180/244] avg loss 205.062, throughput 2.34192K wps\n",
      "[Epoch 87 Batch 190/244] avg loss 170.978, throughput 2.43309K wps\n",
      "[Epoch 87 Batch 200/244] avg loss 388.219, throughput 2.46913K wps\n",
      "[Epoch 87 Batch 210/244] avg loss 207.724, throughput 2.90697K wps\n",
      "[Epoch 87 Batch 220/244] avg loss 186.738, throughput 3.11526K wps\n",
      "[Epoch 87 Batch 230/244] avg loss 224.805, throughput 2.65957K wps\n",
      "[Epoch 87 Batch 240/244] avg loss 229.323, throughput 2.65252K wps\n",
      "[Epoch 87] train avg loss 300.304, train avg r2 0.816383,throughput 2.86924K wps\n",
      "learning rate: 3.90625e-06\n",
      "[Epoch 88 Batch 10/244] avg loss 660.684, throughput 2.36967K wps\n",
      "[Epoch 88 Batch 20/244] avg loss 417.932, throughput 2.77777K wps\n",
      "[Epoch 88 Batch 30/244] avg loss 230.938, throughput 2.90697K wps\n",
      "[Epoch 88 Batch 40/244] avg loss 271.893, throughput 3.84614K wps\n",
      "[Epoch 88 Batch 50/244] avg loss 165.387, throughput 3.937K wps\n",
      "[Epoch 88 Batch 60/244] avg loss 726.019, throughput 2.56409K wps\n",
      "[Epoch 88 Batch 70/244] avg loss 235, throughput 3.20513K wps\n",
      "[Epoch 88 Batch 80/244] avg loss 147.782, throughput 3.64965K wps\n",
      "[Epoch 88 Batch 90/244] avg loss 216.957, throughput 2.6738K wps\n",
      "[Epoch 88 Batch 100/244] avg loss 181.849, throughput 3.6101K wps\n",
      "[Epoch 88 Batch 110/244] avg loss 474.019, throughput 2.76243K wps\n",
      "[Epoch 88 Batch 120/244] avg loss 181.905, throughput 3.04877K wps\n",
      "[Epoch 88 Batch 130/244] avg loss 179.509, throughput 3.25733K wps\n",
      "[Epoch 88 Batch 140/244] avg loss 232.508, throughput 2.87357K wps\n",
      "[Epoch 88 Batch 150/244] avg loss 624.692, throughput 2.43309K wps\n",
      "[Epoch 88 Batch 160/244] avg loss 199.473, throughput 3.41297K wps\n",
      "[Epoch 88 Batch 170/244] avg loss 264.124, throughput 2.7933K wps\n",
      "[Epoch 88 Batch 180/244] avg loss 215.119, throughput 2.35293K wps\n",
      "[Epoch 88 Batch 190/244] avg loss 155.437, throughput 2.43309K wps\n",
      "[Epoch 88 Batch 200/244] avg loss 377.019, throughput 2.46306K wps\n",
      "[Epoch 88 Batch 210/244] avg loss 218.235, throughput 2.89854K wps\n",
      "[Epoch 88 Batch 220/244] avg loss 175.729, throughput 3.09599K wps\n",
      "[Epoch 88 Batch 230/244] avg loss 232.469, throughput 2.65957K wps\n",
      "[Epoch 88 Batch 240/244] avg loss 254.581, throughput 2.6525K wps\n",
      "[Epoch 88] train avg loss 301.51, train avg r2 0.822018,throughput 2.86654K wps\n",
      "learning rate: 3.90625e-06\n",
      "[Epoch 89 Batch 10/244] avg loss 674.053, throughput 2.36967K wps\n",
      "[Epoch 89 Batch 20/244] avg loss 411.303, throughput 2.77006K wps\n",
      "[Epoch 89 Batch 30/244] avg loss 215.496, throughput 2.91546K wps\n",
      "[Epoch 89 Batch 40/244] avg loss 295.128, throughput 3.83142K wps\n",
      "[Epoch 89 Batch 50/244] avg loss 164.371, throughput 3.92155K wps\n",
      "[Epoch 89 Batch 60/244] avg loss 718.079, throughput 2.5641K wps\n",
      "[Epoch 89 Batch 70/244] avg loss 271.21, throughput 3.21546K wps\n",
      "[Epoch 89 Batch 80/244] avg loss 146.19, throughput 3.67646K wps\n",
      "[Epoch 89 Batch 90/244] avg loss 223.238, throughput 2.67381K wps\n",
      "[Epoch 89 Batch 100/244] avg loss 171.224, throughput 3.63635K wps\n",
      "[Epoch 89 Batch 110/244] avg loss 464.204, throughput 2.77778K wps\n",
      "[Epoch 89 Batch 120/244] avg loss 200.036, throughput 3.04879K wps\n",
      "[Epoch 89 Batch 130/244] avg loss 182.13, throughput 3.26795K wps\n",
      "[Epoch 89 Batch 140/244] avg loss 232.583, throughput 2.88183K wps\n",
      "[Epoch 89 Batch 150/244] avg loss 657.211, throughput 2.445K wps\n",
      "[Epoch 89 Batch 160/244] avg loss 204.122, throughput 3.41297K wps\n",
      "[Epoch 89 Batch 170/244] avg loss 241.562, throughput 2.80112K wps\n",
      "[Epoch 89 Batch 180/244] avg loss 225.265, throughput 2.34742K wps\n",
      "[Epoch 89 Batch 190/244] avg loss 167.574, throughput 2.42718K wps\n",
      "[Epoch 89 Batch 200/244] avg loss 367.113, throughput 2.47525K wps\n",
      "[Epoch 89 Batch 210/244] avg loss 221.216, throughput 2.90697K wps\n",
      "[Epoch 89 Batch 220/244] avg loss 197.136, throughput 3.09599K wps\n",
      "[Epoch 89 Batch 230/244] avg loss 215.499, throughput 2.65957K wps\n",
      "[Epoch 89 Batch 240/244] avg loss 245.6, throughput 2.66667K wps\n",
      "[Epoch 89] train avg loss 304.587, train avg r2 0.81827,throughput 2.87126K wps\n",
      "learning rate: 3.90625e-06\n",
      "[Epoch 90 Batch 10/244] avg loss 693.099, throughput 2.37531K wps\n",
      "[Epoch 90 Batch 20/244] avg loss 423.162, throughput 2.77008K wps\n",
      "[Epoch 90 Batch 30/244] avg loss 218.779, throughput 2.92398K wps\n",
      "[Epoch 90 Batch 40/244] avg loss 295.102, throughput 3.83141K wps\n",
      "[Epoch 90 Batch 50/244] avg loss 187.006, throughput 3.92159K wps\n",
      "[Epoch 90 Batch 60/244] avg loss 733.666, throughput 2.5641K wps\n",
      "[Epoch 90 Batch 70/244] avg loss 250.314, throughput 3.21543K wps\n",
      "[Epoch 90 Batch 80/244] avg loss 143.081, throughput 3.63638K wps\n",
      "[Epoch 90 Batch 90/244] avg loss 232.936, throughput 2.68097K wps\n",
      "[Epoch 90 Batch 100/244] avg loss 168.515, throughput 3.62319K wps\n",
      "[Epoch 90 Batch 110/244] avg loss 454.359, throughput 2.76243K wps\n",
      "[Epoch 90 Batch 120/244] avg loss 192.017, throughput 3.0303K wps\n",
      "[Epoch 90 Batch 130/244] avg loss 194.039, throughput 3.25733K wps\n",
      "[Epoch 90 Batch 140/244] avg loss 242.228, throughput 2.89855K wps\n",
      "[Epoch 90 Batch 150/244] avg loss 662.027, throughput 2.26244K wps\n",
      "[Epoch 90 Batch 160/244] avg loss 202.053, throughput 3.41297K wps\n",
      "[Epoch 90 Batch 170/244] avg loss 234.874, throughput 2.7933K wps\n",
      "[Epoch 90 Batch 180/244] avg loss 211.829, throughput 2.34742K wps\n",
      "[Epoch 90 Batch 190/244] avg loss 159.116, throughput 2.42718K wps\n",
      "[Epoch 90 Batch 200/244] avg loss 374.53, throughput 2.48138K wps\n",
      "[Epoch 90 Batch 210/244] avg loss 196.61, throughput 2.89855K wps\n",
      "[Epoch 90 Batch 220/244] avg loss 175.683, throughput 3.11529K wps\n",
      "[Epoch 90 Batch 230/244] avg loss 235.315, throughput 2.65252K wps\n",
      "[Epoch 90 Batch 240/244] avg loss 236.138, throughput 2.6455K wps\n",
      "[Epoch 90] train avg loss 304.998, train avg r2 0.815457,throughput 2.85781K wps\n",
      "learning rate: 1.953125e-06\n",
      "[Epoch 91 Batch 10/244] avg loss 637.563, throughput 2.29885K wps\n",
      "[Epoch 91 Batch 20/244] avg loss 409.897, throughput 2.77009K wps\n",
      "[Epoch 91 Batch 30/244] avg loss 222.82, throughput 2.84899K wps\n",
      "[Epoch 91 Batch 40/244] avg loss 282.174, throughput 3.8168K wps\n",
      "[Epoch 91 Batch 50/244] avg loss 180.073, throughput 3.9526K wps\n",
      "[Epoch 91 Batch 60/244] avg loss 734.153, throughput 2.55755K wps\n",
      "[Epoch 91 Batch 70/244] avg loss 245.487, throughput 3.08641K wps\n",
      "[Epoch 91 Batch 80/244] avg loss 149.495, throughput 3.64964K wps\n",
      "[Epoch 91 Batch 90/244] avg loss 231.337, throughput 2.64551K wps\n",
      "[Epoch 91 Batch 100/244] avg loss 181.715, throughput 3.50877K wps\n",
      "[Epoch 91 Batch 110/244] avg loss 471.912, throughput 2.77008K wps\n",
      "[Epoch 91 Batch 120/244] avg loss 193.646, throughput 3.03952K wps\n",
      "[Epoch 91 Batch 130/244] avg loss 203.071, throughput 3.25732K wps\n",
      "[Epoch 91 Batch 140/244] avg loss 249.072, throughput 2.87356K wps\n",
      "[Epoch 91 Batch 150/244] avg loss 603.055, throughput 2.43309K wps\n",
      "[Epoch 91 Batch 160/244] avg loss 216.421, throughput 3.42465K wps\n",
      "[Epoch 91 Batch 170/244] avg loss 249.25, throughput 2.7855K wps\n",
      "[Epoch 91 Batch 180/244] avg loss 214.963, throughput 2.34193K wps\n",
      "[Epoch 91 Batch 190/244] avg loss 158.917, throughput 2.43309K wps\n",
      "[Epoch 91 Batch 200/244] avg loss 364.505, throughput 2.47524K wps\n",
      "[Epoch 91 Batch 210/244] avg loss 221.271, throughput 2.89856K wps\n",
      "[Epoch 91 Batch 220/244] avg loss 184.049, throughput 3.11526K wps\n",
      "[Epoch 91 Batch 230/244] avg loss 238.745, throughput 2.65252K wps\n",
      "[Epoch 91 Batch 240/244] avg loss 224.456, throughput 2.65957K wps\n",
      "[Epoch 91] train avg loss 303.018, train avg r2 0.815848,throughput 2.85213K wps\n",
      "learning rate: 1.953125e-06\n",
      "[Epoch 92 Batch 10/244] avg loss 655.487, throughput 2.36406K wps\n",
      "[Epoch 92 Batch 20/244] avg loss 395.267, throughput 2.77008K wps\n",
      "[Epoch 92 Batch 30/244] avg loss 214.913, throughput 2.91545K wps\n",
      "[Epoch 92 Batch 40/244] avg loss 297.146, throughput 3.84618K wps\n",
      "[Epoch 92 Batch 50/244] avg loss 173.451, throughput 3.92156K wps\n",
      "[Epoch 92 Batch 60/244] avg loss 772.357, throughput 2.56411K wps\n",
      "[Epoch 92 Batch 70/244] avg loss 252.506, throughput 3.20513K wps\n",
      "[Epoch 92 Batch 80/244] avg loss 142.519, throughput 3.64964K wps\n",
      "[Epoch 92 Batch 90/244] avg loss 224.861, throughput 2.68096K wps\n",
      "[Epoch 92 Batch 100/244] avg loss 188.459, throughput 3.63636K wps\n",
      "[Epoch 92 Batch 110/244] avg loss 443.317, throughput 2.77009K wps\n",
      "[Epoch 92 Batch 120/244] avg loss 182.597, throughput 3.03951K wps\n",
      "[Epoch 92 Batch 130/244] avg loss 197.163, throughput 3.24675K wps\n",
      "[Epoch 92 Batch 140/244] avg loss 235.354, throughput 2.89018K wps\n",
      "[Epoch 92 Batch 150/244] avg loss 624.021, throughput 2.43309K wps\n",
      "[Epoch 92 Batch 160/244] avg loss 210.158, throughput 3.41297K wps\n",
      "[Epoch 92 Batch 170/244] avg loss 231.081, throughput 2.7933K wps\n",
      "[Epoch 92 Batch 180/244] avg loss 215.151, throughput 2.34742K wps\n",
      "[Epoch 92 Batch 190/244] avg loss 164.374, throughput 2.43309K wps\n",
      "[Epoch 92 Batch 200/244] avg loss 387.497, throughput 2.47525K wps\n",
      "[Epoch 92 Batch 210/244] avg loss 228.419, throughput 2.89854K wps\n",
      "[Epoch 92 Batch 220/244] avg loss 170.285, throughput 3.125K wps\n",
      "[Epoch 92 Batch 230/244] avg loss 242.488, throughput 2.65954K wps\n",
      "[Epoch 92 Batch 240/244] avg loss 238.242, throughput 2.65961K wps\n",
      "[Epoch 92] train avg loss 303.459, train avg r2 0.819698,throughput 2.86856K wps\n",
      "learning rate: 1.953125e-06\n",
      "[Epoch 93 Batch 10/244] avg loss 696.052, throughput 2.36407K wps\n",
      "[Epoch 93 Batch 20/244] avg loss 388.929, throughput 2.77008K wps\n",
      "[Epoch 93 Batch 30/244] avg loss 238.401, throughput 2.91545K wps\n",
      "[Epoch 93 Batch 40/244] avg loss 284.81, throughput 3.83142K wps\n",
      "[Epoch 93 Batch 50/244] avg loss 176.892, throughput 3.93702K wps\n",
      "[Epoch 93 Batch 60/244] avg loss 751.361, throughput 2.57069K wps\n",
      "[Epoch 93 Batch 70/244] avg loss 252.483, throughput 3.21543K wps\n",
      "[Epoch 93 Batch 80/244] avg loss 149.546, throughput 3.66301K wps\n",
      "[Epoch 93 Batch 90/244] avg loss 219.018, throughput 2.6738K wps\n",
      "[Epoch 93 Batch 100/244] avg loss 191.182, throughput 3.63635K wps\n",
      "[Epoch 93 Batch 110/244] avg loss 463.282, throughput 2.77008K wps\n",
      "[Epoch 93 Batch 120/244] avg loss 195.31, throughput 3.04876K wps\n",
      "[Epoch 93 Batch 130/244] avg loss 199.317, throughput 3.25734K wps\n",
      "[Epoch 93 Batch 140/244] avg loss 232.835, throughput 2.88186K wps\n",
      "[Epoch 93 Batch 150/244] avg loss 632.977, throughput 2.42718K wps\n",
      "[Epoch 93 Batch 160/244] avg loss 192.744, throughput 3.41296K wps\n",
      "[Epoch 93 Batch 170/244] avg loss 224.815, throughput 2.78552K wps\n",
      "[Epoch 93 Batch 180/244] avg loss 205.717, throughput 2.34741K wps\n",
      "[Epoch 93 Batch 190/244] avg loss 164.869, throughput 2.42718K wps\n",
      "[Epoch 93 Batch 200/244] avg loss 390.991, throughput 2.48139K wps\n",
      "[Epoch 93 Batch 210/244] avg loss 227.208, throughput 2.89017K wps\n",
      "[Epoch 93 Batch 220/244] avg loss 176.613, throughput 3.11526K wps\n",
      "[Epoch 93 Batch 230/244] avg loss 217.55, throughput 2.65957K wps\n",
      "[Epoch 93 Batch 240/244] avg loss 243.451, throughput 2.65957K wps\n",
      "[Epoch 93] train avg loss 304.318, train avg r2 0.819416,throughput 2.86856K wps\n",
      "learning rate: 1.953125e-06\n",
      "[Epoch 94 Batch 10/244] avg loss 653.717, throughput 2.36967K wps\n",
      "[Epoch 94 Batch 20/244] avg loss 385.392, throughput 2.77008K wps\n",
      "[Epoch 94 Batch 30/244] avg loss 216.353, throughput 2.91545K wps\n",
      "[Epoch 94 Batch 40/244] avg loss 301.594, throughput 3.83142K wps\n",
      "[Epoch 94 Batch 50/244] avg loss 185.248, throughput 3.93701K wps\n",
      "[Epoch 94 Batch 60/244] avg loss 760.714, throughput 2.55754K wps\n",
      "[Epoch 94 Batch 70/244] avg loss 255.563, throughput 3.19489K wps\n",
      "[Epoch 94 Batch 80/244] avg loss 143.345, throughput 3.66299K wps\n",
      "[Epoch 94 Batch 90/244] avg loss 225.483, throughput 2.68097K wps\n",
      "[Epoch 94 Batch 100/244] avg loss 186.582, throughput 3.63635K wps\n",
      "[Epoch 94 Batch 110/244] avg loss 467.477, throughput 2.77778K wps\n",
      "[Epoch 94 Batch 120/244] avg loss 185.751, throughput 3.04878K wps\n",
      "[Epoch 94 Batch 130/244] avg loss 192.968, throughput 3.25731K wps\n",
      "[Epoch 94 Batch 140/244] avg loss 248.106, throughput 2.88184K wps\n",
      "[Epoch 94 Batch 150/244] avg loss 631.05, throughput 2.43903K wps\n",
      "[Epoch 94 Batch 160/244] avg loss 207.354, throughput 3.40137K wps\n",
      "[Epoch 94 Batch 170/244] avg loss 221.789, throughput 2.80112K wps\n",
      "[Epoch 94 Batch 180/244] avg loss 211.374, throughput 2.34742K wps\n",
      "[Epoch 94 Batch 190/244] avg loss 166.424, throughput 2.43309K wps\n",
      "[Epoch 94 Batch 200/244] avg loss 365.942, throughput 2.47524K wps\n",
      "[Epoch 94 Batch 210/244] avg loss 226.02, throughput 2.89018K wps\n",
      "[Epoch 94 Batch 220/244] avg loss 192.213, throughput 3.11526K wps\n",
      "[Epoch 94 Batch 230/244] avg loss 243.001, throughput 2.65253K wps\n",
      "[Epoch 94 Batch 240/244] avg loss 235.361, throughput 2.65251K wps\n",
      "[Epoch 94] train avg loss 304.333, train avg r2 0.813538,throughput 2.86856K wps\n",
      "learning rate: 1.953125e-06\n",
      "[Epoch 95 Batch 10/244] avg loss 654.842, throughput 2.36967K wps\n",
      "[Epoch 95 Batch 20/244] avg loss 375.505, throughput 2.77009K wps\n",
      "[Epoch 95 Batch 30/244] avg loss 231.088, throughput 2.92398K wps\n",
      "[Epoch 95 Batch 40/244] avg loss 276.591, throughput 3.84617K wps\n",
      "[Epoch 95 Batch 50/244] avg loss 175.384, throughput 3.9216K wps\n",
      "[Epoch 95 Batch 60/244] avg loss 742.512, throughput 2.5641K wps\n",
      "[Epoch 95 Batch 70/244] avg loss 256.577, throughput 3.20513K wps\n",
      "[Epoch 95 Batch 80/244] avg loss 141.974, throughput 3.67646K wps\n",
      "[Epoch 95 Batch 90/244] avg loss 224.205, throughput 2.68096K wps\n",
      "[Epoch 95 Batch 100/244] avg loss 173.156, throughput 3.64964K wps\n",
      "[Epoch 95 Batch 110/244] avg loss 488.141, throughput 2.77008K wps\n",
      "[Epoch 95 Batch 120/244] avg loss 177.918, throughput 3.04878K wps\n",
      "[Epoch 95 Batch 130/244] avg loss 182.777, throughput 3.24676K wps\n",
      "[Epoch 95 Batch 140/244] avg loss 232.942, throughput 2.89017K wps\n",
      "[Epoch 95 Batch 150/244] avg loss 608.224, throughput 2.44498K wps\n",
      "[Epoch 95 Batch 160/244] avg loss 211.809, throughput 3.41296K wps\n",
      "[Epoch 95 Batch 170/244] avg loss 223.907, throughput 2.79331K wps\n",
      "[Epoch 95 Batch 180/244] avg loss 229.369, throughput 2.35293K wps\n",
      "[Epoch 95 Batch 190/244] avg loss 171.932, throughput 2.43309K wps\n",
      "[Epoch 95 Batch 200/244] avg loss 364.964, throughput 2.48138K wps\n",
      "[Epoch 95 Batch 210/244] avg loss 221.748, throughput 2.89854K wps\n",
      "[Epoch 95 Batch 220/244] avg loss 175.224, throughput 3.11527K wps\n",
      "[Epoch 95 Batch 230/244] avg loss 223.209, throughput 2.65957K wps\n",
      "[Epoch 95 Batch 240/244] avg loss 240.563, throughput 2.65253K wps\n",
      "[Epoch 95] train avg loss 299.469, train avg r2 0.81839,throughput 2.86958K wps\n",
      "learning rate: 1.953125e-06\n",
      "[Epoch 96 Batch 10/244] avg loss 656.372, throughput 2.36967K wps\n",
      "[Epoch 96 Batch 20/244] avg loss 426.158, throughput 2.77008K wps\n",
      "[Epoch 96 Batch 30/244] avg loss 223.451, throughput 2.90697K wps\n",
      "[Epoch 96 Batch 40/244] avg loss 296.174, throughput 3.83142K wps\n",
      "[Epoch 96 Batch 50/244] avg loss 190.129, throughput 3.93702K wps\n",
      "[Epoch 96 Batch 60/244] avg loss 729.76, throughput 2.55754K wps\n",
      "[Epoch 96 Batch 70/244] avg loss 253.738, throughput 3.19488K wps\n",
      "[Epoch 96 Batch 80/244] avg loss 145.056, throughput 3.64965K wps\n",
      "[Epoch 96 Batch 90/244] avg loss 226.201, throughput 2.67379K wps\n",
      "[Epoch 96 Batch 100/244] avg loss 176.818, throughput 3.62319K wps\n",
      "[Epoch 96 Batch 110/244] avg loss 479.044, throughput 2.76244K wps\n",
      "[Epoch 96 Batch 120/244] avg loss 188.808, throughput 3.03951K wps\n",
      "[Epoch 96 Batch 130/244] avg loss 196.919, throughput 3.24674K wps\n",
      "[Epoch 96 Batch 140/244] avg loss 231.916, throughput 2.87356K wps\n",
      "[Epoch 96 Batch 150/244] avg loss 607.042, throughput 2.43903K wps\n",
      "[Epoch 96 Batch 160/244] avg loss 195.677, throughput 3.41295K wps\n",
      "[Epoch 96 Batch 170/244] avg loss 239.798, throughput 2.79329K wps\n",
      "[Epoch 96 Batch 180/244] avg loss 216.195, throughput 2.34192K wps\n",
      "[Epoch 96 Batch 190/244] avg loss 173.461, throughput 2.42719K wps\n",
      "[Epoch 96 Batch 200/244] avg loss 370.399, throughput 2.47525K wps\n",
      "[Epoch 96 Batch 210/244] avg loss 223.097, throughput 2.88185K wps\n",
      "[Epoch 96 Batch 220/244] avg loss 175.079, throughput 3.11526K wps\n",
      "[Epoch 96 Batch 230/244] avg loss 224.609, throughput 2.65253K wps\n",
      "[Epoch 96 Batch 240/244] avg loss 254.944, throughput 2.65251K wps\n",
      "[Epoch 96] train avg loss 303.973, train avg r2 0.815483,throughput 2.86553K wps\n",
      "learning rate: 1.953125e-06\n",
      "[Epoch 97 Batch 10/244] avg loss 594.701, throughput 2.36406K wps\n",
      "[Epoch 97 Batch 20/244] avg loss 399.376, throughput 2.77008K wps\n",
      "[Epoch 97 Batch 30/244] avg loss 214.74, throughput 2.90696K wps\n",
      "[Epoch 97 Batch 40/244] avg loss 275.912, throughput 3.83142K wps\n",
      "[Epoch 97 Batch 50/244] avg loss 183.308, throughput 3.92157K wps\n",
      "[Epoch 97 Batch 60/244] avg loss 741.069, throughput 2.56411K wps\n",
      "[Epoch 97 Batch 70/244] avg loss 259.346, throughput 3.19487K wps\n",
      "[Epoch 97 Batch 80/244] avg loss 135.726, throughput 3.67649K wps\n",
      "[Epoch 97 Batch 90/244] avg loss 222.567, throughput 2.68096K wps\n",
      "[Epoch 97 Batch 100/244] avg loss 176.197, throughput 3.63637K wps\n",
      "[Epoch 97 Batch 110/244] avg loss 481.166, throughput 2.77008K wps\n",
      "[Epoch 97 Batch 120/244] avg loss 190.203, throughput 3.03031K wps\n",
      "[Epoch 97 Batch 130/244] avg loss 189.856, throughput 3.25733K wps\n",
      "[Epoch 97 Batch 140/244] avg loss 227.804, throughput 2.87357K wps\n",
      "[Epoch 97 Batch 150/244] avg loss 623.973, throughput 2.44498K wps\n",
      "[Epoch 97 Batch 160/244] avg loss 212.035, throughput 3.41298K wps\n",
      "[Epoch 97 Batch 170/244] avg loss 244.053, throughput 2.80111K wps\n",
      "[Epoch 97 Batch 180/244] avg loss 218.399, throughput 2.34192K wps\n",
      "[Epoch 97 Batch 190/244] avg loss 168.102, throughput 2.42718K wps\n",
      "[Epoch 97 Batch 200/244] avg loss 366.321, throughput 2.47525K wps\n",
      "[Epoch 97 Batch 210/244] avg loss 219.854, throughput 2.89854K wps\n",
      "[Epoch 97 Batch 220/244] avg loss 193.927, throughput 3.11527K wps\n",
      "[Epoch 97 Batch 230/244] avg loss 230.289, throughput 2.65253K wps\n",
      "[Epoch 97 Batch 240/244] avg loss 255.209, throughput 2.65251K wps\n",
      "[Epoch 97] train avg loss 301.029, train avg r2 0.819504,throughput 2.86755K wps\n",
      "learning rate: 1.953125e-06\n",
      "[Epoch 98 Batch 10/244] avg loss 632.476, throughput 2.37529K wps\n",
      "[Epoch 98 Batch 20/244] avg loss 391.362, throughput 2.76244K wps\n",
      "[Epoch 98 Batch 30/244] avg loss 227.341, throughput 2.91544K wps\n",
      "[Epoch 98 Batch 40/244] avg loss 297.446, throughput 3.83141K wps\n",
      "[Epoch 98 Batch 50/244] avg loss 155.647, throughput 3.93701K wps\n",
      "[Epoch 98 Batch 60/244] avg loss 765.683, throughput 2.55754K wps\n",
      "[Epoch 98 Batch 70/244] avg loss 234.177, throughput 3.2154K wps\n",
      "[Epoch 98 Batch 80/244] avg loss 138.886, throughput 3.67648K wps\n",
      "[Epoch 98 Batch 90/244] avg loss 211.792, throughput 2.66667K wps\n",
      "[Epoch 98 Batch 100/244] avg loss 174.444, throughput 3.62318K wps\n",
      "[Epoch 98 Batch 110/244] avg loss 486.475, throughput 2.77007K wps\n",
      "[Epoch 98 Batch 120/244] avg loss 176.526, throughput 3.05811K wps\n",
      "[Epoch 98 Batch 130/244] avg loss 190.144, throughput 3.25732K wps\n",
      "[Epoch 98 Batch 140/244] avg loss 231.564, throughput 2.88184K wps\n",
      "[Epoch 98 Batch 150/244] avg loss 616.939, throughput 2.43902K wps\n",
      "[Epoch 98 Batch 160/244] avg loss 199.458, throughput 3.41297K wps\n",
      "[Epoch 98 Batch 170/244] avg loss 246.852, throughput 2.7933K wps\n",
      "[Epoch 98 Batch 180/244] avg loss 212.362, throughput 2.34742K wps\n",
      "[Epoch 98 Batch 190/244] avg loss 158.855, throughput 2.43309K wps\n",
      "[Epoch 98 Batch 200/244] avg loss 383.453, throughput 2.47526K wps\n",
      "[Epoch 98 Batch 210/244] avg loss 241.749, throughput 2.89854K wps\n",
      "[Epoch 98 Batch 220/244] avg loss 170.753, throughput 3.11527K wps\n",
      "[Epoch 98 Batch 230/244] avg loss 215.582, throughput 2.65958K wps\n",
      "[Epoch 98 Batch 240/244] avg loss 246.207, throughput 2.65251K wps\n",
      "[Epoch 98] train avg loss 300.101, train avg r2 0.814131,throughput 2.86958K wps\n",
      "learning rate: 1.953125e-06\n",
      "[Epoch 99 Batch 10/244] avg loss 602.511, throughput 2.36967K wps\n",
      "[Epoch 99 Batch 20/244] avg loss 422.358, throughput 2.77777K wps\n",
      "[Epoch 99 Batch 30/244] avg loss 218.391, throughput 2.92397K wps\n",
      "[Epoch 99 Batch 40/244] avg loss 284.035, throughput 3.8314K wps\n",
      "[Epoch 99 Batch 50/244] avg loss 166.216, throughput 3.96828K wps\n",
      "[Epoch 99 Batch 60/244] avg loss 717.703, throughput 2.55755K wps\n",
      "[Epoch 99 Batch 70/244] avg loss 265.838, throughput 3.21542K wps\n",
      "[Epoch 99 Batch 80/244] avg loss 145.773, throughput 3.66302K wps\n",
      "[Epoch 99 Batch 90/244] avg loss 234.377, throughput 2.68096K wps\n",
      "[Epoch 99 Batch 100/244] avg loss 168.858, throughput 3.63636K wps\n",
      "[Epoch 99 Batch 110/244] avg loss 471.524, throughput 2.77009K wps\n",
      "[Epoch 99 Batch 120/244] avg loss 181.115, throughput 3.04877K wps\n",
      "[Epoch 99 Batch 130/244] avg loss 173.756, throughput 3.25734K wps\n",
      "[Epoch 99 Batch 140/244] avg loss 231.134, throughput 2.89855K wps\n",
      "[Epoch 99 Batch 150/244] avg loss 592.814, throughput 2.43902K wps\n",
      "[Epoch 99 Batch 160/244] avg loss 203.691, throughput 3.42466K wps\n",
      "[Epoch 99 Batch 170/244] avg loss 239.734, throughput 2.79331K wps\n",
      "[Epoch 99 Batch 180/244] avg loss 212.246, throughput 2.34741K wps\n",
      "[Epoch 99 Batch 190/244] avg loss 161.121, throughput 2.43309K wps\n",
      "[Epoch 99 Batch 200/244] avg loss 384.091, throughput 2.46913K wps\n",
      "[Epoch 99 Batch 210/244] avg loss 227.547, throughput 2.89017K wps\n",
      "[Epoch 99 Batch 220/244] avg loss 177.314, throughput 3.10559K wps\n",
      "[Epoch 99 Batch 230/244] avg loss 235.315, throughput 2.65252K wps\n",
      "[Epoch 99 Batch 240/244] avg loss 252.23, throughput 2.65958K wps\n",
      "[Epoch 99] train avg loss 298.564, train avg r2 0.822644,throughput 2.86991K wps\n",
      "learning rate: 1.953125e-06\n",
      "[Epoch 100 Batch 10/244] avg loss 697.19, throughput 2.36967K wps\n",
      "[Epoch 100 Batch 20/244] avg loss 426.224, throughput 2.76244K wps\n",
      "[Epoch 100 Batch 30/244] avg loss 218.168, throughput 2.91544K wps\n",
      "[Epoch 100 Batch 40/244] avg loss 303.209, throughput 3.84615K wps\n",
      "[Epoch 100 Batch 50/244] avg loss 184.904, throughput 3.95258K wps\n",
      "[Epoch 100 Batch 60/244] avg loss 792.43, throughput 2.5641K wps\n",
      "[Epoch 100 Batch 70/244] avg loss 269.696, throughput 3.20513K wps\n",
      "[Epoch 100 Batch 80/244] avg loss 157.408, throughput 3.66301K wps\n",
      "[Epoch 100 Batch 90/244] avg loss 222.173, throughput 2.68096K wps\n",
      "[Epoch 100 Batch 100/244] avg loss 174.092, throughput 3.63637K wps\n",
      "[Epoch 100 Batch 110/244] avg loss 438.957, throughput 2.75482K wps\n",
      "[Epoch 100 Batch 120/244] avg loss 194.056, throughput 3.05812K wps\n",
      "[Epoch 100 Batch 130/244] avg loss 181.388, throughput 3.23623K wps\n",
      "[Epoch 100 Batch 140/244] avg loss 240.607, throughput 2.88185K wps\n",
      "[Epoch 100 Batch 150/244] avg loss 621.779, throughput 2.42718K wps\n",
      "[Epoch 100 Batch 160/244] avg loss 205.549, throughput 3.42464K wps\n",
      "[Epoch 100 Batch 170/244] avg loss 230.646, throughput 2.80113K wps\n",
      "[Epoch 100 Batch 180/244] avg loss 202.181, throughput 2.34741K wps\n",
      "[Epoch 100 Batch 190/244] avg loss 159.634, throughput 2.43309K wps\n",
      "[Epoch 100 Batch 200/244] avg loss 389.5, throughput 2.47524K wps\n",
      "[Epoch 100 Batch 210/244] avg loss 239.801, throughput 2.89017K wps\n",
      "[Epoch 100 Batch 220/244] avg loss 186.319, throughput 3.11528K wps\n",
      "[Epoch 100 Batch 230/244] avg loss 220.443, throughput 2.66666K wps\n",
      "[Epoch 100 Batch 240/244] avg loss 239.319, throughput 2.65957K wps\n",
      "[Epoch 100] train avg loss 308.013, train avg r2 0.810882,throughput 2.86924K wps\n",
      "learning rate: 9.765625e-07\n",
      "[Epoch 101 Batch 10/244] avg loss 633.987, throughput 2.3585K wps\n",
      "[Epoch 101 Batch 20/244] avg loss 368.977, throughput 2.76243K wps\n",
      "[Epoch 101 Batch 30/244] avg loss 220.176, throughput 2.91545K wps\n",
      "[Epoch 101 Batch 40/244] avg loss 284.661, throughput 3.83142K wps\n",
      "[Epoch 101 Batch 50/244] avg loss 191.479, throughput 3.95257K wps\n",
      "[Epoch 101 Batch 60/244] avg loss 745.761, throughput 2.56411K wps\n",
      "[Epoch 101 Batch 70/244] avg loss 276.668, throughput 3.20512K wps\n",
      "[Epoch 101 Batch 80/244] avg loss 149.345, throughput 3.663K wps\n",
      "[Epoch 101 Batch 90/244] avg loss 240.884, throughput 2.67381K wps\n",
      "[Epoch 101 Batch 100/244] avg loss 183.688, throughput 3.63634K wps\n",
      "[Epoch 101 Batch 110/244] avg loss 436.803, throughput 2.77009K wps\n",
      "[Epoch 101 Batch 120/244] avg loss 176.657, throughput 3.03952K wps\n",
      "[Epoch 101 Batch 130/244] avg loss 186.192, throughput 3.24673K wps\n",
      "[Epoch 101 Batch 140/244] avg loss 247.334, throughput 2.88186K wps\n",
      "[Epoch 101 Batch 150/244] avg loss 619.451, throughput 2.43308K wps\n",
      "[Epoch 101 Batch 160/244] avg loss 205.09, throughput 3.42466K wps\n",
      "[Epoch 101 Batch 170/244] avg loss 234.206, throughput 2.79331K wps\n",
      "[Epoch 101 Batch 180/244] avg loss 217.364, throughput 2.34741K wps\n",
      "[Epoch 101 Batch 190/244] avg loss 159.561, throughput 2.43309K wps\n",
      "[Epoch 101 Batch 200/244] avg loss 380.056, throughput 2.46913K wps\n",
      "[Epoch 101 Batch 210/244] avg loss 253.905, throughput 2.90697K wps\n",
      "[Epoch 101 Batch 220/244] avg loss 182.972, throughput 3.11525K wps\n",
      "[Epoch 101 Batch 230/244] avg loss 214.011, throughput 2.66668K wps\n",
      "[Epoch 101 Batch 240/244] avg loss 248.819, throughput 2.65957K wps\n",
      "[Epoch 101] train avg loss 302.847, train avg r2 0.813311,throughput 2.86991K wps\n",
      "learning rate: 9.765625e-07\n",
      "[Epoch 102 Batch 10/244] avg loss 631.003, throughput 2.36967K wps\n",
      "[Epoch 102 Batch 20/244] avg loss 417.975, throughput 2.77778K wps\n",
      "[Epoch 102 Batch 30/244] avg loss 229.429, throughput 2.92398K wps\n",
      "[Epoch 102 Batch 40/244] avg loss 302.422, throughput 3.83142K wps\n",
      "[Epoch 102 Batch 50/244] avg loss 190.707, throughput 3.937K wps\n",
      "[Epoch 102 Batch 60/244] avg loss 785.043, throughput 2.56411K wps\n",
      "[Epoch 102 Batch 70/244] avg loss 266.388, throughput 3.20513K wps\n",
      "[Epoch 102 Batch 80/244] avg loss 143.405, throughput 3.663K wps\n",
      "[Epoch 102 Batch 90/244] avg loss 246.068, throughput 2.6738K wps\n",
      "[Epoch 102 Batch 100/244] avg loss 167.996, throughput 3.63637K wps\n",
      "[Epoch 102 Batch 110/244] avg loss 470.637, throughput 2.77006K wps\n",
      "[Epoch 102 Batch 120/244] avg loss 191.754, throughput 3.03951K wps\n",
      "[Epoch 102 Batch 130/244] avg loss 181.823, throughput 3.25734K wps\n",
      "[Epoch 102 Batch 140/244] avg loss 231.743, throughput 2.88184K wps\n",
      "[Epoch 102 Batch 150/244] avg loss 640.166, throughput 2.4331K wps\n",
      "[Epoch 102 Batch 160/244] avg loss 203.584, throughput 3.41296K wps\n",
      "[Epoch 102 Batch 170/244] avg loss 229.789, throughput 2.79328K wps\n",
      "[Epoch 102 Batch 180/244] avg loss 241.496, throughput 2.34743K wps\n",
      "[Epoch 102 Batch 190/244] avg loss 165.587, throughput 2.43307K wps\n",
      "[Epoch 102 Batch 200/244] avg loss 369.604, throughput 2.47526K wps\n",
      "[Epoch 102 Batch 210/244] avg loss 233.612, throughput 2.89854K wps\n",
      "[Epoch 102 Batch 220/244] avg loss 192.634, throughput 3.11527K wps\n",
      "[Epoch 102 Batch 230/244] avg loss 228.132, throughput 2.65957K wps\n",
      "[Epoch 102 Batch 240/244] avg loss 230.909, throughput 2.65957K wps\n",
      "[Epoch 102] train avg loss 306.926, train avg r2 0.811227,throughput 2.87025K wps\n",
      "learning rate: 9.765625e-07\n",
      "[Epoch 103 Batch 10/244] avg loss 629.807, throughput 2.37529K wps\n",
      "[Epoch 103 Batch 20/244] avg loss 409.121, throughput 2.77008K wps\n",
      "[Epoch 103 Batch 30/244] avg loss 242.513, throughput 2.90697K wps\n",
      "[Epoch 103 Batch 40/244] avg loss 316.462, throughput 3.84616K wps\n",
      "[Epoch 103 Batch 50/244] avg loss 184.264, throughput 3.95256K wps\n",
      "[Epoch 103 Batch 60/244] avg loss 732.078, throughput 2.5707K wps\n",
      "[Epoch 103 Batch 70/244] avg loss 272.158, throughput 3.2258K wps\n",
      "[Epoch 103 Batch 80/244] avg loss 151.574, throughput 3.66299K wps\n",
      "[Epoch 103 Batch 90/244] avg loss 236.513, throughput 2.67379K wps\n",
      "[Epoch 103 Batch 100/244] avg loss 171.891, throughput 3.63635K wps\n",
      "[Epoch 103 Batch 110/244] avg loss 406.209, throughput 2.77779K wps\n",
      "[Epoch 103 Batch 120/244] avg loss 175.989, throughput 3.04878K wps\n",
      "[Epoch 103 Batch 130/244] avg loss 197.492, throughput 3.24674K wps\n",
      "[Epoch 103 Batch 140/244] avg loss 236.427, throughput 2.87357K wps\n",
      "[Epoch 103 Batch 150/244] avg loss 632.138, throughput 2.43902K wps\n",
      "[Epoch 103 Batch 160/244] avg loss 210.603, throughput 3.40134K wps\n",
      "[Epoch 103 Batch 170/244] avg loss 224.6, throughput 2.7933K wps\n",
      "[Epoch 103 Batch 180/244] avg loss 203.313, throughput 2.34741K wps\n",
      "[Epoch 103 Batch 190/244] avg loss 170.683, throughput 2.42719K wps\n",
      "[Epoch 103 Batch 200/244] avg loss 365.987, throughput 2.46914K wps\n",
      "[Epoch 103 Batch 210/244] avg loss 248.232, throughput 2.89854K wps\n",
      "[Epoch 103 Batch 220/244] avg loss 178.019, throughput 3.11527K wps\n",
      "[Epoch 103 Batch 230/244] avg loss 225.058, throughput 2.65252K wps\n",
      "[Epoch 103 Batch 240/244] avg loss 250.483, throughput 2.65957K wps\n",
      "[Epoch 103] train avg loss 302.86, train avg r2 0.808069,throughput 2.86958K wps\n",
      "learning rate: 9.765625e-07\n",
      "[Epoch 104 Batch 10/244] avg loss 610.347, throughput 2.36968K wps\n",
      "[Epoch 104 Batch 20/244] avg loss 418.437, throughput 2.77008K wps\n",
      "[Epoch 104 Batch 30/244] avg loss 219.292, throughput 2.91546K wps\n",
      "[Epoch 104 Batch 40/244] avg loss 280.251, throughput 3.81677K wps\n",
      "[Epoch 104 Batch 50/244] avg loss 177.069, throughput 3.93702K wps\n",
      "[Epoch 104 Batch 60/244] avg loss 762.309, throughput 2.57069K wps\n",
      "[Epoch 104 Batch 70/244] avg loss 267.707, throughput 3.20511K wps\n",
      "[Epoch 104 Batch 80/244] avg loss 141.237, throughput 3.66302K wps\n",
      "[Epoch 104 Batch 90/244] avg loss 240.944, throughput 2.68096K wps\n",
      "[Epoch 104 Batch 100/244] avg loss 160.5, throughput 3.63635K wps\n",
      "[Epoch 104 Batch 110/244] avg loss 451.856, throughput 2.77778K wps\n",
      "[Epoch 104 Batch 120/244] avg loss 182.047, throughput 3.0581K wps\n",
      "[Epoch 104 Batch 130/244] avg loss 183.816, throughput 3.24675K wps\n",
      "[Epoch 104 Batch 140/244] avg loss 216.62, throughput 2.89018K wps\n",
      "[Epoch 104 Batch 150/244] avg loss 616.91, throughput 2.43309K wps\n",
      "[Epoch 104 Batch 160/244] avg loss 192.287, throughput 3.40136K wps\n",
      "[Epoch 104 Batch 170/244] avg loss 236.622, throughput 2.79331K wps\n",
      "[Epoch 104 Batch 180/244] avg loss 221.204, throughput 2.34741K wps\n",
      "[Epoch 104 Batch 190/244] avg loss 149.358, throughput 2.43309K wps\n",
      "[Epoch 104 Batch 200/244] avg loss 376.958, throughput 2.47525K wps\n",
      "[Epoch 104 Batch 210/244] avg loss 231.745, throughput 2.89855K wps\n",
      "[Epoch 104 Batch 220/244] avg loss 176.665, throughput 3.11527K wps\n",
      "[Epoch 104 Batch 230/244] avg loss 214.661, throughput 2.65958K wps\n",
      "[Epoch 104 Batch 240/244] avg loss 249.145, throughput 2.65251K wps\n",
      "[Epoch 104] train avg loss 298.718, train avg r2 0.817645,throughput 2.86823K wps\n",
      "learning rate: 9.765625e-07\n",
      "[Epoch 105 Batch 10/244] avg loss 638.387, throughput 2.32558K wps\n",
      "[Epoch 105 Batch 20/244] avg loss 417.505, throughput 2.76243K wps\n",
      "[Epoch 105 Batch 30/244] avg loss 216.043, throughput 2.849K wps\n",
      "[Epoch 105 Batch 40/244] avg loss 267.004, throughput 3.78787K wps\n",
      "[Epoch 105 Batch 50/244] avg loss 177.162, throughput 3.92157K wps\n",
      "[Epoch 105 Batch 60/244] avg loss 741.656, throughput 2.5641K wps\n",
      "[Epoch 105 Batch 70/244] avg loss 251.378, throughput 3.14466K wps\n",
      "[Epoch 105 Batch 80/244] avg loss 136.097, throughput 3.67647K wps\n",
      "[Epoch 105 Batch 90/244] avg loss 249.411, throughput 2.66666K wps\n",
      "[Epoch 105 Batch 100/244] avg loss 163.191, throughput 3.58427K wps\n",
      "[Epoch 105 Batch 110/244] avg loss 466.518, throughput 2.76243K wps\n",
      "[Epoch 105 Batch 120/244] avg loss 174.585, throughput 3.04877K wps\n",
      "[Epoch 105 Batch 130/244] avg loss 173.695, throughput 3.25737K wps\n",
      "[Epoch 105 Batch 140/244] avg loss 236.843, throughput 2.89854K wps\n",
      "[Epoch 105 Batch 150/244] avg loss 582.156, throughput 2.43309K wps\n",
      "[Epoch 105 Batch 160/244] avg loss 211.776, throughput 3.41296K wps\n",
      "[Epoch 105 Batch 170/244] avg loss 241.329, throughput 2.7933K wps\n",
      "[Epoch 105 Batch 180/244] avg loss 221.92, throughput 2.34741K wps\n",
      "[Epoch 105 Batch 190/244] avg loss 156.673, throughput 2.43308K wps\n",
      "[Epoch 105 Batch 200/244] avg loss 406.945, throughput 2.47524K wps\n",
      "[Epoch 105 Batch 210/244] avg loss 239.849, throughput 2.90697K wps\n",
      "[Epoch 105 Batch 220/244] avg loss 190.56, throughput 3.10561K wps\n",
      "[Epoch 105 Batch 230/244] avg loss 237.782, throughput 2.65251K wps\n",
      "[Epoch 105 Batch 240/244] avg loss 232.655, throughput 2.65252K wps\n",
      "[Epoch 105] train avg loss 301.398, train avg r2 0.816889,throughput 2.85848K wps\n",
      "learning rate: 9.765625e-07\n",
      "[Epoch 106 Batch 10/244] avg loss 631.177, throughput 2.36406K wps\n",
      "[Epoch 106 Batch 20/244] avg loss 394.05, throughput 2.76242K wps\n",
      "[Epoch 106 Batch 30/244] avg loss 232.289, throughput 2.92399K wps\n",
      "[Epoch 106 Batch 40/244] avg loss 290.19, throughput 3.83142K wps\n",
      "[Epoch 106 Batch 50/244] avg loss 182.21, throughput 3.92158K wps\n",
      "[Epoch 106 Batch 60/244] avg loss 757.861, throughput 2.57069K wps\n",
      "[Epoch 106 Batch 70/244] avg loss 231.13, throughput 3.20514K wps\n",
      "[Epoch 106 Batch 80/244] avg loss 139.344, throughput 3.66301K wps\n",
      "[Epoch 106 Batch 90/244] avg loss 229.083, throughput 2.68096K wps\n",
      "[Epoch 106 Batch 100/244] avg loss 169.419, throughput 3.63635K wps\n",
      "[Epoch 106 Batch 110/244] avg loss 456.779, throughput 2.77008K wps\n",
      "[Epoch 106 Batch 120/244] avg loss 179.651, throughput 3.04878K wps\n",
      "[Epoch 106 Batch 130/244] avg loss 178.704, throughput 3.24674K wps\n",
      "[Epoch 106 Batch 140/244] avg loss 233.718, throughput 2.88184K wps\n",
      "[Epoch 106 Batch 150/244] avg loss 589.328, throughput 2.43902K wps\n",
      "[Epoch 106 Batch 160/244] avg loss 192.314, throughput 3.41299K wps\n",
      "[Epoch 106 Batch 170/244] avg loss 230.667, throughput 2.7933K wps\n",
      "[Epoch 106 Batch 180/244] avg loss 238.776, throughput 2.34192K wps\n",
      "[Epoch 106 Batch 190/244] avg loss 158.078, throughput 2.43309K wps\n",
      "[Epoch 106 Batch 200/244] avg loss 375.106, throughput 2.48139K wps\n",
      "[Epoch 106 Batch 210/244] avg loss 228.681, throughput 2.89854K wps\n",
      "[Epoch 106 Batch 220/244] avg loss 177.614, throughput 3.10559K wps\n",
      "[Epoch 106 Batch 230/244] avg loss 223.487, throughput 2.65958K wps\n",
      "[Epoch 106 Batch 240/244] avg loss 237.321, throughput 2.65252K wps\n",
      "[Epoch 106] train avg loss 298.316, train avg r2 0.814632,throughput 2.86755K wps\n",
      "learning rate: 9.765625e-07\n",
      "[Epoch 107 Batch 10/244] avg loss 668.013, throughput 2.36967K wps\n",
      "[Epoch 107 Batch 20/244] avg loss 384.942, throughput 2.77006K wps\n",
      "[Epoch 107 Batch 30/244] avg loss 230.584, throughput 2.89856K wps\n",
      "[Epoch 107 Batch 40/244] avg loss 271.721, throughput 3.83142K wps\n",
      "[Epoch 107 Batch 50/244] avg loss 170.139, throughput 3.937K wps\n",
      "[Epoch 107 Batch 60/244] avg loss 719.899, throughput 2.57069K wps\n",
      "[Epoch 107 Batch 70/244] avg loss 240.25, throughput 3.22579K wps\n",
      "[Epoch 107 Batch 80/244] avg loss 141.809, throughput 3.64965K wps\n",
      "[Epoch 107 Batch 90/244] avg loss 236.1, throughput 2.6738K wps\n",
      "[Epoch 107 Batch 100/244] avg loss 168.966, throughput 3.62317K wps\n",
      "[Epoch 107 Batch 110/244] avg loss 436.681, throughput 2.77008K wps\n",
      "[Epoch 107 Batch 120/244] avg loss 186.057, throughput 3.05811K wps\n",
      "[Epoch 107 Batch 130/244] avg loss 182.63, throughput 3.24675K wps\n",
      "[Epoch 107 Batch 140/244] avg loss 236.976, throughput 2.87356K wps\n",
      "[Epoch 107 Batch 150/244] avg loss 584.651, throughput 2.42718K wps\n",
      "[Epoch 107 Batch 160/244] avg loss 195.066, throughput 3.42465K wps\n",
      "[Epoch 107 Batch 170/244] avg loss 254.346, throughput 2.78552K wps\n",
      "[Epoch 107 Batch 180/244] avg loss 217.991, throughput 2.35294K wps\n",
      "[Epoch 107 Batch 190/244] avg loss 165.361, throughput 2.43309K wps\n",
      "[Epoch 107 Batch 200/244] avg loss 358.512, throughput 2.47524K wps\n",
      "[Epoch 107 Batch 210/244] avg loss 248.533, throughput 2.89854K wps\n",
      "[Epoch 107 Batch 220/244] avg loss 195.34, throughput 3.1056K wps\n",
      "[Epoch 107 Batch 230/244] avg loss 239.55, throughput 2.65957K wps\n",
      "[Epoch 107 Batch 240/244] avg loss 227.866, throughput 2.65957K wps\n",
      "[Epoch 107] train avg loss 297.432, train avg r2 0.819823,throughput 2.8689K wps\n",
      "learning rate: 9.765625e-07\n",
      "[Epoch 108 Batch 10/244] avg loss 616.92, throughput 2.36966K wps\n",
      "[Epoch 108 Batch 20/244] avg loss 402.508, throughput 2.77009K wps\n",
      "[Epoch 108 Batch 30/244] avg loss 209.387, throughput 2.91545K wps\n",
      "[Epoch 108 Batch 40/244] avg loss 271.302, throughput 3.83141K wps\n",
      "[Epoch 108 Batch 50/244] avg loss 175.987, throughput 3.93703K wps\n",
      "[Epoch 108 Batch 60/244] avg loss 777.033, throughput 2.57069K wps\n",
      "[Epoch 108 Batch 70/244] avg loss 259.413, throughput 3.20512K wps\n",
      "[Epoch 108 Batch 80/244] avg loss 137.92, throughput 3.64966K wps\n",
      "[Epoch 108 Batch 90/244] avg loss 246.077, throughput 2.68096K wps\n",
      "[Epoch 108 Batch 100/244] avg loss 175.541, throughput 3.62318K wps\n",
      "[Epoch 108 Batch 110/244] avg loss 442.81, throughput 2.77008K wps\n",
      "[Epoch 108 Batch 120/244] avg loss 181.683, throughput 3.04878K wps\n",
      "[Epoch 108 Batch 130/244] avg loss 180.28, throughput 3.25731K wps\n",
      "[Epoch 108 Batch 140/244] avg loss 232.686, throughput 2.88185K wps\n",
      "[Epoch 108 Batch 150/244] avg loss 617.98, throughput 2.43902K wps\n",
      "[Epoch 108 Batch 160/244] avg loss 208.879, throughput 3.41297K wps\n",
      "[Epoch 108 Batch 170/244] avg loss 239.048, throughput 2.79328K wps\n",
      "[Epoch 108 Batch 180/244] avg loss 224.234, throughput 2.34743K wps\n",
      "[Epoch 108 Batch 190/244] avg loss 159.296, throughput 2.43309K wps\n",
      "[Epoch 108 Batch 200/244] avg loss 397.49, throughput 2.46914K wps\n",
      "[Epoch 108 Batch 210/244] avg loss 252.027, throughput 2.89854K wps\n",
      "[Epoch 108 Batch 220/244] avg loss 179.2, throughput 3.10559K wps\n",
      "[Epoch 108 Batch 230/244] avg loss 216.882, throughput 2.65252K wps\n",
      "[Epoch 108 Batch 240/244] avg loss 240.213, throughput 2.65957K wps\n",
      "[Epoch 108] train avg loss 300.971, train avg r2 0.812898,throughput 2.86924K wps\n",
      "learning rate: 9.765625e-07\n",
      "[Epoch 109 Batch 10/244] avg loss 654.452, throughput 2.36968K wps\n",
      "[Epoch 109 Batch 20/244] avg loss 393.752, throughput 2.77008K wps\n",
      "[Epoch 109 Batch 30/244] avg loss 202.067, throughput 2.91542K wps\n",
      "[Epoch 109 Batch 40/244] avg loss 257.736, throughput 3.81683K wps\n",
      "[Epoch 109 Batch 50/244] avg loss 166.725, throughput 3.90627K wps\n",
      "[Epoch 109 Batch 60/244] avg loss 766.576, throughput 2.5641K wps\n",
      "[Epoch 109 Batch 70/244] avg loss 281.749, throughput 3.20512K wps\n",
      "[Epoch 109 Batch 80/244] avg loss 134.052, throughput 3.66302K wps\n",
      "[Epoch 109 Batch 90/244] avg loss 241.129, throughput 2.68097K wps\n",
      "[Epoch 109 Batch 100/244] avg loss 164.74, throughput 3.64964K wps\n",
      "[Epoch 109 Batch 110/244] avg loss 452.297, throughput 2.77007K wps\n",
      "[Epoch 109 Batch 120/244] avg loss 189.548, throughput 3.04876K wps\n",
      "[Epoch 109 Batch 130/244] avg loss 182.688, throughput 3.25734K wps\n",
      "[Epoch 109 Batch 140/244] avg loss 241.22, throughput 2.88184K wps\n",
      "[Epoch 109 Batch 150/244] avg loss 600.225, throughput 2.43902K wps\n",
      "[Epoch 109 Batch 160/244] avg loss 212.707, throughput 3.41297K wps\n",
      "[Epoch 109 Batch 170/244] avg loss 235.013, throughput 2.7933K wps\n",
      "[Epoch 109 Batch 180/244] avg loss 207.601, throughput 2.34742K wps\n",
      "[Epoch 109 Batch 190/244] avg loss 169.663, throughput 2.43308K wps\n",
      "[Epoch 109 Batch 200/244] avg loss 400.437, throughput 2.46915K wps\n",
      "[Epoch 109 Batch 210/244] avg loss 257.241, throughput 2.89854K wps\n",
      "[Epoch 109 Batch 220/244] avg loss 176.248, throughput 3.1056K wps\n",
      "[Epoch 109 Batch 230/244] avg loss 222.397, throughput 2.65957K wps\n",
      "[Epoch 109 Batch 240/244] avg loss 240.056, throughput 2.65956K wps\n",
      "[Epoch 109] train avg loss 302.032, train avg r2 0.818696,throughput 2.86924K wps\n",
      "learning rate: 9.765625e-07\n",
      "[Epoch 110 Batch 10/244] avg loss 632.226, throughput 2.36407K wps\n",
      "[Epoch 110 Batch 20/244] avg loss 425.72, throughput 2.77008K wps\n",
      "[Epoch 110 Batch 30/244] avg loss 231.53, throughput 2.90698K wps\n",
      "[Epoch 110 Batch 40/244] avg loss 287.625, throughput 3.83141K wps\n",
      "[Epoch 110 Batch 50/244] avg loss 163.552, throughput 3.90623K wps\n",
      "[Epoch 110 Batch 60/244] avg loss 773.821, throughput 2.55756K wps\n",
      "[Epoch 110 Batch 70/244] avg loss 264.188, throughput 3.20511K wps\n",
      "[Epoch 110 Batch 80/244] avg loss 148.788, throughput 3.67649K wps\n",
      "[Epoch 110 Batch 90/244] avg loss 241.543, throughput 2.68097K wps\n",
      "[Epoch 110 Batch 100/244] avg loss 180.783, throughput 3.64961K wps\n",
      "[Epoch 110 Batch 110/244] avg loss 420.938, throughput 2.7701K wps\n",
      "[Epoch 110 Batch 120/244] avg loss 189.457, throughput 3.04878K wps\n",
      "[Epoch 110 Batch 130/244] avg loss 172.456, throughput 3.24676K wps\n",
      "[Epoch 110 Batch 140/244] avg loss 250.623, throughput 2.87356K wps\n",
      "[Epoch 110 Batch 150/244] avg loss 583.781, throughput 2.43902K wps\n",
      "[Epoch 110 Batch 160/244] avg loss 211.711, throughput 3.41298K wps\n",
      "[Epoch 110 Batch 170/244] avg loss 240.392, throughput 2.79329K wps\n",
      "[Epoch 110 Batch 180/244] avg loss 216.001, throughput 2.34742K wps\n",
      "[Epoch 110 Batch 190/244] avg loss 167.319, throughput 2.42719K wps\n",
      "[Epoch 110 Batch 200/244] avg loss 361.753, throughput 2.46914K wps\n",
      "[Epoch 110 Batch 210/244] avg loss 239.999, throughput 2.89854K wps\n",
      "[Epoch 110 Batch 220/244] avg loss 175.854, throughput 3.11527K wps\n",
      "[Epoch 110 Batch 230/244] avg loss 215.376, throughput 2.65251K wps\n",
      "[Epoch 110 Batch 240/244] avg loss 253.273, throughput 2.65958K wps\n",
      "[Epoch 110] train avg loss 301.914, train avg r2 0.811471,throughput 2.86755K wps\n",
      "learning rate: 4.8828125e-07\n",
      "[Epoch 111 Batch 10/244] avg loss 618.39, throughput 2.36966K wps\n",
      "[Epoch 111 Batch 20/244] avg loss 389.439, throughput 2.77007K wps\n",
      "[Epoch 111 Batch 30/244] avg loss 225.781, throughput 2.92399K wps\n",
      "[Epoch 111 Batch 40/244] avg loss 300.389, throughput 3.81678K wps\n",
      "[Epoch 111 Batch 50/244] avg loss 159.158, throughput 3.93702K wps\n",
      "[Epoch 111 Batch 60/244] avg loss 747.563, throughput 2.56411K wps\n",
      "[Epoch 111 Batch 70/244] avg loss 251.431, throughput 3.21541K wps\n",
      "[Epoch 111 Batch 80/244] avg loss 144.662, throughput 3.66301K wps\n",
      "[Epoch 111 Batch 90/244] avg loss 222.171, throughput 2.68097K wps\n",
      "[Epoch 111 Batch 100/244] avg loss 169.261, throughput 3.63635K wps\n",
      "[Epoch 111 Batch 110/244] avg loss 426.041, throughput 2.76244K wps\n",
      "[Epoch 111 Batch 120/244] avg loss 195.282, throughput 3.04879K wps\n",
      "[Epoch 111 Batch 130/244] avg loss 176.512, throughput 3.2573K wps\n",
      "[Epoch 111 Batch 140/244] avg loss 244.311, throughput 2.88185K wps\n",
      "[Epoch 111 Batch 150/244] avg loss 594.938, throughput 2.43902K wps\n",
      "[Epoch 111 Batch 160/244] avg loss 216.023, throughput 3.41295K wps\n",
      "[Epoch 111 Batch 170/244] avg loss 250.542, throughput 2.7933K wps\n",
      "[Epoch 111 Batch 180/244] avg loss 218.248, throughput 2.34741K wps\n",
      "[Epoch 111 Batch 190/244] avg loss 168.315, throughput 2.4331K wps\n",
      "[Epoch 111 Batch 200/244] avg loss 381.933, throughput 2.47524K wps\n",
      "[Epoch 111 Batch 210/244] avg loss 231.141, throughput 2.89017K wps\n",
      "[Epoch 111 Batch 220/244] avg loss 189.823, throughput 3.10558K wps\n",
      "[Epoch 111 Batch 230/244] avg loss 240.346, throughput 2.65958K wps\n",
      "[Epoch 111 Batch 240/244] avg loss 235.159, throughput 2.65957K wps\n",
      "[Epoch 111] train avg loss 299.4, train avg r2 0.81429,throughput 2.8689K wps\n",
      "learning rate: 4.8828125e-07\n",
      "[Epoch 112 Batch 10/244] avg loss 615.728, throughput 2.36968K wps\n",
      "[Epoch 112 Batch 20/244] avg loss 372.429, throughput 2.76243K wps\n",
      "[Epoch 112 Batch 30/244] avg loss 197.884, throughput 2.91545K wps\n",
      "[Epoch 112 Batch 40/244] avg loss 285.62, throughput 3.81679K wps\n",
      "[Epoch 112 Batch 50/244] avg loss 160.636, throughput 3.92157K wps\n",
      "[Epoch 112 Batch 60/244] avg loss 820.92, throughput 2.56411K wps\n",
      "[Epoch 112 Batch 70/244] avg loss 233.543, throughput 3.20512K wps\n",
      "[Epoch 112 Batch 80/244] avg loss 132.498, throughput 3.66303K wps\n",
      "[Epoch 112 Batch 90/244] avg loss 221.663, throughput 2.68817K wps\n",
      "[Epoch 112 Batch 100/244] avg loss 167.293, throughput 3.62318K wps\n",
      "[Epoch 112 Batch 110/244] avg loss 424.089, throughput 2.77778K wps\n",
      "[Epoch 112 Batch 120/244] avg loss 179.902, throughput 3.04877K wps\n",
      "[Epoch 112 Batch 130/244] avg loss 177.884, throughput 3.25734K wps\n",
      "[Epoch 112 Batch 140/244] avg loss 218.333, throughput 2.88184K wps\n",
      "[Epoch 112 Batch 150/244] avg loss 568.692, throughput 2.43902K wps\n",
      "[Epoch 112 Batch 160/244] avg loss 198.047, throughput 3.40136K wps\n",
      "[Epoch 112 Batch 170/244] avg loss 238.585, throughput 2.78553K wps\n",
      "[Epoch 112 Batch 180/244] avg loss 204.938, throughput 2.34741K wps\n",
      "[Epoch 112 Batch 190/244] avg loss 167.48, throughput 2.43309K wps\n",
      "[Epoch 112 Batch 200/244] avg loss 387.142, throughput 2.47524K wps\n",
      "[Epoch 112 Batch 210/244] avg loss 244.426, throughput 2.89018K wps\n",
      "[Epoch 112 Batch 220/244] avg loss 199.573, throughput 3.10559K wps\n",
      "[Epoch 112 Batch 230/244] avg loss 226.727, throughput 2.65251K wps\n",
      "[Epoch 112 Batch 240/244] avg loss 227.065, throughput 2.65253K wps\n",
      "[Epoch 112] train avg loss 293.988, train avg r2 0.816659,throughput 2.86823K wps\n",
      "learning rate: 4.8828125e-07\n",
      "[Epoch 113 Batch 10/244] avg loss 594.542, throughput 2.36968K wps\n",
      "[Epoch 113 Batch 20/244] avg loss 397.17, throughput 2.76244K wps\n",
      "[Epoch 113 Batch 30/244] avg loss 238.675, throughput 2.91545K wps\n",
      "[Epoch 113 Batch 40/244] avg loss 292.209, throughput 3.83137K wps\n",
      "[Epoch 113 Batch 50/244] avg loss 176.195, throughput 3.93701K wps\n",
      "[Epoch 113 Batch 60/244] avg loss 768.773, throughput 2.5641K wps\n",
      "[Epoch 113 Batch 70/244] avg loss 243.771, throughput 3.20513K wps\n",
      "[Epoch 113 Batch 80/244] avg loss 139.505, throughput 3.64968K wps\n",
      "[Epoch 113 Batch 90/244] avg loss 242.682, throughput 2.68097K wps\n",
      "[Epoch 113 Batch 100/244] avg loss 179.704, throughput 3.64964K wps\n",
      "[Epoch 113 Batch 110/244] avg loss 460.064, throughput 2.77008K wps\n",
      "[Epoch 113 Batch 120/244] avg loss 183.049, throughput 3.03952K wps\n",
      "[Epoch 113 Batch 130/244] avg loss 166.219, throughput 3.25732K wps\n",
      "[Epoch 113 Batch 140/244] avg loss 237.161, throughput 2.88185K wps\n",
      "[Epoch 113 Batch 150/244] avg loss 606.796, throughput 2.43902K wps\n",
      "[Epoch 113 Batch 160/244] avg loss 190.854, throughput 3.42463K wps\n",
      "[Epoch 113 Batch 170/244] avg loss 233.314, throughput 2.7933K wps\n",
      "[Epoch 113 Batch 180/244] avg loss 224.175, throughput 2.34742K wps\n",
      "[Epoch 113 Batch 190/244] avg loss 172.725, throughput 2.42719K wps\n",
      "[Epoch 113 Batch 200/244] avg loss 367.067, throughput 2.47524K wps\n",
      "[Epoch 113 Batch 210/244] avg loss 246.968, throughput 2.88184K wps\n",
      "[Epoch 113 Batch 220/244] avg loss 186.01, throughput 3.09599K wps\n",
      "[Epoch 113 Batch 230/244] avg loss 226.777, throughput 2.65251K wps\n",
      "[Epoch 113 Batch 240/244] avg loss 256.485, throughput 2.65252K wps\n",
      "[Epoch 113] train avg loss 300.697, train avg r2 0.812721,throughput 2.86722K wps\n",
      "learning rate: 4.8828125e-07\n",
      "[Epoch 114 Batch 10/244] avg loss 702.964, throughput 2.37529K wps\n",
      "[Epoch 114 Batch 20/244] avg loss 406.916, throughput 2.77009K wps\n",
      "[Epoch 114 Batch 30/244] avg loss 221.066, throughput 2.91543K wps\n",
      "[Epoch 114 Batch 40/244] avg loss 295.983, throughput 3.81679K wps\n",
      "[Epoch 114 Batch 50/244] avg loss 172.97, throughput 3.93703K wps\n",
      "[Epoch 114 Batch 60/244] avg loss 761.062, throughput 2.57069K wps\n",
      "[Epoch 114 Batch 70/244] avg loss 279.918, throughput 3.20513K wps\n",
      "[Epoch 114 Batch 80/244] avg loss 133.268, throughput 3.64964K wps\n",
      "[Epoch 114 Batch 90/244] avg loss 230.262, throughput 2.68097K wps\n",
      "[Epoch 114 Batch 100/244] avg loss 170.453, throughput 3.63635K wps\n",
      "[Epoch 114 Batch 110/244] avg loss 462.028, throughput 2.77777K wps\n",
      "[Epoch 114 Batch 120/244] avg loss 186.623, throughput 3.04879K wps\n",
      "[Epoch 114 Batch 130/244] avg loss 176.89, throughput 3.25732K wps\n",
      "[Epoch 114 Batch 140/244] avg loss 249.473, throughput 2.87355K wps\n",
      "[Epoch 114 Batch 150/244] avg loss 616.292, throughput 2.42719K wps\n",
      "[Epoch 114 Batch 160/244] avg loss 209.497, throughput 3.42467K wps\n",
      "[Epoch 114 Batch 170/244] avg loss 251.2, throughput 2.79328K wps\n",
      "[Epoch 114 Batch 180/244] avg loss 212.046, throughput 2.34193K wps\n",
      "[Epoch 114 Batch 190/244] avg loss 169.647, throughput 2.42718K wps\n",
      "[Epoch 114 Batch 200/244] avg loss 364.244, throughput 2.47525K wps\n",
      "[Epoch 114 Batch 210/244] avg loss 235.749, throughput 2.89854K wps\n",
      "[Epoch 114 Batch 220/244] avg loss 187.606, throughput 3.11527K wps\n",
      "[Epoch 114 Batch 230/244] avg loss 222.024, throughput 2.65252K wps\n",
      "[Epoch 114 Batch 240/244] avg loss 245.76, throughput 2.65252K wps\n",
      "[Epoch 114] train avg loss 306.269, train avg r2 0.81776,throughput 2.86924K wps\n",
      "learning rate: 4.8828125e-07\n",
      "[Epoch 115 Batch 10/244] avg loss 629.392, throughput 2.3753K wps\n",
      "[Epoch 115 Batch 20/244] avg loss 384.248, throughput 2.76243K wps\n",
      "[Epoch 115 Batch 30/244] avg loss 215.688, throughput 2.91545K wps\n",
      "[Epoch 115 Batch 40/244] avg loss 308.779, throughput 3.81679K wps\n",
      "[Epoch 115 Batch 50/244] avg loss 168.097, throughput 3.90625K wps\n",
      "[Epoch 115 Batch 60/244] avg loss 734.32, throughput 2.57069K wps\n",
      "[Epoch 115 Batch 70/244] avg loss 247.391, throughput 3.21545K wps\n",
      "[Epoch 115 Batch 80/244] avg loss 150.836, throughput 3.64964K wps\n",
      "[Epoch 115 Batch 90/244] avg loss 211.588, throughput 2.68817K wps\n",
      "[Epoch 115 Batch 100/244] avg loss 169.02, throughput 3.63636K wps\n",
      "[Epoch 115 Batch 110/244] avg loss 463.258, throughput 2.77009K wps\n",
      "[Epoch 115 Batch 120/244] avg loss 188.911, throughput 3.04878K wps\n",
      "[Epoch 115 Batch 130/244] avg loss 175.434, throughput 3.2573K wps\n",
      "[Epoch 115 Batch 140/244] avg loss 228.528, throughput 2.88186K wps\n",
      "[Epoch 115 Batch 150/244] avg loss 601.107, throughput 2.43902K wps\n",
      "[Epoch 115 Batch 160/244] avg loss 199.385, throughput 3.41296K wps\n",
      "[Epoch 115 Batch 170/244] avg loss 231.288, throughput 2.7933K wps\n",
      "[Epoch 115 Batch 180/244] avg loss 216.656, throughput 2.34193K wps\n",
      "[Epoch 115 Batch 190/244] avg loss 170.329, throughput 2.43308K wps\n",
      "[Epoch 115 Batch 200/244] avg loss 358.616, throughput 2.46306K wps\n",
      "[Epoch 115 Batch 210/244] avg loss 226.935, throughput 2.89017K wps\n",
      "[Epoch 115 Batch 220/244] avg loss 191.896, throughput 3.12499K wps\n",
      "[Epoch 115 Batch 230/244] avg loss 225.776, throughput 2.65957K wps\n",
      "[Epoch 115 Batch 240/244] avg loss 230.785, throughput 2.45098K wps\n",
      "[Epoch 115] train avg loss 296.903, train avg r2 0.815605,throughput 2.85781K wps\n",
      "learning rate: 4.8828125e-07\n",
      "[Epoch 116 Batch 10/244] avg loss 606.39, throughput 2.36967K wps\n",
      "[Epoch 116 Batch 20/244] avg loss 408.904, throughput 2.77777K wps\n",
      "[Epoch 116 Batch 30/244] avg loss 222.252, throughput 2.91543K wps\n",
      "[Epoch 116 Batch 40/244] avg loss 271.94, throughput 3.86101K wps\n",
      "[Epoch 116 Batch 50/244] avg loss 164.203, throughput 3.95256K wps\n",
      "[Epoch 116 Batch 60/244] avg loss 764.995, throughput 2.56411K wps\n",
      "[Epoch 116 Batch 70/244] avg loss 263.458, throughput 3.22579K wps\n",
      "[Epoch 116 Batch 80/244] avg loss 147.048, throughput 3.66301K wps\n",
      "[Epoch 116 Batch 90/244] avg loss 226.168, throughput 2.68816K wps\n",
      "[Epoch 116 Batch 100/244] avg loss 172.38, throughput 3.6496K wps\n",
      "[Epoch 116 Batch 110/244] avg loss 428.004, throughput 2.77778K wps\n",
      "[Epoch 116 Batch 120/244] avg loss 198.079, throughput 3.04878K wps\n",
      "[Epoch 116 Batch 130/244] avg loss 173.468, throughput 3.25733K wps\n",
      "[Epoch 116 Batch 140/244] avg loss 242.258, throughput 2.87356K wps\n",
      "[Epoch 116 Batch 150/244] avg loss 594.024, throughput 2.43308K wps\n",
      "[Epoch 116 Batch 160/244] avg loss 210.304, throughput 3.41297K wps\n",
      "[Epoch 116 Batch 170/244] avg loss 238.133, throughput 2.78551K wps\n",
      "[Epoch 116 Batch 180/244] avg loss 216.289, throughput 2.34742K wps\n",
      "[Epoch 116 Batch 190/244] avg loss 165.868, throughput 2.43308K wps\n",
      "[Epoch 116 Batch 200/244] avg loss 373.827, throughput 2.47526K wps\n",
      "[Epoch 116 Batch 210/244] avg loss 238.838, throughput 2.89854K wps\n",
      "[Epoch 116 Batch 220/244] avg loss 169.038, throughput 3.10559K wps\n",
      "[Epoch 116 Batch 230/244] avg loss 237.878, throughput 2.65958K wps\n",
      "[Epoch 116 Batch 240/244] avg loss 219.592, throughput 2.65251K wps\n",
      "[Epoch 116] train avg loss 296.671, train avg r2 0.820004,throughput 2.86991K wps\n",
      "learning rate: 4.8828125e-07\n",
      "[Epoch 117 Batch 10/244] avg loss 649.389, throughput 2.36966K wps\n",
      "[Epoch 117 Batch 20/244] avg loss 380.845, throughput 2.77777K wps\n",
      "[Epoch 117 Batch 30/244] avg loss 221.878, throughput 2.90697K wps\n",
      "[Epoch 117 Batch 40/244] avg loss 286.849, throughput 3.84616K wps\n",
      "[Epoch 117 Batch 50/244] avg loss 164.329, throughput 3.93702K wps\n",
      "[Epoch 117 Batch 60/244] avg loss 746.346, throughput 2.55755K wps\n",
      "[Epoch 117 Batch 70/244] avg loss 239.444, throughput 3.21541K wps\n",
      "[Epoch 117 Batch 80/244] avg loss 132.338, throughput 3.66302K wps\n",
      "[Epoch 117 Batch 90/244] avg loss 207.391, throughput 2.68095K wps\n",
      "[Epoch 117 Batch 100/244] avg loss 179.774, throughput 3.6101K wps\n",
      "[Epoch 117 Batch 110/244] avg loss 438.621, throughput 2.76246K wps\n",
      "[Epoch 117 Batch 120/244] avg loss 195.07, throughput 3.0581K wps\n",
      "[Epoch 117 Batch 130/244] avg loss 174.93, throughput 3.21544K wps\n",
      "[Epoch 117 Batch 140/244] avg loss 221.198, throughput 2.89018K wps\n",
      "[Epoch 117 Batch 150/244] avg loss 598.346, throughput 2.43309K wps\n",
      "[Epoch 117 Batch 160/244] avg loss 208.636, throughput 3.40135K wps\n",
      "[Epoch 117 Batch 170/244] avg loss 237.797, throughput 2.78552K wps\n",
      "[Epoch 117 Batch 180/244] avg loss 209.474, throughput 2.34742K wps\n",
      "[Epoch 117 Batch 190/244] avg loss 173.428, throughput 2.43309K wps\n",
      "[Epoch 117 Batch 200/244] avg loss 370.39, throughput 2.47525K wps\n",
      "[Epoch 117 Batch 210/244] avg loss 239.254, throughput 2.90696K wps\n",
      "[Epoch 117 Batch 220/244] avg loss 190.988, throughput 3.12499K wps\n",
      "[Epoch 117 Batch 230/244] avg loss 232.589, throughput 2.65957K wps\n",
      "[Epoch 117 Batch 240/244] avg loss 238.777, throughput 2.65252K wps\n",
      "[Epoch 117] train avg loss 296.465, train avg r2 0.821048,throughput 2.86688K wps\n",
      "learning rate: 4.8828125e-07\n",
      "[Epoch 118 Batch 10/244] avg loss 615.019, throughput 2.36967K wps\n",
      "[Epoch 118 Batch 20/244] avg loss 388.896, throughput 2.76243K wps\n",
      "[Epoch 118 Batch 30/244] avg loss 234.318, throughput 2.92397K wps\n",
      "[Epoch 118 Batch 40/244] avg loss 278.558, throughput 3.8314K wps\n",
      "[Epoch 118 Batch 50/244] avg loss 163.674, throughput 3.92158K wps\n",
      "[Epoch 118 Batch 60/244] avg loss 741.135, throughput 2.5641K wps\n",
      "[Epoch 118 Batch 70/244] avg loss 247.365, throughput 3.20512K wps\n",
      "[Epoch 118 Batch 80/244] avg loss 143.538, throughput 3.64964K wps\n",
      "[Epoch 118 Batch 90/244] avg loss 217.42, throughput 2.67381K wps\n",
      "[Epoch 118 Batch 100/244] avg loss 170.738, throughput 3.63634K wps\n",
      "[Epoch 118 Batch 110/244] avg loss 442.135, throughput 2.7701K wps\n",
      "[Epoch 118 Batch 120/244] avg loss 180.552, throughput 3.03952K wps\n",
      "[Epoch 118 Batch 130/244] avg loss 163.828, throughput 3.25732K wps\n",
      "[Epoch 118 Batch 140/244] avg loss 223.427, throughput 2.88184K wps\n",
      "[Epoch 118 Batch 150/244] avg loss 620.701, throughput 2.43902K wps\n",
      "[Epoch 118 Batch 160/244] avg loss 203.032, throughput 3.42467K wps\n",
      "[Epoch 118 Batch 170/244] avg loss 215.476, throughput 2.80112K wps\n",
      "[Epoch 118 Batch 180/244] avg loss 199.762, throughput 2.34742K wps\n",
      "[Epoch 118 Batch 190/244] avg loss 158.935, throughput 2.43309K wps\n",
      "[Epoch 118 Batch 200/244] avg loss 373.643, throughput 2.48138K wps\n",
      "[Epoch 118 Batch 210/244] avg loss 242.52, throughput 2.89017K wps\n",
      "[Epoch 118 Batch 220/244] avg loss 173.062, throughput 3.11528K wps\n",
      "[Epoch 118 Batch 230/244] avg loss 221.303, throughput 2.65957K wps\n",
      "[Epoch 118 Batch 240/244] avg loss 240.371, throughput 2.65958K wps\n",
      "[Epoch 118] train avg loss 294.291, train avg r2 0.816867,throughput 2.86991K wps\n",
      "learning rate: 4.8828125e-07\n",
      "[Epoch 119 Batch 10/244] avg loss 636.203, throughput 2.29886K wps\n",
      "[Epoch 119 Batch 20/244] avg loss 412.868, throughput 2.77777K wps\n",
      "[Epoch 119 Batch 30/244] avg loss 213.72, throughput 2.849K wps\n",
      "[Epoch 119 Batch 40/244] avg loss 280.846, throughput 3.81678K wps\n",
      "[Epoch 119 Batch 50/244] avg loss 180.326, throughput 3.937K wps\n",
      "[Epoch 119 Batch 60/244] avg loss 724.901, throughput 2.5641K wps\n",
      "[Epoch 119 Batch 70/244] avg loss 251.642, throughput 3.10558K wps\n",
      "[Epoch 119 Batch 80/244] avg loss 140.612, throughput 3.66301K wps\n",
      "[Epoch 119 Batch 90/244] avg loss 210.262, throughput 2.67379K wps\n",
      "[Epoch 119 Batch 100/244] avg loss 161.136, throughput 3.62318K wps\n",
      "[Epoch 119 Batch 110/244] avg loss 461.266, throughput 2.76242K wps\n",
      "[Epoch 119 Batch 120/244] avg loss 176.922, throughput 3.03954K wps\n",
      "[Epoch 119 Batch 130/244] avg loss 179.752, throughput 3.24674K wps\n",
      "[Epoch 119 Batch 140/244] avg loss 238.799, throughput 2.89017K wps\n",
      "[Epoch 119 Batch 150/244] avg loss 578.5, throughput 2.43902K wps\n",
      "[Epoch 119 Batch 160/244] avg loss 193.69, throughput 3.42467K wps\n",
      "[Epoch 119 Batch 170/244] avg loss 234.896, throughput 2.7933K wps\n",
      "[Epoch 119 Batch 180/244] avg loss 200.524, throughput 2.34191K wps\n",
      "[Epoch 119 Batch 190/244] avg loss 163.715, throughput 2.43309K wps\n",
      "[Epoch 119 Batch 200/244] avg loss 362.143, throughput 2.47525K wps\n",
      "[Epoch 119 Batch 210/244] avg loss 232.18, throughput 2.89855K wps\n",
      "[Epoch 119 Batch 220/244] avg loss 183.25, throughput 3.1056K wps\n",
      "[Epoch 119 Batch 230/244] avg loss 220.25, throughput 2.65958K wps\n",
      "[Epoch 119 Batch 240/244] avg loss 239.337, throughput 2.65956K wps\n",
      "[Epoch 119] train avg loss 294.339, train avg r2 0.821051,throughput 2.85647K wps\n",
      "learning rate: 4.8828125e-07\n",
      "[Epoch 120 Batch 10/244] avg loss 646.58, throughput 2.36406K wps\n",
      "[Epoch 120 Batch 20/244] avg loss 393.575, throughput 2.76243K wps\n",
      "[Epoch 120 Batch 30/244] avg loss 234.662, throughput 2.91546K wps\n",
      "[Epoch 120 Batch 40/244] avg loss 279.964, throughput 3.84617K wps\n",
      "[Epoch 120 Batch 50/244] avg loss 151.006, throughput 3.95257K wps\n",
      "[Epoch 120 Batch 60/244] avg loss 798.277, throughput 2.57732K wps\n",
      "[Epoch 120 Batch 70/244] avg loss 244.716, throughput 3.19489K wps\n",
      "[Epoch 120 Batch 80/244] avg loss 147.285, throughput 3.66302K wps\n",
      "[Epoch 120 Batch 90/244] avg loss 230.469, throughput 2.68096K wps\n",
      "[Epoch 120 Batch 100/244] avg loss 182.828, throughput 3.62319K wps\n",
      "[Epoch 120 Batch 110/244] avg loss 449.847, throughput 2.77777K wps\n",
      "[Epoch 120 Batch 120/244] avg loss 187.255, throughput 3.04878K wps\n",
      "[Epoch 120 Batch 130/244] avg loss 172.089, throughput 3.26799K wps\n",
      "[Epoch 120 Batch 140/244] avg loss 229.696, throughput 2.87355K wps\n",
      "[Epoch 120 Batch 150/244] avg loss 590.843, throughput 2.43902K wps\n",
      "[Epoch 120 Batch 160/244] avg loss 210.189, throughput 3.41298K wps\n",
      "[Epoch 120 Batch 170/244] avg loss 233.436, throughput 2.79329K wps\n",
      "[Epoch 120 Batch 180/244] avg loss 210.663, throughput 2.35293K wps\n",
      "[Epoch 120 Batch 190/244] avg loss 155.264, throughput 2.43309K wps\n",
      "[Epoch 120 Batch 200/244] avg loss 379.459, throughput 2.47525K wps\n",
      "[Epoch 120 Batch 210/244] avg loss 248.942, throughput 2.89855K wps\n",
      "[Epoch 120 Batch 220/244] avg loss 168.405, throughput 3.10562K wps\n",
      "[Epoch 120 Batch 230/244] avg loss 228.56, throughput 2.65251K wps\n",
      "[Epoch 120 Batch 240/244] avg loss 225.132, throughput 2.65958K wps\n",
      "[Epoch 120] train avg loss 299.757, train avg r2 0.817433,throughput 2.8689K wps\n",
      "learning rate: 2.44140625e-07\n",
      "[Epoch 121 Batch 10/244] avg loss 620.758, throughput 2.36407K wps\n",
      "[Epoch 121 Batch 20/244] avg loss 369.52, throughput 2.77008K wps\n",
      "[Epoch 121 Batch 30/244] avg loss 222.631, throughput 2.92398K wps\n",
      "[Epoch 121 Batch 40/244] avg loss 301.247, throughput 3.83142K wps\n",
      "[Epoch 121 Batch 50/244] avg loss 174.848, throughput 3.93699K wps\n",
      "[Epoch 121 Batch 60/244] avg loss 728.408, throughput 2.5641K wps\n",
      "[Epoch 121 Batch 70/244] avg loss 249.611, throughput 3.20513K wps\n",
      "[Epoch 121 Batch 80/244] avg loss 135.842, throughput 3.67647K wps\n",
      "[Epoch 121 Batch 90/244] avg loss 248.615, throughput 2.6738K wps\n",
      "[Epoch 121 Batch 100/244] avg loss 163.625, throughput 3.61011K wps\n",
      "[Epoch 121 Batch 110/244] avg loss 428.678, throughput 2.77777K wps\n",
      "[Epoch 121 Batch 120/244] avg loss 181.602, throughput 3.03031K wps\n",
      "[Epoch 121 Batch 130/244] avg loss 171.833, throughput 3.0864K wps\n",
      "[Epoch 121 Batch 140/244] avg loss 217.014, throughput 2.80112K wps\n",
      "[Epoch 121 Batch 150/244] avg loss 594.18, throughput 2.35294K wps\n",
      "[Epoch 121 Batch 160/244] avg loss 201.786, throughput 3.41294K wps\n",
      "[Epoch 121 Batch 170/244] avg loss 221.198, throughput 2.77778K wps\n",
      "[Epoch 121 Batch 180/244] avg loss 210.128, throughput 2.33644K wps\n",
      "[Epoch 121 Batch 190/244] avg loss 162.464, throughput 2.42132K wps\n",
      "[Epoch 121 Batch 200/244] avg loss 361.869, throughput 2.47524K wps\n",
      "[Epoch 121 Batch 210/244] avg loss 253.628, throughput 2.89016K wps\n",
      "[Epoch 121 Batch 220/244] avg loss 183.018, throughput 3.05811K wps\n",
      "[Epoch 121 Batch 230/244] avg loss 243.036, throughput 2.47524K wps\n",
      "[Epoch 121 Batch 240/244] avg loss 234.483, throughput 2.63852K wps\n",
      "[Epoch 121] train avg loss 294.511, train avg r2 0.814838,throughput 2.8382K wps\n",
      "learning rate: 2.44140625e-07\n",
      "[Epoch 122 Batch 10/244] avg loss 634.653, throughput 2.36967K wps\n",
      "[Epoch 122 Batch 20/244] avg loss 402.846, throughput 2.76243K wps\n",
      "[Epoch 122 Batch 30/244] avg loss 224.317, throughput 2.91545K wps\n",
      "[Epoch 122 Batch 40/244] avg loss 285.3, throughput 3.81678K wps\n",
      "[Epoch 122 Batch 50/244] avg loss 167.331, throughput 3.937K wps\n",
      "[Epoch 122 Batch 60/244] avg loss 731.297, throughput 2.56412K wps\n",
      "[Epoch 122 Batch 70/244] avg loss 254.796, throughput 3.20512K wps\n",
      "[Epoch 122 Batch 80/244] avg loss 142.332, throughput 3.663K wps\n",
      "[Epoch 122 Batch 90/244] avg loss 231.491, throughput 2.67379K wps\n",
      "[Epoch 122 Batch 100/244] avg loss 166.884, throughput 3.6232K wps\n",
      "[Epoch 122 Batch 110/244] avg loss 454.407, throughput 2.77776K wps\n",
      "[Epoch 122 Batch 120/244] avg loss 194.034, throughput 3.0581K wps\n",
      "[Epoch 122 Batch 130/244] avg loss 170.257, throughput 3.24676K wps\n",
      "[Epoch 122 Batch 140/244] avg loss 225.346, throughput 2.88185K wps\n",
      "[Epoch 122 Batch 150/244] avg loss 591.057, throughput 2.43309K wps\n",
      "[Epoch 122 Batch 160/244] avg loss 208.925, throughput 3.41296K wps\n",
      "[Epoch 122 Batch 170/244] avg loss 232.987, throughput 2.7933K wps\n",
      "[Epoch 122 Batch 180/244] avg loss 204.233, throughput 2.34742K wps\n",
      "[Epoch 122 Batch 190/244] avg loss 171.375, throughput 2.43309K wps\n",
      "[Epoch 122 Batch 200/244] avg loss 380.823, throughput 2.46914K wps\n",
      "[Epoch 122 Batch 210/244] avg loss 224.993, throughput 2.89854K wps\n",
      "[Epoch 122 Batch 220/244] avg loss 181.938, throughput 3.11527K wps\n",
      "[Epoch 122 Batch 230/244] avg loss 221.209, throughput 2.65251K wps\n",
      "[Epoch 122 Batch 240/244] avg loss 256.668, throughput 2.65252K wps\n",
      "[Epoch 122] train avg loss 297.661, train avg r2 0.817099,throughput 2.86856K wps\n",
      "learning rate: 2.44140625e-07\n",
      "[Epoch 123 Batch 10/244] avg loss 575.485, throughput 2.35849K wps\n",
      "[Epoch 123 Batch 20/244] avg loss 415.702, throughput 2.77008K wps\n",
      "[Epoch 123 Batch 30/244] avg loss 223.318, throughput 2.91545K wps\n",
      "[Epoch 123 Batch 40/244] avg loss 282.384, throughput 3.84617K wps\n",
      "[Epoch 123 Batch 50/244] avg loss 180.842, throughput 3.95259K wps\n",
      "[Epoch 123 Batch 60/244] avg loss 737.64, throughput 2.55754K wps\n",
      "[Epoch 123 Batch 70/244] avg loss 245.9, throughput 3.21543K wps\n",
      "[Epoch 123 Batch 80/244] avg loss 135.607, throughput 3.64964K wps\n",
      "[Epoch 123 Batch 90/244] avg loss 241.084, throughput 2.68816K wps\n",
      "[Epoch 123 Batch 100/244] avg loss 180.817, throughput 3.62317K wps\n",
      "[Epoch 123 Batch 110/244] avg loss 437.311, throughput 2.77779K wps\n",
      "[Epoch 123 Batch 120/244] avg loss 178.242, throughput 3.04878K wps\n",
      "[Epoch 123 Batch 130/244] avg loss 170.093, throughput 3.25732K wps\n",
      "[Epoch 123 Batch 140/244] avg loss 243.183, throughput 2.88183K wps\n",
      "[Epoch 123 Batch 150/244] avg loss 591.115, throughput 2.4331K wps\n",
      "[Epoch 123 Batch 160/244] avg loss 197.843, throughput 3.41297K wps\n",
      "[Epoch 123 Batch 170/244] avg loss 226.5, throughput 2.79328K wps\n",
      "[Epoch 123 Batch 180/244] avg loss 218.819, throughput 2.34743K wps\n",
      "[Epoch 123 Batch 190/244] avg loss 156.843, throughput 2.42718K wps\n",
      "[Epoch 123 Batch 200/244] avg loss 362.212, throughput 2.47526K wps\n",
      "[Epoch 123 Batch 210/244] avg loss 268.701, throughput 2.89854K wps\n",
      "[Epoch 123 Batch 220/244] avg loss 179.411, throughput 3.11528K wps\n",
      "[Epoch 123 Batch 230/244] avg loss 219.868, throughput 2.65956K wps\n",
      "[Epoch 123 Batch 240/244] avg loss 253.678, throughput 2.65957K wps\n",
      "[Epoch 123] train avg loss 295.452, train avg r2 0.819658,throughput 2.8689K wps\n",
      "learning rate: 2.44140625e-07\n",
      "[Epoch 124 Batch 10/244] avg loss 639.029, throughput 2.36966K wps\n",
      "[Epoch 124 Batch 20/244] avg loss 395.889, throughput 2.76243K wps\n",
      "[Epoch 124 Batch 30/244] avg loss 225.065, throughput 2.90698K wps\n",
      "[Epoch 124 Batch 40/244] avg loss 297.771, throughput 3.84614K wps\n",
      "[Epoch 124 Batch 50/244] avg loss 167.24, throughput 3.93703K wps\n",
      "[Epoch 124 Batch 60/244] avg loss 746.721, throughput 2.55754K wps\n",
      "[Epoch 124 Batch 70/244] avg loss 240.726, throughput 3.20513K wps\n",
      "[Epoch 124 Batch 80/244] avg loss 131.507, throughput 3.663K wps\n",
      "[Epoch 124 Batch 90/244] avg loss 229.838, throughput 2.68097K wps\n",
      "[Epoch 124 Batch 100/244] avg loss 169.057, throughput 3.63637K wps\n",
      "[Epoch 124 Batch 110/244] avg loss 456.562, throughput 2.76243K wps\n",
      "[Epoch 124 Batch 120/244] avg loss 193.048, throughput 3.0395K wps\n",
      "[Epoch 124 Batch 130/244] avg loss 177.149, throughput 3.25734K wps\n",
      "[Epoch 124 Batch 140/244] avg loss 225.923, throughput 2.88183K wps\n",
      "[Epoch 124 Batch 150/244] avg loss 623.987, throughput 2.44499K wps\n",
      "[Epoch 124 Batch 160/244] avg loss 212.438, throughput 3.41296K wps\n",
      "[Epoch 124 Batch 170/244] avg loss 224.198, throughput 2.7933K wps\n",
      "[Epoch 124 Batch 180/244] avg loss 204.943, throughput 2.34741K wps\n",
      "[Epoch 124 Batch 190/244] avg loss 177.063, throughput 2.4331K wps\n",
      "[Epoch 124 Batch 200/244] avg loss 385.377, throughput 2.47525K wps\n",
      "[Epoch 124 Batch 210/244] avg loss 246.731, throughput 2.89854K wps\n",
      "[Epoch 124 Batch 220/244] avg loss 175.667, throughput 3.10559K wps\n",
      "[Epoch 124 Batch 230/244] avg loss 235.515, throughput 2.65252K wps\n",
      "[Epoch 124 Batch 240/244] avg loss 230.135, throughput 2.65252K wps\n",
      "[Epoch 124] train avg loss 299.528, train avg r2 0.819808,throughput 2.86958K wps\n",
      "learning rate: 2.44140625e-07\n",
      "[Epoch 125 Batch 10/244] avg loss 581.488, throughput 2.36407K wps\n",
      "[Epoch 125 Batch 20/244] avg loss 370.176, throughput 2.77009K wps\n",
      "[Epoch 125 Batch 30/244] avg loss 221.182, throughput 2.91544K wps\n",
      "[Epoch 125 Batch 40/244] avg loss 278.841, throughput 3.83141K wps\n",
      "[Epoch 125 Batch 50/244] avg loss 173.133, throughput 3.92159K wps\n",
      "[Epoch 125 Batch 60/244] avg loss 755.588, throughput 2.5641K wps\n",
      "[Epoch 125 Batch 70/244] avg loss 244.471, throughput 3.20513K wps\n",
      "[Epoch 125 Batch 80/244] avg loss 143.293, throughput 3.663K wps\n",
      "[Epoch 125 Batch 90/244] avg loss 223.243, throughput 2.68097K wps\n",
      "[Epoch 125 Batch 100/244] avg loss 156.731, throughput 3.61011K wps\n",
      "[Epoch 125 Batch 110/244] avg loss 457.188, throughput 2.73224K wps\n",
      "[Epoch 125 Batch 120/244] avg loss 200.032, throughput 3.04877K wps\n",
      "[Epoch 125 Batch 130/244] avg loss 179.746, throughput 3.25731K wps\n",
      "[Epoch 125 Batch 140/244] avg loss 218.599, throughput 2.88185K wps\n",
      "[Epoch 125 Batch 150/244] avg loss 577.912, throughput 2.43309K wps\n",
      "[Epoch 125 Batch 160/244] avg loss 213.113, throughput 3.42465K wps\n",
      "[Epoch 125 Batch 170/244] avg loss 224.929, throughput 2.79328K wps\n",
      "[Epoch 125 Batch 180/244] avg loss 213.349, throughput 2.34743K wps\n",
      "[Epoch 125 Batch 190/244] avg loss 185.993, throughput 2.42719K wps\n",
      "[Epoch 125 Batch 200/244] avg loss 352.27, throughput 2.46914K wps\n",
      "[Epoch 125 Batch 210/244] avg loss 222.589, throughput 2.89855K wps\n",
      "[Epoch 125 Batch 220/244] avg loss 191.237, throughput 3.11525K wps\n",
      "[Epoch 125 Batch 230/244] avg loss 240.245, throughput 2.65959K wps\n",
      "[Epoch 125 Batch 240/244] avg loss 230.161, throughput 2.65958K wps\n",
      "[Epoch 125] train avg loss 293.299, train avg r2 0.817429,throughput 2.86688K wps\n",
      "learning rate: 2.44140625e-07\n",
      "[Epoch 126 Batch 10/244] avg loss 611.013, throughput 2.36966K wps\n",
      "[Epoch 126 Batch 20/244] avg loss 377.173, throughput 2.77009K wps\n",
      "[Epoch 126 Batch 30/244] avg loss 220.754, throughput 2.91545K wps\n",
      "[Epoch 126 Batch 40/244] avg loss 271.836, throughput 3.83143K wps\n",
      "[Epoch 126 Batch 50/244] avg loss 156.482, throughput 3.937K wps\n",
      "[Epoch 126 Batch 60/244] avg loss 737.334, throughput 2.5641K wps\n",
      "[Epoch 126 Batch 70/244] avg loss 242.15, throughput 3.21542K wps\n",
      "[Epoch 126 Batch 80/244] avg loss 134.988, throughput 3.663K wps\n",
      "[Epoch 126 Batch 90/244] avg loss 230.216, throughput 2.67379K wps\n",
      "[Epoch 126 Batch 100/244] avg loss 158.745, throughput 3.63635K wps\n",
      "[Epoch 126 Batch 110/244] avg loss 442.73, throughput 2.77008K wps\n",
      "[Epoch 126 Batch 120/244] avg loss 190.525, throughput 3.03952K wps\n",
      "[Epoch 126 Batch 130/244] avg loss 182.379, throughput 3.25732K wps\n",
      "[Epoch 126 Batch 140/244] avg loss 226.604, throughput 2.88184K wps\n",
      "[Epoch 126 Batch 150/244] avg loss 597.089, throughput 2.43309K wps\n",
      "[Epoch 126 Batch 160/244] avg loss 198.305, throughput 3.41296K wps\n",
      "[Epoch 126 Batch 170/244] avg loss 226.805, throughput 2.80899K wps\n",
      "[Epoch 126 Batch 180/244] avg loss 209.496, throughput 2.34192K wps\n",
      "[Epoch 126 Batch 190/244] avg loss 157.717, throughput 2.42719K wps\n",
      "[Epoch 126 Batch 200/244] avg loss 371.28, throughput 2.46913K wps\n",
      "[Epoch 126 Batch 210/244] avg loss 244.7, throughput 2.89854K wps\n",
      "[Epoch 126 Batch 220/244] avg loss 185.075, throughput 3.1056K wps\n",
      "[Epoch 126 Batch 230/244] avg loss 220.743, throughput 2.65957K wps\n",
      "[Epoch 126 Batch 240/244] avg loss 241.9, throughput 2.65253K wps\n",
      "[Epoch 126] train avg loss 292.237, train avg r2 0.820705,throughput 2.8689K wps\n",
      "learning rate: 2.44140625e-07\n",
      "[Epoch 127 Batch 10/244] avg loss 615.921, throughput 2.37529K wps\n",
      "[Epoch 127 Batch 20/244] avg loss 416.145, throughput 2.77008K wps\n",
      "[Epoch 127 Batch 30/244] avg loss 211.911, throughput 2.92397K wps\n",
      "[Epoch 127 Batch 40/244] avg loss 297.922, throughput 3.84618K wps\n",
      "[Epoch 127 Batch 50/244] avg loss 163.573, throughput 3.93703K wps\n",
      "[Epoch 127 Batch 60/244] avg loss 768.374, throughput 2.5707K wps\n",
      "[Epoch 127 Batch 70/244] avg loss 258.564, throughput 3.20512K wps\n",
      "[Epoch 127 Batch 80/244] avg loss 138.67, throughput 3.64964K wps\n",
      "[Epoch 127 Batch 90/244] avg loss 238.26, throughput 2.68096K wps\n",
      "[Epoch 127 Batch 100/244] avg loss 168.341, throughput 3.62318K wps\n",
      "[Epoch 127 Batch 110/244] avg loss 457.472, throughput 2.77008K wps\n",
      "[Epoch 127 Batch 120/244] avg loss 183.883, throughput 3.05811K wps\n",
      "[Epoch 127 Batch 130/244] avg loss 175.583, throughput 3.24675K wps\n",
      "[Epoch 127 Batch 140/244] avg loss 209.809, throughput 2.87357K wps\n",
      "[Epoch 127 Batch 150/244] avg loss 641.355, throughput 2.43309K wps\n",
      "[Epoch 127 Batch 160/244] avg loss 207.213, throughput 3.41298K wps\n",
      "[Epoch 127 Batch 170/244] avg loss 231.278, throughput 2.80112K wps\n",
      "[Epoch 127 Batch 180/244] avg loss 205.26, throughput 2.34742K wps\n",
      "[Epoch 127 Batch 190/244] avg loss 171.02, throughput 2.43309K wps\n",
      "[Epoch 127 Batch 200/244] avg loss 351.513, throughput 2.47525K wps\n",
      "[Epoch 127 Batch 210/244] avg loss 230.467, throughput 2.89854K wps\n",
      "[Epoch 127 Batch 220/244] avg loss 168.739, throughput 3.08643K wps\n",
      "[Epoch 127 Batch 230/244] avg loss 229.058, throughput 2.65251K wps\n",
      "[Epoch 127 Batch 240/244] avg loss 248.093, throughput 2.65956K wps\n",
      "[Epoch 127] train avg loss 299.17, train avg r2 0.814107,throughput 2.8689K wps\n",
      "learning rate: 2.44140625e-07\n",
      "[Epoch 128 Batch 10/244] avg loss 605.909, throughput 2.36967K wps\n",
      "[Epoch 128 Batch 20/244] avg loss 402.044, throughput 2.77776K wps\n",
      "[Epoch 128 Batch 30/244] avg loss 226.35, throughput 2.91547K wps\n",
      "[Epoch 128 Batch 40/244] avg loss 293.568, throughput 3.83141K wps\n",
      "[Epoch 128 Batch 50/244] avg loss 162.583, throughput 3.92157K wps\n",
      "[Epoch 128 Batch 60/244] avg loss 750.085, throughput 2.56411K wps\n",
      "[Epoch 128 Batch 70/244] avg loss 251.633, throughput 3.20512K wps\n",
      "[Epoch 128 Batch 80/244] avg loss 136.846, throughput 3.66301K wps\n",
      "[Epoch 128 Batch 90/244] avg loss 238.773, throughput 2.68096K wps\n",
      "[Epoch 128 Batch 100/244] avg loss 171.823, throughput 3.63636K wps\n",
      "[Epoch 128 Batch 110/244] avg loss 439.093, throughput 2.77009K wps\n",
      "[Epoch 128 Batch 120/244] avg loss 194.922, throughput 3.0581K wps\n",
      "[Epoch 128 Batch 130/244] avg loss 169.391, throughput 3.25733K wps\n",
      "[Epoch 128 Batch 140/244] avg loss 220.606, throughput 2.88182K wps\n",
      "[Epoch 128 Batch 150/244] avg loss 582.223, throughput 2.42719K wps\n",
      "[Epoch 128 Batch 160/244] avg loss 196.003, throughput 3.41297K wps\n",
      "[Epoch 128 Batch 170/244] avg loss 227.296, throughput 2.78551K wps\n",
      "[Epoch 128 Batch 180/244] avg loss 212.835, throughput 2.35294K wps\n",
      "[Epoch 128 Batch 190/244] avg loss 155.679, throughput 2.42718K wps\n",
      "[Epoch 128 Batch 200/244] avg loss 366.512, throughput 2.48137K wps\n",
      "[Epoch 128 Batch 210/244] avg loss 212.172, throughput 2.89019K wps\n",
      "[Epoch 128 Batch 220/244] avg loss 195.107, throughput 3.11527K wps\n",
      "[Epoch 128 Batch 230/244] avg loss 231.469, throughput 2.65957K wps\n",
      "[Epoch 128 Batch 240/244] avg loss 234.962, throughput 2.65957K wps\n",
      "[Epoch 128] train avg loss 293.544, train avg r2 0.8165,throughput 2.86958K wps\n",
      "learning rate: 2.44140625e-07\n",
      "[Epoch 129 Batch 10/244] avg loss 637.754, throughput 2.36966K wps\n",
      "[Epoch 129 Batch 20/244] avg loss 394.069, throughput 2.77008K wps\n",
      "[Epoch 129 Batch 30/244] avg loss 218.307, throughput 2.90699K wps\n",
      "[Epoch 129 Batch 40/244] avg loss 316.849, throughput 3.83141K wps\n",
      "[Epoch 129 Batch 50/244] avg loss 171.379, throughput 3.95256K wps\n",
      "[Epoch 129 Batch 60/244] avg loss 750.844, throughput 2.5641K wps\n",
      "[Epoch 129 Batch 70/244] avg loss 237.745, throughput 3.22581K wps\n",
      "[Epoch 129 Batch 80/244] avg loss 137.903, throughput 3.663K wps\n",
      "[Epoch 129 Batch 90/244] avg loss 225.576, throughput 2.67379K wps\n",
      "[Epoch 129 Batch 100/244] avg loss 173.273, throughput 3.62321K wps\n",
      "[Epoch 129 Batch 110/244] avg loss 382.272, throughput 2.77008K wps\n",
      "[Epoch 129 Batch 120/244] avg loss 200.454, throughput 3.04878K wps\n",
      "[Epoch 129 Batch 130/244] avg loss 179.59, throughput 3.25732K wps\n",
      "[Epoch 129 Batch 140/244] avg loss 227.047, throughput 2.89018K wps\n",
      "[Epoch 129 Batch 150/244] avg loss 585.877, throughput 2.4331K wps\n",
      "[Epoch 129 Batch 160/244] avg loss 215.342, throughput 3.41295K wps\n",
      "[Epoch 129 Batch 170/244] avg loss 237.583, throughput 2.79329K wps\n",
      "[Epoch 129 Batch 180/244] avg loss 211.369, throughput 2.34742K wps\n",
      "[Epoch 129 Batch 190/244] avg loss 162.195, throughput 2.42719K wps\n",
      "[Epoch 129 Batch 200/244] avg loss 387.647, throughput 2.46913K wps\n",
      "[Epoch 129 Batch 210/244] avg loss 236.247, throughput 2.89855K wps\n",
      "[Epoch 129 Batch 220/244] avg loss 183.927, throughput 3.10561K wps\n",
      "[Epoch 129 Batch 230/244] avg loss 226.007, throughput 2.66665K wps\n",
      "[Epoch 129 Batch 240/244] avg loss 229.878, throughput 2.65252K wps\n",
      "[Epoch 129] train avg loss 296.631, train avg r2 0.816598,throughput 2.86957K wps\n",
      "learning rate: 2.44140625e-07\n",
      "[Epoch 130 Batch 10/244] avg loss 602.558, throughput 2.36407K wps\n",
      "[Epoch 130 Batch 20/244] avg loss 392.613, throughput 2.76243K wps\n",
      "[Epoch 130 Batch 30/244] avg loss 227.997, throughput 2.91543K wps\n",
      "[Epoch 130 Batch 40/244] avg loss 293.209, throughput 3.83141K wps\n",
      "[Epoch 130 Batch 50/244] avg loss 168.751, throughput 3.95257K wps\n",
      "[Epoch 130 Batch 60/244] avg loss 722.599, throughput 2.5641K wps\n",
      "[Epoch 130 Batch 70/244] avg loss 254.048, throughput 3.19489K wps\n",
      "[Epoch 130 Batch 80/244] avg loss 135.033, throughput 3.63637K wps\n",
      "[Epoch 130 Batch 90/244] avg loss 228.234, throughput 2.68817K wps\n",
      "[Epoch 130 Batch 100/244] avg loss 172.769, throughput 3.64963K wps\n",
      "[Epoch 130 Batch 110/244] avg loss 421.462, throughput 2.77008K wps\n",
      "[Epoch 130 Batch 120/244] avg loss 184.019, throughput 3.04877K wps\n",
      "[Epoch 130 Batch 130/244] avg loss 167.423, throughput 3.25733K wps\n",
      "[Epoch 130 Batch 140/244] avg loss 231.848, throughput 2.89017K wps\n",
      "[Epoch 130 Batch 150/244] avg loss 614.167, throughput 2.43902K wps\n",
      "[Epoch 130 Batch 160/244] avg loss 205.671, throughput 3.40136K wps\n",
      "[Epoch 130 Batch 170/244] avg loss 237.922, throughput 2.80112K wps\n",
      "[Epoch 130 Batch 180/244] avg loss 209.178, throughput 2.34742K wps\n",
      "[Epoch 130 Batch 190/244] avg loss 166.589, throughput 2.43309K wps\n",
      "[Epoch 130 Batch 200/244] avg loss 370.723, throughput 2.47525K wps\n",
      "[Epoch 130 Batch 210/244] avg loss 226.221, throughput 2.89855K wps\n",
      "[Epoch 130 Batch 220/244] avg loss 176.464, throughput 3.10559K wps\n",
      "[Epoch 130 Batch 230/244] avg loss 229.625, throughput 2.66666K wps\n",
      "[Epoch 130 Batch 240/244] avg loss 254.907, throughput 2.65252K wps\n",
      "[Epoch 130] train avg loss 295.479, train avg r2 0.815112,throughput 2.86924K wps\n",
      "learning rate: 1.220703125e-07\n",
      "[Epoch 131 Batch 10/244] avg loss 636.919, throughput 2.3585K wps\n",
      "[Epoch 131 Batch 20/244] avg loss 421.833, throughput 2.77008K wps\n",
      "[Epoch 131 Batch 30/244] avg loss 215.692, throughput 2.91546K wps\n",
      "[Epoch 131 Batch 40/244] avg loss 266.494, throughput 3.80227K wps\n",
      "[Epoch 131 Batch 50/244] avg loss 169.072, throughput 3.937K wps\n",
      "[Epoch 131 Batch 60/244] avg loss 724.307, throughput 2.5641K wps\n",
      "[Epoch 131 Batch 70/244] avg loss 251.787, throughput 3.21542K wps\n",
      "[Epoch 131 Batch 80/244] avg loss 133.909, throughput 3.64965K wps\n",
      "[Epoch 131 Batch 90/244] avg loss 225.826, throughput 2.68094K wps\n",
      "[Epoch 131 Batch 100/244] avg loss 153.919, throughput 3.63635K wps\n",
      "[Epoch 131 Batch 110/244] avg loss 433.453, throughput 2.77007K wps\n",
      "[Epoch 131 Batch 120/244] avg loss 173.542, throughput 3.04878K wps\n",
      "[Epoch 131 Batch 130/244] avg loss 175.261, throughput 3.25731K wps\n",
      "[Epoch 131 Batch 140/244] avg loss 236.336, throughput 2.89018K wps\n",
      "[Epoch 131 Batch 150/244] avg loss 603.363, throughput 2.44498K wps\n",
      "[Epoch 131 Batch 160/244] avg loss 195.708, throughput 3.42464K wps\n",
      "[Epoch 131 Batch 170/244] avg loss 235.942, throughput 2.7933K wps\n",
      "[Epoch 131 Batch 180/244] avg loss 215.469, throughput 2.35294K wps\n",
      "[Epoch 131 Batch 190/244] avg loss 159.346, throughput 2.42718K wps\n",
      "[Epoch 131 Batch 200/244] avg loss 366.968, throughput 2.46914K wps\n",
      "[Epoch 131 Batch 210/244] avg loss 238.779, throughput 2.90698K wps\n",
      "[Epoch 131 Batch 220/244] avg loss 186.966, throughput 3.125K wps\n",
      "[Epoch 131 Batch 230/244] avg loss 247.891, throughput 2.66666K wps\n",
      "[Epoch 131 Batch 240/244] avg loss 228.828, throughput 2.65957K wps\n",
      "[Epoch 131] train avg loss 294.98, train avg r2 0.81929,throughput 2.86924K wps\n",
      "learning rate: 1.220703125e-07\n",
      "[Epoch 132 Batch 10/244] avg loss 595.748, throughput 2.36407K wps\n",
      "[Epoch 132 Batch 20/244] avg loss 402.87, throughput 2.77777K wps\n",
      "[Epoch 132 Batch 30/244] avg loss 218.7, throughput 2.91544K wps\n",
      "[Epoch 132 Batch 40/244] avg loss 305.211, throughput 3.83141K wps\n",
      "[Epoch 132 Batch 50/244] avg loss 168.447, throughput 3.96824K wps\n",
      "[Epoch 132 Batch 60/244] avg loss 734.775, throughput 2.5707K wps\n",
      "[Epoch 132 Batch 70/244] avg loss 242.471, throughput 3.20513K wps\n",
      "[Epoch 132 Batch 80/244] avg loss 142.332, throughput 3.64964K wps\n",
      "[Epoch 132 Batch 90/244] avg loss 211.347, throughput 2.68096K wps\n",
      "[Epoch 132 Batch 100/244] avg loss 181.809, throughput 3.62319K wps\n",
      "[Epoch 132 Batch 110/244] avg loss 495.787, throughput 2.77009K wps\n",
      "[Epoch 132 Batch 120/244] avg loss 180.562, throughput 3.0395K wps\n",
      "[Epoch 132 Batch 130/244] avg loss 178.059, throughput 3.24675K wps\n",
      "[Epoch 132 Batch 140/244] avg loss 207.705, throughput 2.88184K wps\n",
      "[Epoch 132 Batch 150/244] avg loss 611.336, throughput 2.43903K wps\n",
      "[Epoch 132 Batch 160/244] avg loss 189.285, throughput 3.42466K wps\n",
      "[Epoch 132 Batch 170/244] avg loss 227.63, throughput 2.78551K wps\n",
      "[Epoch 132 Batch 180/244] avg loss 199.234, throughput 2.33645K wps\n",
      "[Epoch 132 Batch 190/244] avg loss 169.634, throughput 2.43309K wps\n",
      "[Epoch 132 Batch 200/244] avg loss 352.004, throughput 2.46913K wps\n",
      "[Epoch 132 Batch 210/244] avg loss 232.819, throughput 2.89018K wps\n",
      "[Epoch 132 Batch 220/244] avg loss 180.035, throughput 3.09598K wps\n",
      "[Epoch 132 Batch 230/244] avg loss 234.567, throughput 2.65252K wps\n",
      "[Epoch 132 Batch 240/244] avg loss 244.869, throughput 2.6455K wps\n",
      "[Epoch 132] train avg loss 294.66, train avg r2 0.818059,throughput 2.86654K wps\n",
      "learning rate: 1.220703125e-07\n",
      "[Epoch 133 Batch 10/244] avg loss 586.617, throughput 2.30414K wps\n",
      "[Epoch 133 Batch 20/244] avg loss 428.873, throughput 2.77008K wps\n",
      "[Epoch 133 Batch 30/244] avg loss 220.401, throughput 2.85715K wps\n",
      "[Epoch 133 Batch 40/244] avg loss 299.876, throughput 3.78788K wps\n",
      "[Epoch 133 Batch 50/244] avg loss 178.489, throughput 3.92158K wps\n",
      "[Epoch 133 Batch 60/244] avg loss 687.881, throughput 2.55754K wps\n",
      "[Epoch 133 Batch 70/244] avg loss 239.444, throughput 3.11526K wps\n",
      "[Epoch 133 Batch 80/244] avg loss 137.642, throughput 3.64966K wps\n",
      "[Epoch 133 Batch 90/244] avg loss 203.42, throughput 2.68096K wps\n",
      "[Epoch 133 Batch 100/244] avg loss 166.347, throughput 3.6232K wps\n",
      "[Epoch 133 Batch 110/244] avg loss 439.405, throughput 2.76243K wps\n",
      "[Epoch 133 Batch 120/244] avg loss 186.823, throughput 3.03951K wps\n",
      "[Epoch 133 Batch 130/244] avg loss 164.765, throughput 3.24676K wps\n",
      "[Epoch 133 Batch 140/244] avg loss 222.841, throughput 2.88184K wps\n",
      "[Epoch 133 Batch 150/244] avg loss 603.157, throughput 2.43903K wps\n",
      "[Epoch 133 Batch 160/244] avg loss 205.427, throughput 3.40136K wps\n",
      "[Epoch 133 Batch 170/244] avg loss 223.203, throughput 2.78551K wps\n",
      "[Epoch 133 Batch 180/244] avg loss 214.816, throughput 2.34193K wps\n",
      "[Epoch 133 Batch 190/244] avg loss 148.343, throughput 2.42718K wps\n",
      "[Epoch 133 Batch 200/244] avg loss 381.917, throughput 2.46913K wps\n",
      "[Epoch 133 Batch 210/244] avg loss 230.849, throughput 2.90697K wps\n",
      "[Epoch 133 Batch 220/244] avg loss 196.447, throughput 3.1056K wps\n",
      "[Epoch 133 Batch 230/244] avg loss 236.071, throughput 2.65957K wps\n",
      "[Epoch 133 Batch 240/244] avg loss 239.099, throughput 2.65252K wps\n",
      "[Epoch 133] train avg loss 293.307, train avg r2 0.814879,throughput 2.85614K wps\n",
      "learning rate: 1.220703125e-07\n",
      "[Epoch 134 Batch 10/244] avg loss 595.991, throughput 2.36407K wps\n",
      "[Epoch 134 Batch 20/244] avg loss 408.875, throughput 2.77008K wps\n",
      "[Epoch 134 Batch 30/244] avg loss 213.54, throughput 2.91545K wps\n",
      "[Epoch 134 Batch 40/244] avg loss 267.995, throughput 3.84615K wps\n",
      "[Epoch 134 Batch 50/244] avg loss 190.753, throughput 3.93702K wps\n",
      "[Epoch 134 Batch 60/244] avg loss 751.389, throughput 2.56409K wps\n",
      "[Epoch 134 Batch 70/244] avg loss 248.73, throughput 3.1949K wps\n",
      "[Epoch 134 Batch 80/244] avg loss 149.239, throughput 3.64965K wps\n",
      "[Epoch 134 Batch 90/244] avg loss 222.894, throughput 2.68097K wps\n",
      "[Epoch 134 Batch 100/244] avg loss 172.797, throughput 3.63635K wps\n",
      "[Epoch 134 Batch 110/244] avg loss 433.777, throughput 2.77007K wps\n",
      "[Epoch 134 Batch 120/244] avg loss 185.174, throughput 3.04878K wps\n",
      "[Epoch 134 Batch 130/244] avg loss 174.867, throughput 3.25733K wps\n",
      "[Epoch 134 Batch 140/244] avg loss 228.44, throughput 2.87357K wps\n",
      "[Epoch 134 Batch 150/244] avg loss 594.779, throughput 2.43902K wps\n",
      "[Epoch 134 Batch 160/244] avg loss 211.6, throughput 3.38982K wps\n",
      "[Epoch 134 Batch 170/244] avg loss 225.388, throughput 2.7933K wps\n",
      "[Epoch 134 Batch 180/244] avg loss 221.462, throughput 2.34742K wps\n",
      "[Epoch 134 Batch 190/244] avg loss 162.365, throughput 2.42718K wps\n",
      "[Epoch 134 Batch 200/244] avg loss 372.658, throughput 2.47524K wps\n",
      "[Epoch 134 Batch 210/244] avg loss 254.106, throughput 2.89855K wps\n",
      "[Epoch 134 Batch 220/244] avg loss 178.337, throughput 3.1056K wps\n",
      "[Epoch 134 Batch 230/244] avg loss 231.761, throughput 2.65957K wps\n",
      "[Epoch 134 Batch 240/244] avg loss 229.446, throughput 2.65251K wps\n",
      "[Epoch 134] train avg loss 296.803, train avg r2 0.81553,throughput 2.86755K wps\n",
      "learning rate: 1.220703125e-07\n",
      "[Epoch 135 Batch 10/244] avg loss 614.285, throughput 2.36407K wps\n",
      "[Epoch 135 Batch 20/244] avg loss 394.49, throughput 2.76243K wps\n",
      "[Epoch 135 Batch 30/244] avg loss 230.004, throughput 2.92398K wps\n",
      "[Epoch 135 Batch 40/244] avg loss 267.32, throughput 3.84615K wps\n",
      "[Epoch 135 Batch 50/244] avg loss 178.251, throughput 3.937K wps\n",
      "[Epoch 135 Batch 60/244] avg loss 725.98, throughput 2.5641K wps\n",
      "[Epoch 135 Batch 70/244] avg loss 244.633, throughput 3.20513K wps\n",
      "[Epoch 135 Batch 80/244] avg loss 145.812, throughput 3.64964K wps\n",
      "[Epoch 135 Batch 90/244] avg loss 232.713, throughput 2.6738K wps\n",
      "[Epoch 135 Batch 100/244] avg loss 180.478, throughput 3.63637K wps\n",
      "[Epoch 135 Batch 110/244] avg loss 427.658, throughput 2.77008K wps\n",
      "[Epoch 135 Batch 120/244] avg loss 196.988, throughput 3.0581K wps\n",
      "[Epoch 135 Batch 130/244] avg loss 188.618, throughput 3.25733K wps\n",
      "[Epoch 135 Batch 140/244] avg loss 216.926, throughput 2.87356K wps\n",
      "[Epoch 135 Batch 150/244] avg loss 596.179, throughput 2.42718K wps\n",
      "[Epoch 135 Batch 160/244] avg loss 201.813, throughput 3.41297K wps\n",
      "[Epoch 135 Batch 170/244] avg loss 249.426, throughput 2.78552K wps\n",
      "[Epoch 135 Batch 180/244] avg loss 205.664, throughput 2.34741K wps\n",
      "[Epoch 135 Batch 190/244] avg loss 152.31, throughput 2.43309K wps\n",
      "[Epoch 135 Batch 200/244] avg loss 353.383, throughput 2.48757K wps\n",
      "[Epoch 135 Batch 210/244] avg loss 221.164, throughput 2.89855K wps\n",
      "[Epoch 135 Batch 220/244] avg loss 180.31, throughput 3.12499K wps\n",
      "[Epoch 135 Batch 230/244] avg loss 225.205, throughput 2.65957K wps\n",
      "[Epoch 135 Batch 240/244] avg loss 251.129, throughput 2.65252K wps\n",
      "[Epoch 135] train avg loss 294.559, train avg r2 0.817393,throughput 2.86856K wps\n",
      "learning rate: 1.220703125e-07\n",
      "[Epoch 136 Batch 10/244] avg loss 597.619, throughput 2.36408K wps\n",
      "[Epoch 136 Batch 20/244] avg loss 395.133, throughput 2.77008K wps\n",
      "[Epoch 136 Batch 30/244] avg loss 218.344, throughput 2.91545K wps\n",
      "[Epoch 136 Batch 40/244] avg loss 286.939, throughput 3.8314K wps\n",
      "[Epoch 136 Batch 50/244] avg loss 158.884, throughput 3.93703K wps\n",
      "[Epoch 136 Batch 60/244] avg loss 743.071, throughput 2.55754K wps\n",
      "[Epoch 136 Batch 70/244] avg loss 264.719, throughput 3.21544K wps\n",
      "[Epoch 136 Batch 80/244] avg loss 146.259, throughput 3.66301K wps\n",
      "[Epoch 136 Batch 90/244] avg loss 212.365, throughput 2.68096K wps\n",
      "[Epoch 136 Batch 100/244] avg loss 168.824, throughput 3.63637K wps\n",
      "[Epoch 136 Batch 110/244] avg loss 442.823, throughput 2.77777K wps\n",
      "[Epoch 136 Batch 120/244] avg loss 180.573, throughput 3.05811K wps\n",
      "[Epoch 136 Batch 130/244] avg loss 167.42, throughput 3.25734K wps\n",
      "[Epoch 136 Batch 140/244] avg loss 231.794, throughput 2.87354K wps\n",
      "[Epoch 136 Batch 150/244] avg loss 582.255, throughput 2.43904K wps\n",
      "[Epoch 136 Batch 160/244] avg loss 205.507, throughput 3.41296K wps\n",
      "[Epoch 136 Batch 170/244] avg loss 233.875, throughput 2.7933K wps\n",
      "[Epoch 136 Batch 180/244] avg loss 208.942, throughput 2.34741K wps\n",
      "[Epoch 136 Batch 190/244] avg loss 153.166, throughput 2.42719K wps\n",
      "[Epoch 136 Batch 200/244] avg loss 349.811, throughput 2.46914K wps\n",
      "[Epoch 136 Batch 210/244] avg loss 229.53, throughput 2.89854K wps\n",
      "[Epoch 136 Batch 220/244] avg loss 176.125, throughput 3.11527K wps\n",
      "[Epoch 136 Batch 230/244] avg loss 234.122, throughput 2.65957K wps\n",
      "[Epoch 136 Batch 240/244] avg loss 247.936, throughput 2.65957K wps\n",
      "[Epoch 136] train avg loss 292.548, train avg r2 0.820347,throughput 2.86991K wps\n",
      "learning rate: 1.220703125e-07\n",
      "[Epoch 137 Batch 10/244] avg loss 574.375, throughput 2.36406K wps\n",
      "[Epoch 137 Batch 20/244] avg loss 399.545, throughput 2.76244K wps\n",
      "[Epoch 137 Batch 30/244] avg loss 212.19, throughput 2.92398K wps\n",
      "[Epoch 137 Batch 40/244] avg loss 272.083, throughput 3.83141K wps\n",
      "[Epoch 137 Batch 50/244] avg loss 142.816, throughput 3.90627K wps\n",
      "[Epoch 137 Batch 60/244] avg loss 737.07, throughput 2.5641K wps\n",
      "[Epoch 137 Batch 70/244] avg loss 257.657, throughput 3.20511K wps\n",
      "[Epoch 137 Batch 80/244] avg loss 145.834, throughput 3.63638K wps\n",
      "[Epoch 137 Batch 90/244] avg loss 210.307, throughput 2.67379K wps\n",
      "[Epoch 137 Batch 100/244] avg loss 165.821, throughput 3.63638K wps\n",
      "[Epoch 137 Batch 110/244] avg loss 434.006, throughput 2.76243K wps\n",
      "[Epoch 137 Batch 120/244] avg loss 201.358, throughput 3.04877K wps\n",
      "[Epoch 137 Batch 130/244] avg loss 167.282, throughput 3.25733K wps\n",
      "[Epoch 137 Batch 140/244] avg loss 229.317, throughput 2.87355K wps\n",
      "[Epoch 137 Batch 150/244] avg loss 587.832, throughput 2.43903K wps\n",
      "[Epoch 137 Batch 160/244] avg loss 208.161, throughput 3.42465K wps\n",
      "[Epoch 137 Batch 170/244] avg loss 230.25, throughput 2.7933K wps\n",
      "[Epoch 137 Batch 180/244] avg loss 223.298, throughput 2.34742K wps\n",
      "[Epoch 137 Batch 190/244] avg loss 158.547, throughput 2.43309K wps\n",
      "[Epoch 137 Batch 200/244] avg loss 381.301, throughput 2.47525K wps\n",
      "[Epoch 137 Batch 210/244] avg loss 223.912, throughput 2.89855K wps\n",
      "[Epoch 137 Batch 220/244] avg loss 189.085, throughput 3.12501K wps\n",
      "[Epoch 137 Batch 230/244] avg loss 228.132, throughput 2.66666K wps\n",
      "[Epoch 137 Batch 240/244] avg loss 236.154, throughput 2.66666K wps\n",
      "[Epoch 137] train avg loss 290.957, train avg r2 0.81977,throughput 2.8689K wps\n",
      "learning rate: 1.220703125e-07\n",
      "[Epoch 138 Batch 10/244] avg loss 663.284, throughput 2.36967K wps\n",
      "[Epoch 138 Batch 20/244] avg loss 385.121, throughput 2.76243K wps\n",
      "[Epoch 138 Batch 30/244] avg loss 222.584, throughput 2.92399K wps\n",
      "[Epoch 138 Batch 40/244] avg loss 283.916, throughput 3.83141K wps\n",
      "[Epoch 138 Batch 50/244] avg loss 158.569, throughput 3.93701K wps\n",
      "[Epoch 138 Batch 60/244] avg loss 686.631, throughput 2.56411K wps\n",
      "[Epoch 138 Batch 70/244] avg loss 253.192, throughput 3.21542K wps\n",
      "[Epoch 138 Batch 80/244] avg loss 142.98, throughput 3.66302K wps\n",
      "[Epoch 138 Batch 90/244] avg loss 200.156, throughput 2.68096K wps\n",
      "[Epoch 138 Batch 100/244] avg loss 172.624, throughput 3.62318K wps\n",
      "[Epoch 138 Batch 110/244] avg loss 436.612, throughput 2.77778K wps\n",
      "[Epoch 138 Batch 120/244] avg loss 199.307, throughput 3.04878K wps\n",
      "[Epoch 138 Batch 130/244] avg loss 169.639, throughput 3.25733K wps\n",
      "[Epoch 138 Batch 140/244] avg loss 214.211, throughput 2.88183K wps\n",
      "[Epoch 138 Batch 150/244] avg loss 591.418, throughput 2.43903K wps\n",
      "[Epoch 138 Batch 160/244] avg loss 194.371, throughput 3.42465K wps\n",
      "[Epoch 138 Batch 170/244] avg loss 231.719, throughput 2.79329K wps\n",
      "[Epoch 138 Batch 180/244] avg loss 221.456, throughput 2.34192K wps\n",
      "[Epoch 138 Batch 190/244] avg loss 156.407, throughput 2.43309K wps\n",
      "[Epoch 138 Batch 200/244] avg loss 373.799, throughput 2.46914K wps\n",
      "[Epoch 138 Batch 210/244] avg loss 239.846, throughput 2.89854K wps\n",
      "[Epoch 138 Batch 220/244] avg loss 173.098, throughput 3.11527K wps\n",
      "[Epoch 138 Batch 230/244] avg loss 226.887, throughput 2.65252K wps\n",
      "[Epoch 138 Batch 240/244] avg loss 240.816, throughput 2.65251K wps\n",
      "[Epoch 138] train avg loss 292.921, train avg r2 0.819508,throughput 2.86958K wps\n",
      "learning rate: 1.220703125e-07\n",
      "[Epoch 139 Batch 10/244] avg loss 639.84, throughput 2.36407K wps\n",
      "[Epoch 139 Batch 20/244] avg loss 368.917, throughput 2.76243K wps\n",
      "[Epoch 139 Batch 30/244] avg loss 218.593, throughput 2.91545K wps\n",
      "[Epoch 139 Batch 40/244] avg loss 270.169, throughput 3.81679K wps\n",
      "[Epoch 139 Batch 50/244] avg loss 169.434, throughput 3.92158K wps\n",
      "[Epoch 139 Batch 60/244] avg loss 755.835, throughput 2.56409K wps\n",
      "[Epoch 139 Batch 70/244] avg loss 238.694, throughput 3.20515K wps\n",
      "[Epoch 139 Batch 80/244] avg loss 143.596, throughput 3.64963K wps\n",
      "[Epoch 139 Batch 90/244] avg loss 213.587, throughput 2.68096K wps\n",
      "[Epoch 139 Batch 100/244] avg loss 165.634, throughput 3.63635K wps\n",
      "[Epoch 139 Batch 110/244] avg loss 439.329, throughput 2.76244K wps\n",
      "[Epoch 139 Batch 120/244] avg loss 181.535, throughput 3.04876K wps\n",
      "[Epoch 139 Batch 130/244] avg loss 174.806, throughput 3.24675K wps\n",
      "[Epoch 139 Batch 140/244] avg loss 224.086, throughput 2.87356K wps\n",
      "[Epoch 139 Batch 150/244] avg loss 650.631, throughput 2.43903K wps\n",
      "[Epoch 139 Batch 160/244] avg loss 196.851, throughput 3.41296K wps\n",
      "[Epoch 139 Batch 170/244] avg loss 229.147, throughput 2.7933K wps\n",
      "[Epoch 139 Batch 180/244] avg loss 213.944, throughput 2.34742K wps\n",
      "[Epoch 139 Batch 190/244] avg loss 162.326, throughput 2.42719K wps\n",
      "[Epoch 139 Batch 200/244] avg loss 385.646, throughput 2.47525K wps\n",
      "[Epoch 139 Batch 210/244] avg loss 230.952, throughput 2.89854K wps\n",
      "[Epoch 139 Batch 220/244] avg loss 171.294, throughput 3.11527K wps\n",
      "[Epoch 139 Batch 230/244] avg loss 222.607, throughput 2.65958K wps\n",
      "[Epoch 139 Batch 240/244] avg loss 229.361, throughput 2.65251K wps\n",
      "[Epoch 139] train avg loss 295.735, train avg r2 0.81798,throughput 2.86789K wps\n",
      "learning rate: 1.220703125e-07\n",
      "[Epoch 140 Batch 10/244] avg loss 558.687, throughput 2.36967K wps\n",
      "[Epoch 140 Batch 20/244] avg loss 409.633, throughput 2.76243K wps\n",
      "[Epoch 140 Batch 30/244] avg loss 223.392, throughput 2.91545K wps\n",
      "[Epoch 140 Batch 40/244] avg loss 280.176, throughput 3.83141K wps\n",
      "[Epoch 140 Batch 50/244] avg loss 160.692, throughput 3.93702K wps\n",
      "[Epoch 140 Batch 60/244] avg loss 724.516, throughput 2.5641K wps\n",
      "[Epoch 140 Batch 70/244] avg loss 233.827, throughput 3.20514K wps\n",
      "[Epoch 140 Batch 80/244] avg loss 137.567, throughput 3.663K wps\n",
      "[Epoch 140 Batch 90/244] avg loss 236.248, throughput 2.68097K wps\n",
      "[Epoch 140 Batch 100/244] avg loss 157.944, throughput 3.57144K wps\n",
      "[Epoch 140 Batch 110/244] avg loss 444.302, throughput 2.74725K wps\n",
      "[Epoch 140 Batch 120/244] avg loss 196.128, throughput 3.04878K wps\n",
      "[Epoch 140 Batch 130/244] avg loss 176.195, throughput 3.23624K wps\n",
      "[Epoch 140 Batch 140/244] avg loss 220.432, throughput 2.88183K wps\n",
      "[Epoch 140 Batch 150/244] avg loss 610.026, throughput 2.44499K wps\n",
      "[Epoch 140 Batch 160/244] avg loss 195.394, throughput 3.41296K wps\n",
      "[Epoch 140 Batch 170/244] avg loss 225.22, throughput 2.80111K wps\n",
      "[Epoch 140 Batch 180/244] avg loss 224.339, throughput 2.34741K wps\n",
      "[Epoch 140 Batch 190/244] avg loss 176.822, throughput 2.43309K wps\n",
      "[Epoch 140 Batch 200/244] avg loss 344.761, throughput 2.47526K wps\n",
      "[Epoch 140 Batch 210/244] avg loss 249.363, throughput 2.90697K wps\n",
      "[Epoch 140 Batch 220/244] avg loss 195.57, throughput 3.11526K wps\n",
      "[Epoch 140 Batch 230/244] avg loss 226.321, throughput 2.65956K wps\n",
      "[Epoch 140 Batch 240/244] avg loss 237.688, throughput 2.64551K wps\n",
      "[Epoch 140] train avg loss 293.275, train avg r2 0.817608,throughput 2.86654K wps\n",
      "learning rate: 6.103515625e-08\n",
      "[Epoch 141 Batch 10/244] avg loss 625.609, throughput 2.36968K wps\n",
      "[Epoch 141 Batch 20/244] avg loss 389.643, throughput 2.77007K wps\n",
      "[Epoch 141 Batch 30/244] avg loss 221.586, throughput 2.91545K wps\n",
      "[Epoch 141 Batch 40/244] avg loss 261.754, throughput 3.81679K wps\n",
      "[Epoch 141 Batch 50/244] avg loss 159.703, throughput 3.92157K wps\n",
      "[Epoch 141 Batch 60/244] avg loss 763.194, throughput 2.57069K wps\n",
      "[Epoch 141 Batch 70/244] avg loss 257.656, throughput 3.19487K wps\n",
      "[Epoch 141 Batch 80/244] avg loss 134.905, throughput 3.64965K wps\n",
      "[Epoch 141 Batch 90/244] avg loss 205.001, throughput 2.6738K wps\n",
      "[Epoch 141 Batch 100/244] avg loss 174.907, throughput 3.63635K wps\n",
      "[Epoch 141 Batch 110/244] avg loss 429.373, throughput 2.78551K wps\n",
      "[Epoch 141 Batch 120/244] avg loss 200.855, throughput 3.04878K wps\n",
      "[Epoch 141 Batch 130/244] avg loss 177.822, throughput 2.93255K wps\n",
      "[Epoch 141 Batch 140/244] avg loss 224.174, throughput 2.87355K wps\n",
      "[Epoch 141 Batch 150/244] avg loss 608.656, throughput 2.43309K wps\n",
      "[Epoch 141 Batch 160/244] avg loss 186.084, throughput 3.41299K wps\n",
      "[Epoch 141 Batch 170/244] avg loss 217.128, throughput 2.7933K wps\n",
      "[Epoch 141 Batch 180/244] avg loss 214.166, throughput 2.34192K wps\n",
      "[Epoch 141 Batch 190/244] avg loss 157.071, throughput 2.42719K wps\n",
      "[Epoch 141 Batch 200/244] avg loss 357.598, throughput 2.48138K wps\n",
      "[Epoch 141 Batch 210/244] avg loss 229.274, throughput 2.89855K wps\n",
      "[Epoch 141 Batch 220/244] avg loss 175.862, throughput 3.11526K wps\n",
      "[Epoch 141 Batch 230/244] avg loss 227.201, throughput 2.65958K wps\n",
      "[Epoch 141 Batch 240/244] avg loss 241.096, throughput 2.65957K wps\n",
      "[Epoch 141] train avg loss 293.558, train avg r2 0.821663,throughput 2.85681K wps\n",
      "learning rate: 6.103515625e-08\n",
      "[Epoch 142 Batch 10/244] avg loss 650.561, throughput 2.36407K wps\n",
      "[Epoch 142 Batch 20/244] avg loss 380.177, throughput 2.77008K wps\n",
      "[Epoch 142 Batch 30/244] avg loss 224.164, throughput 2.91545K wps\n",
      "[Epoch 142 Batch 40/244] avg loss 272.358, throughput 3.84615K wps\n",
      "[Epoch 142 Batch 50/244] avg loss 161.777, throughput 3.92157K wps\n",
      "[Epoch 142 Batch 60/244] avg loss 722.331, throughput 2.55755K wps\n",
      "[Epoch 142 Batch 70/244] avg loss 242.529, throughput 3.20512K wps\n",
      "[Epoch 142 Batch 80/244] avg loss 143.418, throughput 3.66299K wps\n",
      "[Epoch 142 Batch 90/244] avg loss 224.591, throughput 2.68097K wps\n",
      "[Epoch 142 Batch 100/244] avg loss 176.547, throughput 3.62318K wps\n",
      "[Epoch 142 Batch 110/244] avg loss 398.4, throughput 2.77007K wps\n",
      "[Epoch 142 Batch 120/244] avg loss 178.2, throughput 3.0581K wps\n",
      "[Epoch 142 Batch 130/244] avg loss 179.502, throughput 3.25734K wps\n",
      "[Epoch 142 Batch 140/244] avg loss 225.716, throughput 2.88185K wps\n",
      "[Epoch 142 Batch 150/244] avg loss 625.07, throughput 2.43309K wps\n",
      "[Epoch 142 Batch 160/244] avg loss 197.234, throughput 3.40135K wps\n",
      "[Epoch 142 Batch 170/244] avg loss 238.712, throughput 2.79328K wps\n",
      "[Epoch 142 Batch 180/244] avg loss 212.861, throughput 2.33646K wps\n",
      "[Epoch 142 Batch 190/244] avg loss 157.78, throughput 2.43309K wps\n",
      "[Epoch 142 Batch 200/244] avg loss 378.743, throughput 2.48139K wps\n",
      "[Epoch 142 Batch 210/244] avg loss 236.468, throughput 2.89852K wps\n",
      "[Epoch 142 Batch 220/244] avg loss 178.316, throughput 3.12501K wps\n",
      "[Epoch 142 Batch 230/244] avg loss 231.182, throughput 2.65957K wps\n",
      "[Epoch 142 Batch 240/244] avg loss 256.813, throughput 2.65252K wps\n",
      "[Epoch 142] train avg loss 295.535, train avg r2 0.818788,throughput 2.8689K wps\n",
      "learning rate: 6.103515625e-08\n",
      "[Epoch 143 Batch 10/244] avg loss 629.887, throughput 2.36967K wps\n",
      "[Epoch 143 Batch 20/244] avg loss 383.331, throughput 2.76243K wps\n",
      "[Epoch 143 Batch 30/244] avg loss 217.838, throughput 2.90697K wps\n",
      "[Epoch 143 Batch 40/244] avg loss 281.602, throughput 3.83144K wps\n",
      "[Epoch 143 Batch 50/244] avg loss 157.545, throughput 3.93703K wps\n",
      "[Epoch 143 Batch 60/244] avg loss 772.32, throughput 2.5641K wps\n",
      "[Epoch 143 Batch 70/244] avg loss 258.464, throughput 3.21542K wps\n",
      "[Epoch 143 Batch 80/244] avg loss 139.133, throughput 3.66301K wps\n",
      "[Epoch 143 Batch 90/244] avg loss 247.566, throughput 2.68097K wps\n",
      "[Epoch 143 Batch 100/244] avg loss 170.274, throughput 3.63635K wps\n",
      "[Epoch 143 Batch 110/244] avg loss 435.753, throughput 2.77009K wps\n",
      "[Epoch 143 Batch 120/244] avg loss 177.287, throughput 3.0581K wps\n",
      "[Epoch 143 Batch 130/244] avg loss 176.082, throughput 3.23624K wps\n",
      "[Epoch 143 Batch 140/244] avg loss 216.702, throughput 2.88184K wps\n",
      "[Epoch 143 Batch 150/244] avg loss 584.9, throughput 2.43903K wps\n",
      "[Epoch 143 Batch 160/244] avg loss 199.608, throughput 3.41298K wps\n",
      "[Epoch 143 Batch 170/244] avg loss 233.713, throughput 2.79329K wps\n",
      "[Epoch 143 Batch 180/244] avg loss 204.226, throughput 2.34742K wps\n",
      "[Epoch 143 Batch 190/244] avg loss 165.263, throughput 2.42131K wps\n",
      "[Epoch 143 Batch 200/244] avg loss 364.695, throughput 2.46914K wps\n",
      "[Epoch 143 Batch 210/244] avg loss 218.648, throughput 2.89854K wps\n",
      "[Epoch 143 Batch 220/244] avg loss 184.353, throughput 3.1348K wps\n",
      "[Epoch 143 Batch 230/244] avg loss 224.6, throughput 2.66666K wps\n",
      "[Epoch 143 Batch 240/244] avg loss 239.411, throughput 2.65957K wps\n",
      "[Epoch 143] train avg loss 295.036, train avg r2 0.815544,throughput 2.86958K wps\n",
      "learning rate: 6.103515625e-08\n",
      "[Epoch 144 Batch 10/244] avg loss 619.709, throughput 2.36967K wps\n",
      "[Epoch 144 Batch 20/244] avg loss 416.985, throughput 2.77007K wps\n",
      "[Epoch 144 Batch 30/244] avg loss 230.597, throughput 2.91546K wps\n",
      "[Epoch 144 Batch 40/244] avg loss 282.76, throughput 3.83141K wps\n",
      "[Epoch 144 Batch 50/244] avg loss 158.861, throughput 3.95259K wps\n",
      "[Epoch 144 Batch 60/244] avg loss 746.426, throughput 2.56411K wps\n",
      "[Epoch 144 Batch 70/244] avg loss 233.891, throughput 3.20513K wps\n",
      "[Epoch 144 Batch 80/244] avg loss 133.756, throughput 3.64965K wps\n",
      "[Epoch 144 Batch 90/244] avg loss 223.93, throughput 2.68096K wps\n",
      "[Epoch 144 Batch 100/244] avg loss 169.266, throughput 3.63635K wps\n",
      "[Epoch 144 Batch 110/244] avg loss 495.851, throughput 2.77009K wps\n",
      "[Epoch 144 Batch 120/244] avg loss 178.326, throughput 3.0303K wps\n",
      "[Epoch 144 Batch 130/244] avg loss 167.117, throughput 3.25735K wps\n",
      "[Epoch 144 Batch 140/244] avg loss 216.05, throughput 2.87356K wps\n",
      "[Epoch 144 Batch 150/244] avg loss 599.424, throughput 2.43308K wps\n",
      "[Epoch 144 Batch 160/244] avg loss 207.147, throughput 3.40136K wps\n",
      "[Epoch 144 Batch 170/244] avg loss 227.979, throughput 2.78551K wps\n",
      "[Epoch 144 Batch 180/244] avg loss 202.718, throughput 2.34741K wps\n",
      "[Epoch 144 Batch 190/244] avg loss 169.697, throughput 2.42719K wps\n",
      "[Epoch 144 Batch 200/244] avg loss 347.702, throughput 2.47524K wps\n",
      "[Epoch 144 Batch 210/244] avg loss 232.053, throughput 2.8985K wps\n",
      "[Epoch 144 Batch 220/244] avg loss 167.355, throughput 3.10562K wps\n",
      "[Epoch 144 Batch 230/244] avg loss 253.542, throughput 2.65956K wps\n",
      "[Epoch 144 Batch 240/244] avg loss 250.969, throughput 2.65958K wps\n",
      "[Epoch 144] train avg loss 295.9, train avg r2 0.822533,throughput 2.86823K wps\n",
      "learning rate: 6.103515625e-08\n",
      "[Epoch 145 Batch 10/244] avg loss 612.388, throughput 2.36966K wps\n",
      "[Epoch 145 Batch 20/244] avg loss 391.135, throughput 2.77009K wps\n",
      "[Epoch 145 Batch 30/244] avg loss 216.244, throughput 2.90697K wps\n",
      "[Epoch 145 Batch 40/244] avg loss 288.429, throughput 3.83142K wps\n",
      "[Epoch 145 Batch 50/244] avg loss 174.38, throughput 3.93701K wps\n",
      "[Epoch 145 Batch 60/244] avg loss 742.579, throughput 2.5641K wps\n",
      "[Epoch 145 Batch 70/244] avg loss 243.335, throughput 3.20512K wps\n",
      "[Epoch 145 Batch 80/244] avg loss 143.322, throughput 3.66301K wps\n",
      "[Epoch 145 Batch 90/244] avg loss 224.585, throughput 2.68097K wps\n",
      "[Epoch 145 Batch 100/244] avg loss 174.168, throughput 3.63635K wps\n",
      "[Epoch 145 Batch 110/244] avg loss 425.208, throughput 2.77009K wps\n",
      "[Epoch 145 Batch 120/244] avg loss 192.695, throughput 3.03951K wps\n",
      "[Epoch 145 Batch 130/244] avg loss 179.331, throughput 3.25731K wps\n",
      "[Epoch 145 Batch 140/244] avg loss 240.522, throughput 2.89018K wps\n",
      "[Epoch 145 Batch 150/244] avg loss 614.104, throughput 2.43903K wps\n",
      "[Epoch 145 Batch 160/244] avg loss 201.648, throughput 3.41296K wps\n",
      "[Epoch 145 Batch 170/244] avg loss 247.426, throughput 2.80113K wps\n",
      "[Epoch 145 Batch 180/244] avg loss 220.517, throughput 2.34741K wps\n",
      "[Epoch 145 Batch 190/244] avg loss 164.695, throughput 2.4331K wps\n",
      "[Epoch 145 Batch 200/244] avg loss 346.353, throughput 2.47524K wps\n",
      "[Epoch 145 Batch 210/244] avg loss 218.897, throughput 2.89018K wps\n",
      "[Epoch 145 Batch 220/244] avg loss 181.629, throughput 3.11526K wps\n",
      "[Epoch 145 Batch 230/244] avg loss 239.821, throughput 2.65957K wps\n",
      "[Epoch 145 Batch 240/244] avg loss 243.468, throughput 2.65958K wps\n",
      "[Epoch 145] train avg loss 296.401, train avg r2 0.816281,throughput 2.86924K wps\n",
      "learning rate: 6.103515625e-08\n",
      "[Epoch 146 Batch 10/244] avg loss 633.094, throughput 2.36965K wps\n",
      "[Epoch 146 Batch 20/244] avg loss 402.178, throughput 2.7778K wps\n",
      "[Epoch 146 Batch 30/244] avg loss 210.597, throughput 2.92396K wps\n",
      "[Epoch 146 Batch 40/244] avg loss 283.643, throughput 3.8168K wps\n",
      "[Epoch 146 Batch 50/244] avg loss 168.029, throughput 3.92156K wps\n",
      "[Epoch 146 Batch 60/244] avg loss 743.521, throughput 2.55755K wps\n",
      "[Epoch 146 Batch 70/244] avg loss 249.688, throughput 3.2051K wps\n",
      "[Epoch 146 Batch 80/244] avg loss 135.62, throughput 3.66303K wps\n",
      "[Epoch 146 Batch 90/244] avg loss 237.528, throughput 2.68097K wps\n",
      "[Epoch 146 Batch 100/244] avg loss 171.429, throughput 3.63635K wps\n",
      "[Epoch 146 Batch 110/244] avg loss 454.24, throughput 2.77777K wps\n",
      "[Epoch 146 Batch 120/244] avg loss 187.812, throughput 3.0303K wps\n",
      "[Epoch 146 Batch 130/244] avg loss 181.437, throughput 3.25736K wps\n",
      "[Epoch 146 Batch 140/244] avg loss 241.669, throughput 2.88183K wps\n",
      "[Epoch 146 Batch 150/244] avg loss 582.595, throughput 2.44498K wps\n",
      "[Epoch 146 Batch 160/244] avg loss 196.001, throughput 3.413K wps\n",
      "[Epoch 146 Batch 170/244] avg loss 234.779, throughput 2.80112K wps\n",
      "[Epoch 146 Batch 180/244] avg loss 215.458, throughput 2.34742K wps\n",
      "[Epoch 146 Batch 190/244] avg loss 145.738, throughput 2.43308K wps\n",
      "[Epoch 146 Batch 200/244] avg loss 352.343, throughput 2.48139K wps\n",
      "[Epoch 146 Batch 210/244] avg loss 232.073, throughput 2.90697K wps\n",
      "[Epoch 146 Batch 220/244] avg loss 185.899, throughput 3.12499K wps\n",
      "[Epoch 146 Batch 230/244] avg loss 233.319, throughput 2.65957K wps\n",
      "[Epoch 146 Batch 240/244] avg loss 250.83, throughput 2.65252K wps\n",
      "[Epoch 146] train avg loss 296.521, train avg r2 0.817212,throughput 2.87059K wps\n",
      "learning rate: 6.103515625e-08\n",
      "[Epoch 147 Batch 10/244] avg loss 617.371, throughput 2.30414K wps\n",
      "[Epoch 147 Batch 20/244] avg loss 386.225, throughput 2.77779K wps\n",
      "[Epoch 147 Batch 30/244] avg loss 211.512, throughput 2.84091K wps\n",
      "[Epoch 147 Batch 40/244] avg loss 276.419, throughput 3.81679K wps\n",
      "[Epoch 147 Batch 50/244] avg loss 153.409, throughput 3.92156K wps\n",
      "[Epoch 147 Batch 60/244] avg loss 721.761, throughput 2.57069K wps\n",
      "[Epoch 147 Batch 70/244] avg loss 239.152, throughput 3.14464K wps\n",
      "[Epoch 147 Batch 80/244] avg loss 137.101, throughput 3.61011K wps\n",
      "[Epoch 147 Batch 90/244] avg loss 230.462, throughput 2.68097K wps\n",
      "[Epoch 147 Batch 100/244] avg loss 165.206, throughput 3.62317K wps\n",
      "[Epoch 147 Batch 110/244] avg loss 439.21, throughput 2.77007K wps\n",
      "[Epoch 147 Batch 120/244] avg loss 194.977, throughput 3.03954K wps\n",
      "[Epoch 147 Batch 130/244] avg loss 175.159, throughput 3.26798K wps\n",
      "[Epoch 147 Batch 140/244] avg loss 243.568, throughput 2.88184K wps\n",
      "[Epoch 147 Batch 150/244] avg loss 623.218, throughput 2.43902K wps\n",
      "[Epoch 147 Batch 160/244] avg loss 205.965, throughput 3.41297K wps\n",
      "[Epoch 147 Batch 170/244] avg loss 229.042, throughput 2.7933K wps\n",
      "[Epoch 147 Batch 180/244] avg loss 208.973, throughput 2.34192K wps\n",
      "[Epoch 147 Batch 190/244] avg loss 170.846, throughput 2.42131K wps\n",
      "[Epoch 147 Batch 200/244] avg loss 373.341, throughput 2.46914K wps\n",
      "[Epoch 147 Batch 210/244] avg loss 242.684, throughput 2.89016K wps\n",
      "[Epoch 147 Batch 220/244] avg loss 168.794, throughput 3.11526K wps\n",
      "[Epoch 147 Batch 230/244] avg loss 223.572, throughput 2.65252K wps\n",
      "[Epoch 147 Batch 240/244] avg loss 239.4, throughput 2.65251K wps\n",
      "[Epoch 147] train avg loss 293.583, train avg r2 0.819583,throughput 2.85714K wps\n",
      "learning rate: 6.103515625e-08\n",
      "[Epoch 148 Batch 10/244] avg loss 600.937, throughput 2.36968K wps\n",
      "[Epoch 148 Batch 20/244] avg loss 404.043, throughput 2.77777K wps\n",
      "[Epoch 148 Batch 30/244] avg loss 232.386, throughput 2.92398K wps\n",
      "[Epoch 148 Batch 40/244] avg loss 278.388, throughput 3.81678K wps\n",
      "[Epoch 148 Batch 50/244] avg loss 153.466, throughput 3.92159K wps\n",
      "[Epoch 148 Batch 60/244] avg loss 756.965, throughput 2.5641K wps\n",
      "[Epoch 148 Batch 70/244] avg loss 253.752, throughput 3.20511K wps\n",
      "[Epoch 148 Batch 80/244] avg loss 142.1, throughput 3.66301K wps\n",
      "[Epoch 148 Batch 90/244] avg loss 216.983, throughput 2.6738K wps\n",
      "[Epoch 148 Batch 100/244] avg loss 165.942, throughput 3.62317K wps\n",
      "[Epoch 148 Batch 110/244] avg loss 413.994, throughput 2.7701K wps\n",
      "[Epoch 148 Batch 120/244] avg loss 189.311, throughput 3.05809K wps\n",
      "[Epoch 148 Batch 130/244] avg loss 176.558, throughput 3.25733K wps\n",
      "[Epoch 148 Batch 140/244] avg loss 216.37, throughput 2.87356K wps\n",
      "[Epoch 148 Batch 150/244] avg loss 583.536, throughput 2.43902K wps\n",
      "[Epoch 148 Batch 160/244] avg loss 201.482, throughput 3.42466K wps\n",
      "[Epoch 148 Batch 170/244] avg loss 243.82, throughput 2.78551K wps\n",
      "[Epoch 148 Batch 180/244] avg loss 208.248, throughput 2.34743K wps\n",
      "[Epoch 148 Batch 190/244] avg loss 161.193, throughput 2.4331K wps\n",
      "[Epoch 148 Batch 200/244] avg loss 363.574, throughput 2.47524K wps\n",
      "[Epoch 148 Batch 210/244] avg loss 238.545, throughput 2.89855K wps\n",
      "[Epoch 148 Batch 220/244] avg loss 176.345, throughput 3.11526K wps\n",
      "[Epoch 148 Batch 230/244] avg loss 240.664, throughput 2.65957K wps\n",
      "[Epoch 148 Batch 240/244] avg loss 232.948, throughput 2.65252K wps\n",
      "[Epoch 148] train avg loss 293.406, train avg r2 0.819341,throughput 2.87025K wps\n",
      "learning rate: 6.103515625e-08\n",
      "[Epoch 149 Batch 10/244] avg loss 631.499, throughput 2.36967K wps\n",
      "[Epoch 149 Batch 20/244] avg loss 401.642, throughput 2.77008K wps\n",
      "[Epoch 149 Batch 30/244] avg loss 218.7, throughput 2.92398K wps\n",
      "[Epoch 149 Batch 40/244] avg loss 282.568, throughput 3.8168K wps\n",
      "[Epoch 149 Batch 50/244] avg loss 163.723, throughput 3.92158K wps\n",
      "[Epoch 149 Batch 60/244] avg loss 711.51, throughput 2.55753K wps\n",
      "[Epoch 149 Batch 70/244] avg loss 254.703, throughput 3.22581K wps\n",
      "[Epoch 149 Batch 80/244] avg loss 143.074, throughput 3.66302K wps\n",
      "[Epoch 149 Batch 90/244] avg loss 234.004, throughput 2.67379K wps\n",
      "[Epoch 149 Batch 100/244] avg loss 184.186, throughput 3.61012K wps\n",
      "[Epoch 149 Batch 110/244] avg loss 405.385, throughput 2.76243K wps\n",
      "[Epoch 149 Batch 120/244] avg loss 182.775, throughput 3.05811K wps\n",
      "[Epoch 149 Batch 130/244] avg loss 169.182, throughput 3.25733K wps\n",
      "[Epoch 149 Batch 140/244] avg loss 233.279, throughput 2.88185K wps\n",
      "[Epoch 149 Batch 150/244] avg loss 613.244, throughput 2.43309K wps\n",
      "[Epoch 149 Batch 160/244] avg loss 182.565, throughput 3.41296K wps\n",
      "[Epoch 149 Batch 170/244] avg loss 242.7, throughput 2.77778K wps\n",
      "[Epoch 149 Batch 180/244] avg loss 206.023, throughput 2.34192K wps\n",
      "[Epoch 149 Batch 190/244] avg loss 171.52, throughput 2.42719K wps\n",
      "[Epoch 149 Batch 200/244] avg loss 371.582, throughput 2.46914K wps\n",
      "[Epoch 149 Batch 210/244] avg loss 238.414, throughput 2.89854K wps\n",
      "[Epoch 149 Batch 220/244] avg loss 180.035, throughput 3.10559K wps\n",
      "[Epoch 149 Batch 230/244] avg loss 237.616, throughput 2.65958K wps\n",
      "[Epoch 149 Batch 240/244] avg loss 254.64, throughput 2.65252K wps\n",
      "[Epoch 149] train avg loss 295.833, train avg r2 0.819798,throughput 2.86755K wps\n",
      "learning rate: 6.103515625e-08\n",
      "[Epoch 150 Batch 10/244] avg loss 604.608, throughput 2.36967K wps\n",
      "[Epoch 150 Batch 20/244] avg loss 400.312, throughput 2.77007K wps\n",
      "[Epoch 150 Batch 30/244] avg loss 231.741, throughput 2.90698K wps\n",
      "[Epoch 150 Batch 40/244] avg loss 285.048, throughput 3.83141K wps\n",
      "[Epoch 150 Batch 50/244] avg loss 161.915, throughput 3.90627K wps\n",
      "[Epoch 150 Batch 60/244] avg loss 710.252, throughput 2.55753K wps\n",
      "[Epoch 150 Batch 70/244] avg loss 254.783, throughput 3.21544K wps\n",
      "[Epoch 150 Batch 80/244] avg loss 145.713, throughput 3.66301K wps\n",
      "[Epoch 150 Batch 90/244] avg loss 243.137, throughput 2.68097K wps\n",
      "[Epoch 150 Batch 100/244] avg loss 160.493, throughput 3.63635K wps\n",
      "[Epoch 150 Batch 110/244] avg loss 445.617, throughput 2.77008K wps\n",
      "[Epoch 150 Batch 120/244] avg loss 181.534, throughput 3.04879K wps\n",
      "[Epoch 150 Batch 130/244] avg loss 180.77, throughput 3.25733K wps\n",
      "[Epoch 150 Batch 140/244] avg loss 230.811, throughput 2.87355K wps\n",
      "[Epoch 150 Batch 150/244] avg loss 604.029, throughput 2.43902K wps\n",
      "[Epoch 150 Batch 160/244] avg loss 201.793, throughput 3.41297K wps\n",
      "[Epoch 150 Batch 170/244] avg loss 234.56, throughput 2.79329K wps\n",
      "[Epoch 150 Batch 180/244] avg loss 194.669, throughput 2.34742K wps\n",
      "[Epoch 150 Batch 190/244] avg loss 156.751, throughput 2.43309K wps\n",
      "[Epoch 150 Batch 200/244] avg loss 362.901, throughput 2.47525K wps\n",
      "[Epoch 150 Batch 210/244] avg loss 248.582, throughput 2.89854K wps\n",
      "[Epoch 150 Batch 220/244] avg loss 193.133, throughput 3.11527K wps\n",
      "[Epoch 150 Batch 230/244] avg loss 225.235, throughput 2.65958K wps\n",
      "[Epoch 150 Batch 240/244] avg loss 221.537, throughput 2.65957K wps\n",
      "[Epoch 150] train avg loss 294.113, train avg r2 0.816695,throughput 2.86958K wps\n",
      "learning rate: 3.0517578125e-08\n",
      "[Epoch 151 Batch 10/244] avg loss 620.774, throughput 2.38095K wps\n",
      "[Epoch 151 Batch 20/244] avg loss 380.664, throughput 2.76244K wps\n",
      "[Epoch 151 Batch 30/244] avg loss 238.783, throughput 2.92397K wps\n",
      "[Epoch 151 Batch 40/244] avg loss 288.374, throughput 3.84615K wps\n",
      "[Epoch 151 Batch 50/244] avg loss 166.985, throughput 3.92159K wps\n",
      "[Epoch 151 Batch 60/244] avg loss 724.562, throughput 2.5641K wps\n",
      "[Epoch 151 Batch 70/244] avg loss 242.015, throughput 3.21543K wps\n",
      "[Epoch 151 Batch 80/244] avg loss 127.687, throughput 3.66303K wps\n",
      "[Epoch 151 Batch 90/244] avg loss 219.531, throughput 2.6738K wps\n",
      "[Epoch 151 Batch 100/244] avg loss 159.843, throughput 3.62317K wps\n",
      "[Epoch 151 Batch 110/244] avg loss 452.603, throughput 2.77008K wps\n",
      "[Epoch 151 Batch 120/244] avg loss 189.893, throughput 3.04879K wps\n",
      "[Epoch 151 Batch 130/244] avg loss 171.498, throughput 3.24675K wps\n",
      "[Epoch 151 Batch 140/244] avg loss 219.295, throughput 2.89855K wps\n",
      "[Epoch 151 Batch 150/244] avg loss 575.895, throughput 2.43902K wps\n",
      "[Epoch 151 Batch 160/244] avg loss 198.699, throughput 3.41298K wps\n",
      "[Epoch 151 Batch 170/244] avg loss 229.255, throughput 2.79329K wps\n",
      "[Epoch 151 Batch 180/244] avg loss 212.74, throughput 2.34741K wps\n",
      "[Epoch 151 Batch 190/244] avg loss 156.392, throughput 2.42719K wps\n",
      "[Epoch 151 Batch 200/244] avg loss 358.256, throughput 2.46306K wps\n",
      "[Epoch 151 Batch 210/244] avg loss 249.173, throughput 2.90697K wps\n",
      "[Epoch 151 Batch 220/244] avg loss 185.459, throughput 3.11527K wps\n",
      "[Epoch 151 Batch 230/244] avg loss 226.966, throughput 2.65958K wps\n",
      "[Epoch 151 Batch 240/244] avg loss 243.631, throughput 2.65957K wps\n",
      "[Epoch 151] train avg loss 292.461, train avg r2 0.820035,throughput 2.86924K wps\n",
      "learning rate: 3.0517578125e-08\n",
      "[Epoch 152 Batch 10/244] avg loss 626.664, throughput 2.36966K wps\n",
      "[Epoch 152 Batch 20/244] avg loss 384.924, throughput 2.77007K wps\n",
      "[Epoch 152 Batch 30/244] avg loss 229.435, throughput 2.92398K wps\n",
      "[Epoch 152 Batch 40/244] avg loss 270.544, throughput 3.84617K wps\n",
      "[Epoch 152 Batch 50/244] avg loss 177.252, throughput 3.95256K wps\n",
      "[Epoch 152 Batch 60/244] avg loss 755.021, throughput 2.57069K wps\n",
      "[Epoch 152 Batch 70/244] avg loss 243.794, throughput 3.21543K wps\n",
      "[Epoch 152 Batch 80/244] avg loss 141.264, throughput 3.663K wps\n",
      "[Epoch 152 Batch 90/244] avg loss 224.464, throughput 2.68097K wps\n",
      "[Epoch 152 Batch 100/244] avg loss 167.877, throughput 3.63637K wps\n",
      "[Epoch 152 Batch 110/244] avg loss 405.779, throughput 2.77777K wps\n",
      "[Epoch 152 Batch 120/244] avg loss 201.605, throughput 3.04877K wps\n",
      "[Epoch 152 Batch 130/244] avg loss 170.286, throughput 3.22581K wps\n",
      "[Epoch 152 Batch 140/244] avg loss 223.003, throughput 2.89855K wps\n",
      "[Epoch 152 Batch 150/244] avg loss 635.525, throughput 2.44498K wps\n",
      "[Epoch 152 Batch 160/244] avg loss 210.701, throughput 3.40136K wps\n",
      "[Epoch 152 Batch 170/244] avg loss 219.834, throughput 2.79329K wps\n",
      "[Epoch 152 Batch 180/244] avg loss 197.943, throughput 2.34741K wps\n",
      "[Epoch 152 Batch 190/244] avg loss 161.389, throughput 2.4331K wps\n",
      "[Epoch 152 Batch 200/244] avg loss 373.373, throughput 2.47524K wps\n",
      "[Epoch 152 Batch 210/244] avg loss 233.5, throughput 2.90698K wps\n",
      "[Epoch 152 Batch 220/244] avg loss 176.061, throughput 3.11526K wps\n",
      "[Epoch 152 Batch 230/244] avg loss 238.19, throughput 2.65253K wps\n",
      "[Epoch 152 Batch 240/244] avg loss 243.855, throughput 2.65251K wps\n",
      "[Epoch 152] train avg loss 295.991, train avg r2 0.816647,throughput 2.86924K wps\n",
      "learning rate: 3.0517578125e-08\n",
      "[Epoch 153 Batch 10/244] avg loss 591.935, throughput 2.36967K wps\n",
      "[Epoch 153 Batch 20/244] avg loss 403.491, throughput 2.77778K wps\n",
      "[Epoch 153 Batch 30/244] avg loss 221.624, throughput 2.92397K wps\n",
      "[Epoch 153 Batch 40/244] avg loss 300.106, throughput 3.84615K wps\n",
      "[Epoch 153 Batch 50/244] avg loss 183.507, throughput 3.95259K wps\n",
      "[Epoch 153 Batch 60/244] avg loss 739.052, throughput 2.55753K wps\n",
      "[Epoch 153 Batch 70/244] avg loss 246.073, throughput 3.21545K wps\n",
      "[Epoch 153 Batch 80/244] avg loss 137.601, throughput 3.64961K wps\n",
      "[Epoch 153 Batch 90/244] avg loss 216.624, throughput 2.68098K wps\n",
      "[Epoch 153 Batch 100/244] avg loss 158.336, throughput 3.6232K wps\n",
      "[Epoch 153 Batch 110/244] avg loss 428.49, throughput 2.77007K wps\n",
      "[Epoch 153 Batch 120/244] avg loss 188.673, throughput 3.04878K wps\n",
      "[Epoch 153 Batch 130/244] avg loss 177.618, throughput 3.24673K wps\n",
      "[Epoch 153 Batch 140/244] avg loss 225.006, throughput 2.87357K wps\n",
      "[Epoch 153 Batch 150/244] avg loss 554.264, throughput 2.43309K wps\n",
      "[Epoch 153 Batch 160/244] avg loss 208.818, throughput 3.41297K wps\n",
      "[Epoch 153 Batch 170/244] avg loss 226.002, throughput 2.79329K wps\n",
      "[Epoch 153 Batch 180/244] avg loss 213.592, throughput 2.34741K wps\n",
      "[Epoch 153 Batch 190/244] avg loss 151.854, throughput 2.43309K wps\n",
      "[Epoch 153 Batch 200/244] avg loss 345.778, throughput 2.47524K wps\n",
      "[Epoch 153 Batch 210/244] avg loss 218.848, throughput 2.89854K wps\n",
      "[Epoch 153 Batch 220/244] avg loss 181.99, throughput 3.11529K wps\n",
      "[Epoch 153 Batch 230/244] avg loss 216.384, throughput 2.65956K wps\n",
      "[Epoch 153 Batch 240/244] avg loss 244.388, throughput 2.6455K wps\n",
      "[Epoch 153] train avg loss 291.19, train avg r2 0.818328,throughput 2.86924K wps\n",
      "learning rate: 3.0517578125e-08\n",
      "[Epoch 154 Batch 10/244] avg loss 569.389, throughput 2.36967K wps\n",
      "[Epoch 154 Batch 20/244] avg loss 409.11, throughput 2.77008K wps\n",
      "[Epoch 154 Batch 30/244] avg loss 205.581, throughput 2.92397K wps\n",
      "[Epoch 154 Batch 40/244] avg loss 272.81, throughput 3.83143K wps\n",
      "[Epoch 154 Batch 50/244] avg loss 150.202, throughput 3.95258K wps\n",
      "[Epoch 154 Batch 60/244] avg loss 781.168, throughput 2.56411K wps\n",
      "[Epoch 154 Batch 70/244] avg loss 254.238, throughput 3.19489K wps\n",
      "[Epoch 154 Batch 80/244] avg loss 158.238, throughput 3.64961K wps\n",
      "[Epoch 154 Batch 90/244] avg loss 232.883, throughput 2.68096K wps\n",
      "[Epoch 154 Batch 100/244] avg loss 180.308, throughput 3.63636K wps\n",
      "[Epoch 154 Batch 110/244] avg loss 451.708, throughput 2.77009K wps\n",
      "[Epoch 154 Batch 120/244] avg loss 189.401, throughput 3.04878K wps\n",
      "[Epoch 154 Batch 130/244] avg loss 174.703, throughput 3.25731K wps\n",
      "[Epoch 154 Batch 140/244] avg loss 224.172, throughput 2.88184K wps\n",
      "[Epoch 154 Batch 150/244] avg loss 591.657, throughput 2.43903K wps\n",
      "[Epoch 154 Batch 160/244] avg loss 205.559, throughput 3.41297K wps\n",
      "[Epoch 154 Batch 170/244] avg loss 228.674, throughput 2.7933K wps\n",
      "[Epoch 154 Batch 180/244] avg loss 221.025, throughput 2.34742K wps\n",
      "[Epoch 154 Batch 190/244] avg loss 171.948, throughput 2.43309K wps\n",
      "[Epoch 154 Batch 200/244] avg loss 376.35, throughput 2.46914K wps\n",
      "[Epoch 154 Batch 210/244] avg loss 228.149, throughput 2.89016K wps\n",
      "[Epoch 154 Batch 220/244] avg loss 174.812, throughput 3.1056K wps\n",
      "[Epoch 154 Batch 230/244] avg loss 238.014, throughput 2.65957K wps\n",
      "[Epoch 154 Batch 240/244] avg loss 238.599, throughput 2.65956K wps\n",
      "[Epoch 154] train avg loss 296.67, train avg r2 0.823486,throughput 2.86924K wps\n",
      "learning rate: 3.0517578125e-08\n",
      "[Epoch 155 Batch 10/244] avg loss 620.265, throughput 2.3753K wps\n",
      "[Epoch 155 Batch 20/244] avg loss 401.074, throughput 2.76243K wps\n",
      "[Epoch 155 Batch 30/244] avg loss 237.317, throughput 2.91546K wps\n",
      "[Epoch 155 Batch 40/244] avg loss 267.949, throughput 3.8314K wps\n",
      "[Epoch 155 Batch 50/244] avg loss 157.663, throughput 3.93703K wps\n",
      "[Epoch 155 Batch 60/244] avg loss 723.385, throughput 2.5641K wps\n",
      "[Epoch 155 Batch 70/244] avg loss 257.903, throughput 3.20512K wps\n",
      "[Epoch 155 Batch 80/244] avg loss 137.866, throughput 3.66299K wps\n",
      "[Epoch 155 Batch 90/244] avg loss 225.36, throughput 2.68098K wps\n",
      "[Epoch 155 Batch 100/244] avg loss 163.752, throughput 3.62319K wps\n",
      "[Epoch 155 Batch 110/244] avg loss 448.509, throughput 2.77007K wps\n",
      "[Epoch 155 Batch 120/244] avg loss 201.912, throughput 3.03951K wps\n",
      "[Epoch 155 Batch 130/244] avg loss 169.088, throughput 3.26797K wps\n",
      "[Epoch 155 Batch 140/244] avg loss 225.834, throughput 2.89017K wps\n",
      "[Epoch 155 Batch 150/244] avg loss 640.829, throughput 2.43309K wps\n",
      "[Epoch 155 Batch 160/244] avg loss 200.291, throughput 3.40136K wps\n",
      "[Epoch 155 Batch 170/244] avg loss 225.605, throughput 2.80112K wps\n",
      "[Epoch 155 Batch 180/244] avg loss 208.058, throughput 2.35294K wps\n",
      "[Epoch 155 Batch 190/244] avg loss 150.375, throughput 2.43309K wps\n",
      "[Epoch 155 Batch 200/244] avg loss 339.154, throughput 2.47525K wps\n",
      "[Epoch 155 Batch 210/244] avg loss 230.53, throughput 2.89857K wps\n",
      "[Epoch 155 Batch 220/244] avg loss 177.171, throughput 3.10561K wps\n",
      "[Epoch 155 Batch 230/244] avg loss 246.184, throughput 2.65957K wps\n",
      "[Epoch 155 Batch 240/244] avg loss 230.746, throughput 2.6455K wps\n",
      "[Epoch 155] train avg loss 294.381, train avg r2 0.81794,throughput 2.86958K wps\n",
      "learning rate: 3.0517578125e-08\n",
      "[Epoch 156 Batch 10/244] avg loss 615.322, throughput 2.36966K wps\n",
      "[Epoch 156 Batch 20/244] avg loss 382.802, throughput 2.76243K wps\n",
      "[Epoch 156 Batch 30/244] avg loss 220.874, throughput 2.92396K wps\n",
      "[Epoch 156 Batch 40/244] avg loss 279.524, throughput 3.84616K wps\n",
      "[Epoch 156 Batch 50/244] avg loss 158.168, throughput 3.92157K wps\n",
      "[Epoch 156 Batch 60/244] avg loss 728.841, throughput 2.55755K wps\n",
      "[Epoch 156 Batch 70/244] avg loss 242.26, throughput 3.21542K wps\n",
      "[Epoch 156 Batch 80/244] avg loss 137.628, throughput 3.64964K wps\n",
      "[Epoch 156 Batch 90/244] avg loss 238.441, throughput 2.68096K wps\n",
      "[Epoch 156 Batch 100/244] avg loss 175.951, throughput 3.64963K wps\n",
      "[Epoch 156 Batch 110/244] avg loss 453.737, throughput 2.77008K wps\n",
      "[Epoch 156 Batch 120/244] avg loss 193.004, throughput 3.04879K wps\n",
      "[Epoch 156 Batch 130/244] avg loss 170.572, throughput 3.25732K wps\n",
      "[Epoch 156 Batch 140/244] avg loss 222.991, throughput 2.87356K wps\n",
      "[Epoch 156 Batch 150/244] avg loss 599.063, throughput 2.43309K wps\n",
      "[Epoch 156 Batch 160/244] avg loss 195.153, throughput 3.40135K wps\n",
      "[Epoch 156 Batch 170/244] avg loss 240.087, throughput 2.7933K wps\n",
      "[Epoch 156 Batch 180/244] avg loss 203.826, throughput 2.34192K wps\n",
      "[Epoch 156 Batch 190/244] avg loss 167.547, throughput 2.43309K wps\n",
      "[Epoch 156 Batch 200/244] avg loss 337.696, throughput 2.46914K wps\n",
      "[Epoch 156 Batch 210/244] avg loss 233.009, throughput 2.89854K wps\n",
      "[Epoch 156 Batch 220/244] avg loss 190.852, throughput 3.125K wps\n",
      "[Epoch 156 Batch 230/244] avg loss 221.542, throughput 2.65956K wps\n",
      "[Epoch 156 Batch 240/244] avg loss 235.466, throughput 2.64551K wps\n",
      "[Epoch 156] train avg loss 292.316, train avg r2 0.816531,throughput 2.86856K wps\n",
      "learning rate: 3.0517578125e-08\n",
      "[Epoch 157 Batch 10/244] avg loss 597.891, throughput 2.36967K wps\n",
      "[Epoch 157 Batch 20/244] avg loss 393.51, throughput 2.77008K wps\n",
      "[Epoch 157 Batch 30/244] avg loss 227.333, throughput 2.91546K wps\n",
      "[Epoch 157 Batch 40/244] avg loss 304.301, throughput 3.8314K wps\n",
      "[Epoch 157 Batch 50/244] avg loss 164.728, throughput 3.92159K wps\n",
      "[Epoch 157 Batch 60/244] avg loss 726.318, throughput 2.5641K wps\n",
      "[Epoch 157 Batch 70/244] avg loss 235.236, throughput 3.21544K wps\n",
      "[Epoch 157 Batch 80/244] avg loss 138.091, throughput 3.663K wps\n",
      "[Epoch 157 Batch 90/244] avg loss 215.858, throughput 2.68096K wps\n",
      "[Epoch 157 Batch 100/244] avg loss 174.965, throughput 3.62319K wps\n",
      "[Epoch 157 Batch 110/244] avg loss 454.234, throughput 2.76242K wps\n",
      "[Epoch 157 Batch 120/244] avg loss 181.191, throughput 3.03953K wps\n",
      "[Epoch 157 Batch 130/244] avg loss 181.305, throughput 3.24672K wps\n",
      "[Epoch 157 Batch 140/244] avg loss 217.417, throughput 2.87359K wps\n",
      "[Epoch 157 Batch 150/244] avg loss 577.299, throughput 2.44498K wps\n",
      "[Epoch 157 Batch 160/244] avg loss 203.247, throughput 3.42465K wps\n",
      "[Epoch 157 Batch 170/244] avg loss 225.112, throughput 2.7933K wps\n",
      "[Epoch 157 Batch 180/244] avg loss 229.489, throughput 2.34192K wps\n",
      "[Epoch 157 Batch 190/244] avg loss 162.561, throughput 2.42719K wps\n",
      "[Epoch 157 Batch 200/244] avg loss 349.495, throughput 2.46912K wps\n",
      "[Epoch 157 Batch 210/244] avg loss 218.37, throughput 2.89857K wps\n",
      "[Epoch 157 Batch 220/244] avg loss 177.74, throughput 3.12499K wps\n",
      "[Epoch 157 Batch 230/244] avg loss 229.806, throughput 2.64551K wps\n",
      "[Epoch 157 Batch 240/244] avg loss 235.135, throughput 2.6455K wps\n",
      "[Epoch 157] train avg loss 292.525, train avg r2 0.81672,throughput 2.86755K wps\n",
      "learning rate: 3.0517578125e-08\n",
      "[Epoch 158 Batch 10/244] avg loss 595.431, throughput 2.36967K wps\n",
      "[Epoch 158 Batch 20/244] avg loss 408.596, throughput 2.77008K wps\n",
      "[Epoch 158 Batch 30/244] avg loss 226.374, throughput 2.92397K wps\n",
      "[Epoch 158 Batch 40/244] avg loss 271.381, throughput 3.84615K wps\n",
      "[Epoch 158 Batch 50/244] avg loss 160.93, throughput 3.93701K wps\n",
      "[Epoch 158 Batch 60/244] avg loss 662.089, throughput 2.55754K wps\n",
      "[Epoch 158 Batch 70/244] avg loss 251.879, throughput 3.20513K wps\n",
      "[Epoch 158 Batch 80/244] avg loss 147.509, throughput 3.64964K wps\n",
      "[Epoch 158 Batch 90/244] avg loss 221.15, throughput 2.68098K wps\n",
      "[Epoch 158 Batch 100/244] avg loss 179.703, throughput 3.62316K wps\n",
      "[Epoch 158 Batch 110/244] avg loss 454.977, throughput 2.77009K wps\n",
      "[Epoch 158 Batch 120/244] avg loss 182.53, throughput 3.04878K wps\n",
      "[Epoch 158 Batch 130/244] avg loss 168.702, throughput 3.25732K wps\n",
      "[Epoch 158 Batch 140/244] avg loss 217.797, throughput 2.89855K wps\n",
      "[Epoch 158 Batch 150/244] avg loss 597.907, throughput 2.43902K wps\n",
      "[Epoch 158 Batch 160/244] avg loss 202.82, throughput 3.41298K wps\n",
      "[Epoch 158 Batch 170/244] avg loss 244.795, throughput 2.7933K wps\n",
      "[Epoch 158 Batch 180/244] avg loss 219.597, throughput 2.35294K wps\n",
      "[Epoch 158 Batch 190/244] avg loss 156.219, throughput 2.4331K wps\n",
      "[Epoch 158 Batch 200/244] avg loss 341.931, throughput 2.47525K wps\n",
      "[Epoch 158 Batch 210/244] avg loss 216.755, throughput 2.89854K wps\n",
      "[Epoch 158 Batch 220/244] avg loss 177.595, throughput 3.125K wps\n",
      "[Epoch 158 Batch 230/244] avg loss 222.573, throughput 2.65958K wps\n",
      "[Epoch 158 Batch 240/244] avg loss 226.694, throughput 2.65251K wps\n",
      "[Epoch 158] train avg loss 288.869, train avg r2 0.821071,throughput 2.87059K wps\n",
      "learning rate: 3.0517578125e-08\n",
      "[Epoch 159 Batch 10/244] avg loss 620.549, throughput 2.36967K wps\n",
      "[Epoch 159 Batch 20/244] avg loss 386.755, throughput 2.76243K wps\n",
      "[Epoch 159 Batch 30/244] avg loss 218.181, throughput 2.90696K wps\n",
      "[Epoch 159 Batch 40/244] avg loss 302.977, throughput 3.84617K wps\n",
      "[Epoch 159 Batch 50/244] avg loss 171.086, throughput 3.95259K wps\n",
      "[Epoch 159 Batch 60/244] avg loss 691.592, throughput 2.56411K wps\n",
      "[Epoch 159 Batch 70/244] avg loss 252.775, throughput 3.22579K wps\n",
      "[Epoch 159 Batch 80/244] avg loss 131.26, throughput 3.67647K wps\n",
      "[Epoch 159 Batch 90/244] avg loss 213.285, throughput 2.68096K wps\n",
      "[Epoch 159 Batch 100/244] avg loss 172.85, throughput 3.6232K wps\n",
      "[Epoch 159 Batch 110/244] avg loss 459.347, throughput 2.77777K wps\n",
      "[Epoch 159 Batch 120/244] avg loss 202.503, throughput 3.04878K wps\n",
      "[Epoch 159 Batch 130/244] avg loss 179.008, throughput 3.26798K wps\n",
      "[Epoch 159 Batch 140/244] avg loss 233.575, throughput 2.88184K wps\n",
      "[Epoch 159 Batch 150/244] avg loss 596.839, throughput 2.43902K wps\n",
      "[Epoch 159 Batch 160/244] avg loss 199.12, throughput 3.41296K wps\n",
      "[Epoch 159 Batch 170/244] avg loss 232.76, throughput 2.80112K wps\n",
      "[Epoch 159 Batch 180/244] avg loss 201.157, throughput 2.35293K wps\n",
      "[Epoch 159 Batch 190/244] avg loss 161.659, throughput 2.4331K wps\n",
      "[Epoch 159 Batch 200/244] avg loss 352.246, throughput 2.46913K wps\n",
      "[Epoch 159 Batch 210/244] avg loss 222.072, throughput 2.88184K wps\n",
      "[Epoch 159 Batch 220/244] avg loss 173.724, throughput 3.11527K wps\n",
      "[Epoch 159 Batch 230/244] avg loss 237.994, throughput 2.65252K wps\n",
      "[Epoch 159 Batch 240/244] avg loss 250.855, throughput 2.65252K wps\n",
      "[Epoch 159] train avg loss 294.612, train avg r2 0.81566,throughput 2.86958K wps\n",
      "learning rate: 3.0517578125e-08\n",
      "Total time cost 2014.75s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(294.6120919349292, 0.8156604007943504)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs, learning_rate = 160,0.001                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "max_len = 100\n",
    "train(net, train_dataloader, train_batch_size, learning_rate, ctx, epochs)\n",
    "#train(net, train_dataloader, test_dataloader, batch_size, learning_rate, ctx, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
